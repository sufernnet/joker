#!/usr/bin/env python3
"""
ä»TVæºä¸­æå–"æ¸¯æ¾³é »é“"å’Œ"é«”è‚²ä¸–ç•Œ"å¹¶ä¸BB.m3uåˆå¹¶ï¼Œä¿å­˜ä¸ºEE.m3u
æ¸¯æ¾³é »é“: å‡¤å‡°é¢‘é“ â†’ NOWé¢‘é“ï¼ˆå»é‡ï¼‰ â†’ å…¶ä»–æ¸¯æ¾³é¢‘é“
é«”è‚²ä¸–ç•Œ: NOWä½“è‚²é¢‘é“ â†’ å…¶ä»–ä½“è‚²é¢‘é“
"""

import requests
import re
import os
import sys
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
SOURCE_URL = "https://raw.githubusercontent.com/yihad168/tv/refs/heads/main/tv.m3u"
EPG_URL = "http://epg.51zmt.top:8000/e.xml"
BB_FILE = "BB.m3u"  # å‡è®¾BB.m3uåœ¨ä»“åº“æ ¹ç›®å½•
OUTPUT_FILE = "../EE.m3u"  # ä¸Šä¸€çº§ç›®å½•ï¼ˆjokerç›®å½•ï¼‰

def fetch_m3u_content():
    """è·å–åŸå§‹M3Uæ–‡ä»¶å†…å®¹"""
    try:
        logger.info(f"æ­£åœ¨ä» {SOURCE_URL} ä¸‹è½½M3Uæ–‡ä»¶...")
        response = requests.get(SOURCE_URL, timeout=30)
        response.raise_for_status()
        logger.info(f"ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(response.text)} å­—ç¬¦")
        return response.text
    except requests.RequestException as e:
        logger.error(f"ä¸‹è½½M3Uæ–‡ä»¶å¤±è´¥: {e}")
        return None

def read_bb_file():
    """è¯»å–BB.m3uæ–‡ä»¶å†…å®¹"""
    try:
        # BB.m3uåœ¨ä»“åº“æ ¹ç›®å½•
        bb_path = "../BB.m3u"
        if os.path.exists(bb_path):
            with open(bb_path, 'r', encoding='utf-8') as f:
                content = f.read()
            logger.info(f"è¯»å–BB.m3uæˆåŠŸï¼Œå¤§å°: {len(content)} å­—ç¬¦")
            return content
        else:
            logger.warning(f"BB.m3uæ–‡ä»¶ä¸å­˜åœ¨: {bb_path}")
            return None
    except Exception as e:
        logger.error(f"è¯»å–BB.m3uå¤±è´¥: {e}")
        return None

def extract_and_sort_channels(content):
    """æå–æ¸¯æ¾³é »é“å’Œé«”è‚²ä¸–ç•Œï¼Œå¹¶è¿›è¡Œæ’åºå’Œå»é‡"""
    if not content:
        return None
    
    logger.info("å¼€å§‹æå–æŒ‡å®šåˆ†ç»„é¢‘é“...")
    
    # ç›®æ ‡åˆ†ç»„
    target_groups = ["æ¸¯æ¾³é »é“", "é«”è‚²ä¸–ç•Œ"]
    
    # æŒ‰è¡Œåˆ†å‰²å†…å®¹
    lines = content.split('\n')
    
    # å­˜å‚¨æå–çš„é¢‘é“
    # æ¸¯æ¾³é »é“åˆ†ç»„
    phoenix_channels = []  # å‡¤å‡°é¢‘é“
    now_channels = []      # NOWé¢‘é“ï¼ˆéœ€è¦å»é‡ï¼‰
    other_hk_channels = []  # æ¸¯æ¾³é »é“å…¶ä»–é¢‘é“
    
    # é«”è‚²ä¸–ç•Œåˆ†ç»„
    now_sports_channels = []  # NOWä½“è‚²é¢‘é“
    other_sports_channels = []  # å…¶ä»–ä½“è‚²é¢‘é“
    
    # ç”¨äºå»é‡çš„é›†åˆ
    seen_channels = set()
    
    # æŸ¥æ‰¾æ‰€æœ‰åˆ†ç»„ç”¨äºè°ƒè¯•
    all_groups = set()
    for line in lines:
        if '#EXTINF' in line and 'group-title="' in line:
            match = re.search(r'group-title="([^"]+)"', line)
            if match:
                all_groups.add(match.group(1))
    
    logger.info(f"æºæ–‡ä»¶ä¸­æ‰¾åˆ°çš„æ‰€æœ‰åˆ†ç»„: {sorted(all_groups)}")
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        if not line:
            i += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†ç»„è¡Œ
        if line.startswith("#EXTINF"):
            # æå–åˆ†ç»„ä¿¡æ¯
            group_match = re.search(r'group-title="([^"]+)"', line)
            if group_match:
                group_name = group_match.group(1)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åˆ†ç»„
                if group_name in target_groups:
                    # æŸ¥æ‰¾å¯¹åº”çš„URLè¡Œ
                    j = i + 1
                    url_line = ""
                    while j < len(lines):
                        temp_line = lines[j].strip()
                        if not temp_line:
                            j += 1
                            continue
                        if temp_line.startswith("#EXTINF"):
                            break
                        if temp_line and not temp_line.startswith("#"):
                            url_line = temp_line
                            break
                        j += 1
                    
                    if url_line:
                        # æå–é¢‘é“åç§°ç”¨äºå»é‡
                        channel_name_match = re.search(r',([^,]+)$', line)
                        channel_name = channel_name_match.group(1).strip() if channel_name_match else ""
                        
                        # åˆ›å»ºå”¯ä¸€æ ‡è¯†ï¼ˆé¢‘é“å+URLï¼‰
                        channel_id = f"{channel_name}|{url_line}"
                        
                        # æ£€æŸ¥æ˜¯å¦é‡å¤
                        if channel_id in seen_channels:
                            logger.info(f"è·³è¿‡é‡å¤é¢‘é“: {channel_name}")
                            i = j - 1
                            continue
                        
                        seen_channels.add(channel_id)
                        
                        channel_data = {
                            'extinf': line,
                            'url': url_line,
                            'group': group_name,
                            'name': channel_name
                        }
                        
                        # æ¸¯æ¾³é »é“åˆ†ç»„
                        if group_name == "æ¸¯æ¾³é »é“":
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å‡¤å‡°é¢‘é“
                            if 'å‡¤å‡°' in line or 'é³³å‡°' in line or 'Phoenix' in line.upper():
                                phoenix_channels.append(channel_data)
                                logger.info(f"å‡¤å‡°é¢‘é“: {channel_name}")
                            # æ£€æŸ¥æ˜¯å¦æ˜¯NOWé¢‘é“
                            elif 'NOW' in line.upper():
                                now_channels.append(channel_data)
                                logger.info(f"NOWé¢‘é“: {channel_name}")
                            else:
                                other_hk_channels.append(channel_data)
                        
                        # é«”è‚²ä¸–ç•Œåˆ†ç»„
                        elif group_name == "é«”è‚²ä¸–ç•Œ":
                            # æ£€æŸ¥æ˜¯å¦æ˜¯NOWä½“è‚²é¢‘é“
                            if 'NOW' in line.upper():
                                now_sports_channels.append(channel_data)
                                logger.info(f"NOWä½“è‚²é¢‘é“: {channel_name}")
                            else:
                                other_sports_channels.append(channel_data)
                                logger.info(f"å…¶ä»–ä½“è‚²é¢‘é“: {channel_name}")
        
        i += 1
    
    # å¯¹NOWé¢‘é“è¿›è¡Œå»é‡ï¼ˆé’ˆå¯¹NOWæ–°é—»å°ï¼‰
    logger.info("=== å¼€å§‹å»é‡NOWé¢‘é“ ===")
    unique_now_channels = []
    now_names_seen = set()
    
    for channel in now_channels:
        channel_name = channel['name']
        # æ ‡å‡†åŒ–NOWæ–°é—»å°åç§°
        if 'NOWæ–°é—»å°' in channel_name or 'NOWæ–°èå°' in channel_name:
            standardized_name = 'NOWæ–°é—»å°'
        else:
            standardized_name = channel_name
        
        if standardized_name not in now_names_seen:
            now_names_seen.add(standardized_name)
            unique_now_channels.append(channel)
            logger.info(f"ä¿ç•™NOWé¢‘é“: {channel_name}")
        else:
            logger.info(f"å»é‡NOWé¢‘é“: {channel_name}")
    
    now_channels = unique_now_channels
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    logger.info("=== æå–ç»Ÿè®¡ ===")
    logger.info(f"æ¸¯æ¾³é »é“ - å‡¤å‡°é¢‘é“: {len(phoenix_channels)} ä¸ª")
    logger.info(f"æ¸¯æ¾³é »é“ - NOWé¢‘é“ï¼ˆå»é‡åï¼‰: {len(now_channels)} ä¸ª")
    logger.info(f"æ¸¯æ¾³é »é“ - å…¶ä»–é¢‘é“: {len(other_hk_channels)} ä¸ª")
    logger.info(f"é«”è‚²ä¸–ç•Œ - NOWä½“è‚²é¢‘é“: {len(now_sports_channels)} ä¸ª")
    logger.info(f"é«”è‚²ä¸–ç•Œ - å…¶ä»–ä½“è‚²é¢‘é“: {len(other_sports_channels)} ä¸ª")
    
    total_channels = (len(phoenix_channels) + len(now_channels) + len(other_hk_channels) +
                     len(now_sports_channels) + len(other_sports_channels))
    logger.info(f"æ€»è®¡æå–ï¼ˆå»é‡åï¼‰: {total_channels} ä¸ªé¢‘é“")
    
    if total_channels == 0:
        logger.error("æ²¡æœ‰æå–åˆ°ä»»ä½•é¢‘é“ï¼Œè¯·æ£€æŸ¥åˆ†ç»„åç§°")
        return None
    
    # æ„å»ºæ’åºåçš„å†…å®¹
    extracted_lines = []
    
    # æ·»åŠ æ–‡ä»¶å¤´
    extracted_lines.append(f'#EXTM3U url-tvg="{EPG_URL}"')
    
    # æ·»åŠ æ³¨é‡Šè¯´æ˜æ’åºå’Œå»é‡è§„åˆ™
    extracted_lines.append("# æ’åºå’Œå»é‡è§„åˆ™:")
    extracted_lines.append("# æ¸¯æ¾³é »é“: å‡¤å‡°é¢‘é“ â†’ NOWé¢‘é“ï¼ˆå»é‡ï¼‰ â†’ å…¶ä»–æ¸¯æ¾³é¢‘é“")
    extracted_lines.append("# é«”è‚²ä¸–ç•Œ: NOWä½“è‚²é¢‘é“ â†’ å…¶ä»–ä½“è‚²é¢‘é“")
    extracted_lines.append("")
    
    # æ¸¯æ¾³é »é“éƒ¨åˆ†
    if phoenix_channels or now_channels or other_hk_channels:
        extracted_lines.append("#" + "="*50)
        extracted_lines.append("# æ¸¯æ¾³é »é“")
        extracted_lines.append("#" + "="*50)
        
        # 1. å‡¤å‡°é¢‘é“
        if phoenix_channels:
            extracted_lines.append("## å‡¤å‡°é¢‘é“")
            for channel in phoenix_channels:
                extracted_lines.append(channel['extinf'])
                extracted_lines.append(channel['url'])
        
        # 2. NOWé¢‘é“ï¼ˆå»é‡åï¼‰
        if now_channels:
            extracted_lines.append("## NOWé¢‘é“")
            for channel in now_channels:
                extracted_lines.append(channel['extinf'])
                extracted_lines.append(channel['url'])
        
        # 3. å…¶ä»–æ¸¯æ¾³é¢‘é“
        if other_hk_channels:
            extracted_lines.append("## å…¶ä»–æ¸¯æ¾³é¢‘é“")
            for channel in other_hk_channels:
                extracted_lines.append(channel['extinf'])
                extracted_lines.append(channel['url'])
        
        extracted_lines.append("")  # ç©ºè¡Œåˆ†éš”
    
    # é«”è‚²ä¸–ç•Œéƒ¨åˆ†
    if now_sports_channels or other_sports_channels:
        extracted_lines.append("#" + "="*50)
        extracted_lines.append("# é«”è‚²ä¸–ç•Œ")
        extracted_lines.append("#" + "="*50)
        
        # 1. NOWä½“è‚²é¢‘é“ä¼˜å…ˆ
        if now_sports_channels:
            extracted_lines.append("## NOWä½“è‚²é¢‘é“")
            for channel in now_sports_channels:
                extracted_lines.append(channel['extinf'])
                extracted_lines.append(channel['url'])
        
        # 2. å…¶ä»–ä½“è‚²é¢‘é“
        if other_sports_channels:
            extracted_lines.append("## å…¶ä»–ä½“è‚²é¢‘é“")
            for channel in other_sports_channels:
                extracted_lines.append(channel['extinf'])
                extracted_lines.append(channel['url'])
    
    return '\n'.join(extracted_lines)

def merge_with_bb(tv_content, bb_content):
    """å°†æå–çš„TVå†…å®¹ä¸BB.m3uåˆå¹¶"""
    merged_lines = []
    
    # æ·»åŠ æ–‡ä»¶å¤´
    merged_lines.append(f'#EXTM3U url-tvg="{EPG_URL}"')
    
    # æ·»åŠ ç”Ÿæˆä¿¡æ¯
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    merged_lines.append(f"# ç”Ÿæˆæ—¶é—´: {timestamp}")
    merged_lines.append(f"# æºåœ°å€: {SOURCE_URL}")
    merged_lines.append(f"# EPGæº: {EPG_URL}")
    merged_lines.append("# åŒ…å«å†…å®¹: BB.m3u + æ¸¯æ¾³é »é“ + é«”è‚²ä¸–ç•Œ")
    merged_lines.append("# æ’åºè§„åˆ™:")
    merged_lines.append("#   æ¸¯æ¾³é »é“: å‡¤å‡°é¢‘é“ â†’ NOWé¢‘é“ï¼ˆå»é‡ï¼‰ â†’ å…¶ä»–æ¸¯æ¾³é¢‘é“")
    merged_lines.append("#   é«”è‚²ä¸–ç•Œ: NOWä½“è‚²é¢‘é“ â†’ å…¶ä»–ä½“è‚²é¢‘é“")
    merged_lines.append("# è‡ªåŠ¨æ›´æ–°é¢‘é“åˆ—è¡¨")
    merged_lines.append("")
    
    # å¦‚æœæœ‰BBå†…å®¹ï¼Œå…ˆæ·»åŠ BBçš„å†…å®¹ï¼ˆè·³è¿‡å…¶æ–‡ä»¶å¤´ï¼‰
    if bb_content:
        bb_lines = bb_content.split('\n')
        bb_count = 0
        for line in bb_lines:
            line = line.strip()
            if line:
                if line.startswith("#EXTM3U"):
                    continue  # è·³è¿‡BBçš„æ–‡ä»¶å¤´
                if line.startswith("#EXTINF"):
                    bb_count += 1
                merged_lines.append(line)
        
        if bb_count > 0:
            logger.info(f"åˆå¹¶äº† {bb_count} ä¸ªBBé¢‘é“")
            merged_lines.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
            merged_lines.append("#" + "="*60)
            merged_lines.append("# ä»¥ä¸‹ä¸ºæå–çš„æ¸¯æ¾³é »é“å’Œé«”è‚²ä¸–ç•Œï¼ˆå·²æ’åºå’Œå»é‡ï¼‰")
            merged_lines.append("#" + "="*60)
            merged_lines.append("")
    
    # æ·»åŠ æå–çš„TVå†…å®¹ï¼ˆè·³è¿‡æ–‡ä»¶å¤´ï¼‰
    if tv_content:
        tv_lines = tv_content.split('\n')
        for line in tv_lines:
            line = line.strip()
            if line:
                merged_lines.append(line)
    
    return '\n'.join(merged_lines)

def save_m3u_file(content):
    """ä¿å­˜M3Uæ–‡ä»¶"""
    if not content:
        logger.error("æ²¡æœ‰å†…å®¹å¯ä¿å­˜")
        return False
    
    try:
        # è·å–è„šæœ¬ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•ï¼ˆjokerç›®å½•ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(script_dir)
        output_path = os.path.join(parent_dir, "EE.m3u")
        
        logger.info(f"å°†ä¿å­˜åˆ°: {output_path}")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # éªŒè¯æ–‡ä»¶
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            extinf_count = content.count("#EXTINF")
            
            logger.info("âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
            logger.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {output_path}")
            logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            logger.info(f"ğŸ“ˆ é¢‘é“æ€»æ•°: {extinf_count}")
            
            # ç»Ÿè®¡å„åˆ†ç±»æ•°é‡
            phoenix_count = content.count("å‡¤å‡°") + content.count("é³³å‡°")
            now_hk_count = 0
            now_sports_count = 0
            
            # æ›´ç²¾ç¡®çš„ç»Ÿè®¡
            lines = content.split('\n')
            in_now_hk = False
            in_now_sports = False
            
            for line in lines:
                if "## NOWé¢‘é“" in line:
                    in_now_hk = True
                    in_now_sports = False
                elif "## NOWä½“è‚²é¢‘é“" in line:
                    in_now_hk = False
                    in_now_sports = True
                elif line.startswith("#EXTINF"):
                    if in_now_hk:
                        now_hk_count += 1
                    elif in_now_sports:
                        now_sports_count += 1
            
            sports_count = content.count("é«”è‚²ä¸–ç•Œ")
            
            logger.info("=== è¯¦ç»†åˆ†ç±»ç»Ÿè®¡ ===")
            logger.info(f"å‡¤å‡°é¢‘é“: {phoenix_count} ä¸ª")
            logger.info(f"NOWæ¸¯æ¾³é¢‘é“ï¼ˆå»é‡åï¼‰: {now_hk_count} ä¸ª")
            logger.info(f"NOWä½“è‚²é¢‘é“: {now_sports_count} ä¸ª")
            logger.info(f"é«”è‚²ä¸–ç•Œæ€»æ•°: {sports_count} ä¸ª")
            
            # æ£€æŸ¥NOWæ–°é—»å°æ˜¯å¦é‡å¤
            now_news_count = 0
            for line in lines:
                if line.startswith("#EXTINF") and ('NOWæ–°é—»å°' in line or 'NOWæ–°èå°' in line):
                    now_news_count += 1
            
            if now_news_count > 1:
                logger.warning(f"âš ï¸  å‘ç° {now_news_count} ä¸ªNOWæ–°é—»å°ï¼Œå¯èƒ½å­˜åœ¨é‡å¤")
            else:
                logger.info("âœ… NOWæ–°é—»å°å·²å»é‡")
            
            return True
        else:
            logger.error("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=== M3Ué¢‘é“æå–å™¨å¼€å§‹è¿è¡Œ ===")
    logger.info("æ’åºè§„åˆ™: æ¸¯æ¾³é »é“-å‡¤å‡°ä¼˜å…ˆ+NOWå»é‡ï¼›é«”è‚²ä¸–ç•Œ-NOWä¼˜å…ˆ")
    
    # 1. è·å–åŸå§‹TVå†…å®¹
    raw_content = fetch_m3u_content()
    if not raw_content:
        logger.error("æ— æ³•è·å–åŸå§‹TVå†…å®¹ï¼Œç¨‹åºé€€å‡º")
        sys.exit(1)
    
    # 2. æå–ã€æ’åºå¹¶å»é‡æŒ‡å®šé¢‘é“
    extracted_content = extract_and_sort_channels(raw_content)
    if not extracted_content:
        logger.error("æœªæ‰¾åˆ°æŒ‡å®šçš„åˆ†ç»„é¢‘é“")
        sys.exit(1)
    
    # 3. è¯»å–BB.m3u
    bb_content = read_bb_file()
    
    # 4. åˆå¹¶å†…å®¹
    merged_content = merge_with_bb(extracted_content, bb_content)
    
    # 5. ä¿å­˜æ–‡ä»¶
    if save_m3u_file(merged_content):
        logger.info("=== å¤„ç†å®Œæˆ ===")
    else:
        logger.error("=== å¤„ç†å¤±è´¥ ===")
        sys.exit(1)

if __name__ == "__main__":
    main()
