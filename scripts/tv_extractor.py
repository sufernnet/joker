#!/usr/bin/env python3
"""
ä»TVæºä¸­æå–"æ¸¯æ¾³é »é“"å’Œ"é«”è‚²ä¸–ç•Œ"å¹¶ä¸BB.m3uåˆå¹¶ï¼Œä¿å­˜ä¸ºEE.m3u
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæé«˜è¿è¡Œé€Ÿåº¦
"""

import requests
import re
import os
import sys
from datetime import datetime
import logging
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
SOURCE_URL = "https://raw.githubusercontent.com/yihad168/tv/refs/heads/main/tv.m3u"
EPG_URL = "http://epg.51zmt.top:8000/e.xml"
BB_FILE = "BB.m3u"
OUTPUT_FILE = "../EE.m3u"

def fetch_m3u_content():
    """è·å–åŸå§‹M3Uæ–‡ä»¶å†…å®¹"""
    try:
        logger.info(f"æ­£åœ¨ä» {SOURCE_URL} ä¸‹è½½M3Uæ–‡ä»¶...")
        start_time = time.time()
        response = requests.get(SOURCE_URL, timeout=60)  # å¢åŠ è¶…æ—¶æ—¶é—´
        response.raise_for_status()
        elapsed = time.time() - start_time
        logger.info(f"ä¸‹è½½æˆåŠŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’ï¼Œå¤§å°: {len(response.text)} å­—ç¬¦")
        return response.text
    except requests.RequestException as e:
        logger.error(f"ä¸‹è½½M3Uæ–‡ä»¶å¤±è´¥: {e}")
        return None

def read_bb_file():
    """è¯»å–BB.m3uæ–‡ä»¶å†…å®¹"""
    try:
        bb_path = "../BB.m3u"
        if os.path.exists(bb_path):
            with open(bb_path, 'r', encoding='utf-8') as f:
                content = f.read()
            logger.info(f"è¯»å–BB.m3uæˆåŠŸï¼Œå¤§å°: {len(content)} å­—ç¬¦")
            return content
        else:
            logger.warning(f"BB.m3uæ–‡ä»¶ä¸å­˜åœ¨: {bb_path}")
            return None
    except Exception as e:
        logger.error(f"è¯»å–BB.m3uå¤±è´¥: {e}")
        return None

def extract_and_sort_channels_fast(content):
    """å¿«é€Ÿæå–å’Œæ’åºé¢‘é“"""
    if not content:
        return None
    
    logger.info("å¼€å§‹å¿«é€Ÿæå–æŒ‡å®šåˆ†ç»„é¢‘é“...")
    start_time = time.time()
    
    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼Œæé«˜é€Ÿåº¦
    group_pattern = re.compile(r'group-title="([^"]+)"')
    channel_name_pattern = re.compile(r',([^,]+)$')
    
    # ç›®æ ‡åˆ†ç»„
    target_groups = {"æ¸¯æ¾³é »é“", "é«”è‚²ä¸–ç•Œ"}
    
    # å­˜å‚¨é¢‘é“
    categories = {
        'phoenix': [],      # å‡¤å‡°é¢‘é“
        'now_hk': [],       # NOWæ¸¯æ¾³é¢‘é“ï¼ˆå»é‡ï¼‰
        'other_hk': [],     # å…¶ä»–æ¸¯æ¾³é¢‘é“
        'now_sports': [],   # NOWä½“è‚²é¢‘é“
        'other_sports': []  # å…¶ä»–ä½“è‚²é¢‘é“
    }
    
    # ç”¨äºå»é‡çš„é›†åˆ
    seen_now_hk = set()     # NOWæ¸¯æ¾³é¢‘é“åç§°å»é‡
    seen_urls = set()       # URLå»é‡ï¼ˆé˜²æ­¢å®Œå…¨ç›¸åŒçš„é¢‘é“ï¼‰
    
    # å¿«é€Ÿåˆ†å‰²è¡Œ
    lines = content.split('\n')
    total_lines = len(lines)
    logger.info(f"å¼€å§‹å¤„ç† {total_lines} è¡Œæ•°æ®...")
    
    i = 0
    processed_count = 0
    
    while i < total_lines:
        line = lines[i].strip()
        
        if line and line.startswith("#EXTINF"):
            # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡åˆ†ç»„
            if any(f'group-title="{group}"' in line for group in target_groups):
                processed_count += 1
                
                # æå–åˆ†ç»„ä¿¡æ¯
                group_match = group_pattern.search(line)
                if not group_match:
                    i += 1
                    continue
                    
                group_name = group_match.group(1)
                
                # æŸ¥æ‰¾URLè¡Œ
                url_line = ""
                j = i + 1
                while j < total_lines:
                    temp_line = lines[j].strip()
                    if temp_line and not temp_line.startswith("#"):
                        url_line = temp_line
                        break
                    j += 1
                
                if url_line:
                    # URLå»é‡
                    if url_line in seen_urls:
                        i = j
                        continue
                    seen_urls.add(url_line)
                    
                    # æå–é¢‘é“åç§°
                    name_match = channel_name_pattern.search(line)
                    channel_name = name_match.group(1).strip() if name_match else ""
                    
                    # æ¸¯æ¾³é »é“å¤„ç†
                    if group_name == "æ¸¯æ¾³é »é“":
                        line_upper = line.upper()
                        
                        # æ£€æŸ¥å‡¤å‡°é¢‘é“
                        if 'å‡¤å‡°' in line or 'é³³å‡°' in line or 'PHOENIX' in line_upper:
                            categories['phoenix'].append((line, url_line, channel_name))
                        
                        # æ£€æŸ¥NOWé¢‘é“ï¼ˆéœ€è¦å»é‡ï¼‰
                        elif 'NOW' in line_upper:
                            # æ ‡å‡†åŒ–NOWæ–°é—»å°åç§°
                            if 'NOWæ–°é—»å°' in channel_name or 'NOWæ–°èå°' in channel_name:
                                std_name = 'NOWæ–°é—»å°'
                            else:
                                std_name = channel_name
                            
                            # NOWé¢‘é“å»é‡
                            if std_name not in seen_now_hk:
                                seen_now_hk.add(std_name)
                                categories['now_hk'].append((line, url_line, channel_name))
                        
                        # å…¶ä»–æ¸¯æ¾³é¢‘é“
                        else:
                            categories['other_hk'].append((line, url_line, channel_name))
                    
                    # é«”è‚²ä¸–ç•Œå¤„ç†
                    elif group_name == "é«”è‚²ä¸–ç•Œ":
                        if 'NOW' in line.upper():
                            categories['now_sports'].append((line, url_line, channel_name))
                        else:
                            categories['other_sports'].append((line, url_line, channel_name))
                    
                    i = j  # è·³è¿‡URLè¡Œ
                else:
                    i += 1
            else:
                i += 1
        else:
            i += 1
    
    elapsed = time.time() - start_time
    logger.info(f"å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    logger.info(f"å¤„ç†äº† {processed_count} ä¸ªé¢‘é“æ¡ç›®")
    
    # ç»Ÿè®¡
    logger.info("=== æå–ç»Ÿè®¡ ===")
    for cat_name, cat_list in categories.items():
        logger.info(f"{cat_name}: {len(cat_list)} ä¸ª")
    
    total_channels = sum(len(cat) for cat in categories.values())
    logger.info(f"æ€»è®¡æå–: {total_channels} ä¸ªé¢‘é“")
    
    if total_channels == 0:
        return None
    
    # æ„å»ºè¾“å‡ºå†…å®¹
    result_lines = [f'#EXTM3U url-tvg="{EPG_URL}"']
    result_lines.append("# æ’åºè§„åˆ™: æ¸¯æ¾³é »é“(å‡¤å‡°â†’NOWå»é‡â†’å…¶ä»–) | é«”è‚²ä¸–ç•Œ(NOWâ†’å…¶ä»–)")
    result_lines.append("")
    
    # æ·»åŠ æ¸¯æ¾³é »é“
    if any(len(categories[cat]) > 0 for cat in ['phoenix', 'now_hk', 'other_hk']):
        result_lines.append("#" + "=" * 50)
        result_lines.append("# æ¸¯æ¾³é »é“")
        result_lines.append("#" + "=" * 50)
        
        # å‡¤å‡°é¢‘é“
        if categories['phoenix']:
            result_lines.append("## å‡¤å‡°é¢‘é“")
            for extinf, url, name in categories['phoenix']:
                result_lines.append(extinf)
                result_lines.append(url)
        
        # NOWæ¸¯æ¾³é¢‘é“
        if categories['now_hk']:
            result_lines.append("## NOWé¢‘é“")
            for extinf, url, name in categories['now_hk']:
                result_lines.append(extinf)
                result_lines.append(url)
        
        # å…¶ä»–æ¸¯æ¾³é¢‘é“
        if categories['other_hk']:
            result_lines.append("## å…¶ä»–æ¸¯æ¾³é¢‘é“")
            for extinf, url, name in categories['other_hk']:
                result_lines.append(extinf)
                result_lines.append(url)
        
        result_lines.append("")
    
    # æ·»åŠ é«”è‚²ä¸–ç•Œ
    if any(len(categories[cat]) > 0 for cat in ['now_sports', 'other_sports']):
        result_lines.append("#" + "=" * 50)
        result_lines.append("# é«”è‚²ä¸–ç•Œ")
        result_lines.append("#" + "=" * 50)
        
        # NOWä½“è‚²é¢‘é“
        if categories['now_sports']:
            result_lines.append("## NOWä½“è‚²é¢‘é“")
            for extinf, url, name in categories['now_sports']:
                result_lines.append(extinf)
                result_lines.append(url)
        
        # å…¶ä»–ä½“è‚²é¢‘é“
        if categories['other_sports']:
            result_lines.append("## å…¶ä»–ä½“è‚²é¢‘é“")
            for extinf, url, name in categories['other_sports']:
                result_lines.append(extinf)
                result_lines.append(url)
    
    return '\n'.join(result_lines)

def merge_with_bb_fast(tv_content, bb_content):
    """å¿«é€Ÿåˆå¹¶å†…å®¹"""
    result_lines = []
    
    # å¤´éƒ¨ä¿¡æ¯
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    result_lines.append(f'#EXTM3U url-tvg="{EPG_URL}"')
    result_lines.append(f"# ç”Ÿæˆæ—¶é—´: {timestamp}")
    result_lines.append(f"# æºåœ°å€: {SOURCE_URL}")
    result_lines.append(f"# EPGæº: {EPG_URL}")
    result_lines.append("# åŒ…å«: BB.m3u + æ¸¯æ¾³é »é“ + é«”è‚²ä¸–ç•Œ")
    result_lines.append("# æ’åº: æ¸¯æ¾³é »é“(å‡¤å‡°â†’NOWå»é‡â†’å…¶ä»–) | é«”è‚²ä¸–ç•Œ(NOWâ†’å…¶ä»–)")
    result_lines.append("")
    
    # æ·»åŠ BBå†…å®¹
    if bb_content:
        bb_lines = bb_content.split('\n')
        bb_count = 0
        for line in bb_lines:
            line = line.strip()
            if line:
                if line.startswith("#EXTM3U"):
                    continue
                if line.startswith("#EXTINF"):
                    bb_count += 1
                result_lines.append(line)
        
        if bb_count > 0:
            logger.info(f"åˆå¹¶BBé¢‘é“: {bb_count} ä¸ª")
            result_lines.append("")
            result_lines.append("#" + "=" * 60)
            result_lines.append("# ä»¥ä¸‹ä¸ºæå–çš„æ¸¯æ¾³é »é“å’Œé«”è‚²ä¸–ç•Œ")
            result_lines.append("#" + "=" * 60)
            result_lines.append("")
    
    # æ·»åŠ TVå†…å®¹ï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ª#EXTM3Uï¼‰
    if tv_content:
        tv_lines = tv_content.split('\n')
        skip_first_extm3u = True
        for line in tv_lines:
            line = line.strip()
            if line:
                if line.startswith("#EXTM3U") and skip_first_extm3u:
                    skip_first_extm3u = False
                    continue
                result_lines.append(line)
    
    return '\n'.join(result_lines)

def save_m3u_file(content):
    """ä¿å­˜M3Uæ–‡ä»¶"""
    if not content:
        logger.error("æ²¡æœ‰å†…å®¹å¯ä¿å­˜")
        return False
    
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_path = os.path.join(os.path.dirname(script_dir), "EE.m3u")
        
        logger.info(f"æ­£åœ¨ä¿å­˜åˆ°: {output_path}")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            extinf_count = content.count("#EXTINF")
            
            logger.info("âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
            logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size/1024:.1f} KB")
            logger.info(f"ğŸ“ˆ é¢‘é“æ€»æ•°: {extinf_count}")
            
            # å¿«é€Ÿç»Ÿè®¡
            lines = content.split('\n')
            now_news_count = sum(1 for line in lines if line.startswith("#EXTINF") and 
                                ('NOWæ–°é—»å°' in line or 'NOWæ–°èå°' in line))
            
            logger.info(f"ğŸ“Š NOWæ–°é—»å°: {now_news_count} ä¸ªï¼ˆå·²å»é‡ï¼‰")
            
            return True
        else:
            logger.error("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=== M3Ué¢‘é“æå–å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰å¼€å§‹è¿è¡Œ ===")
    total_start = time.time()
    
    # 1. è·å–åŸå§‹TVå†…å®¹
    raw_content = fetch_m3u_content()
    if not raw_content:
        logger.error("æ— æ³•è·å–åŸå§‹TVå†…å®¹")
        sys.exit(1)
    
    # 2. æå–å¹¶æ’åº
    extracted_content = extract_and_sort_channels_fast(raw_content)
    if not extracted_content:
        logger.error("æœªæ‰¾åˆ°æŒ‡å®šçš„åˆ†ç»„é¢‘é“")
        sys.exit(1)
    
    # 3. è¯»å–BB.m3u
    bb_content = read_bb_file()
    
    # 4. åˆå¹¶å†…å®¹
    merged_content = merge_with_bb_fast(extracted_content, bb_content)
    
    # 5. ä¿å­˜æ–‡ä»¶
    if not save_m3u_file(merged_content):
        logger.error("æ–‡ä»¶ä¿å­˜å¤±è´¥")
        sys.exit(1)
    
    total_elapsed = time.time() - total_start
    logger.info(f"=== å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_elapsed:.2f}ç§’ ===")

if __name__ == "__main__":
    main()
