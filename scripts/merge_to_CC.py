#!/usr/bin/env python3
"""
CC.m3u åˆå¹¶è„šæœ¬ - æ ‡å‡†M3Uæ ¼å¼ï¼ˆæ”¯æŒé¢‘é“æºåˆå¹¶ï¼‰
ä» https://stymei.sufern001.workers.dev/ æå–ï¼š
1. ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°
2. ğŸ”®æ¸¯æ¾³å°ç›´æ’­
å°†ç›¸åŒé¢‘é“åˆå¹¶ï¼Œæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼Œå¹¶ä¸æœ¬åœ° BB.m3u åˆå¹¶è¾“å‡º CC.m3u
"""

import requests
from datetime import datetime
import os
import re
import hashlib
from collections import defaultdict

# ================== é…ç½®åŒºåŸŸ ==================
SOURCE_URL = "https://stymei.sufern001.workers.dev/"
BB_FILE = "BB.m3u"
OUTPUT_FILE = "CC.m3u"

# è¦æå–çš„æºåˆ†ç»„ï¼ˆå¯æ‰©å±•å¤šä¸ªï¼‰
SOURCE_GROUPS = [
    "ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°",
    "ğŸ”®æ¸¯æ¾³å°ç›´æ’­"
]
TARGET_GROUP = "å…¨ç½‘é€šæ¸¯æ¾³å°"  # åˆå¹¶åçš„ç»Ÿä¸€åˆ†ç»„å

# å°æ ‡æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
LOGO_SOURCES = [
    "https://raw.githubusercontent.com/iptv-org/iptv/master/logos/",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/",
    "https://raw.githubusercontent.com/lqist/IPTVlogos/main/",
]

# ================== å·¥å…·å‡½æ•° ==================
def log(msg):
    """æ—¥å¿—è¾“å‡º"""
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def get_channel_logo(channel_name):
    """æ ¹æ®é¢‘é“ååŒ¹é…å°æ ‡"""
    # é¢‘é“åæ˜ å°„è¡¨ï¼ˆå¯è‡ªè¡Œæ‰©å±•ï¼‰
    logo_map = {
        # å‡¤å‡°ç³»åˆ—
        "å‡¤å‡°ä¸­æ–‡": "phoenix.chinese.png",
        "å‡¤å‡°èµ„è®¯": "phoenix.infonews.png",
        "å‡¤å‡°é¦™æ¸¯": "phoenix.hongkong.png",
        "å‡¤å‡°å«è§†": "phoenix.tv.png",
        # TVBç³»åˆ—
        "ç¿¡ç¿ å°": "tvb.jade.png",
        "æ˜ç å°": "tvb.pearl.png",
        "J2": "tvb.j2.png",
        # å…¶ä»–å¸¸è§é¢‘é“
        "TVBS": "tvbs.png",
        "ä¸­å¤©": "cti.png",
        "ä¸œæ£®": "ettv.png",
        "ä¸‰ç«‹": "set.png",
        "æ°‘è§†": "ftv.png",
        "HBO": "hbo.png",
        "CNN": "cnn.png",
        "BBC": "bbc.png",
        "Discovery": "discovery.png",
        "National Geographic": "natgeo.png",
        "ESPN": "espn.png",
        "FOX": "fox.png",
    }
    
    # 1. ç²¾ç¡®åŒ¹é…
    for key, filename in logo_map.items():
        if key in channel_name:
            for source in LOGO_SOURCES:
                logo_url = f"{source}{filename}"
                return logo_url
    
    # 2. å…³é”®è¯åŒ¹é…
    keywords = {
        "æ–°é—»": "news.png",
        "ä½“è‚²": "sports.png",
        "ç”µå½±": "movie.png",
        "éŸ³ä¹": "music.png",
        "å„¿ç«¥": "kids.png",
        "å¡é€š": "cartoon.png",
        "è´¢ç»": "finance.png",
        "æ•™è‚²": "education.png",
    }
    
    for keyword, filename in keywords.items():
        if keyword in channel_name:
            for source in LOGO_SOURCES:
                logo_url = f"{source}{filename}"
                return logo_url
    
    # 3. è¿”å›é»˜è®¤å°æ ‡
    return "https://raw.githubusercontent.com/iptv-org/iptv/master/logos/default.png"

def extract_tvg_info(channel_name):
    """ç”Ÿæˆé¢‘é“çš„tvgä¿¡æ¯"""
    # æ¸…ç†åç§°ç”Ÿæˆtvg-id
    clean_name = re.sub(r'[^\w\u4e00-\u9fff]', '', channel_name)
    
    # ä½¿ç”¨MD5ç”Ÿæˆä¸€è‡´çš„tvg-idï¼Œç¡®ä¿ç›¸åŒé¢‘é“åæœ‰ç›¸åŒID
    tvg_id = f"channel_{hashlib.md5(channel_name.encode()).hexdigest()[:8]}"
    tvg_name = channel_name
    logo_url = get_channel_logo(channel_name)
    
    return tvg_id, tvg_name, logo_url

def download_source():
    """ä¸‹è½½æºæ•°æ®"""
    try:
        log(f"æ­£åœ¨ä¸‹è½½æºæ•°æ®: {SOURCE_URL}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/plain'
        }
        response = requests.get(SOURCE_URL, headers=headers, timeout=30)
        response.raise_for_status()
        content = response.text
        log(f"âœ… ä¸‹è½½æˆåŠŸï¼Œ{len(content)} å­—ç¬¦")
        return content
    except Exception as e:
        log(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None

def extract_and_merge_channels(content):
    """
    ä»å†…å®¹ä¸­æå–æŒ‡å®šåˆ†ç»„çš„æ‰€æœ‰é¢‘é“ï¼Œå¹¶åˆå¹¶ç›¸åŒé¢‘é“çš„å¤šä¸ªæº
    è¿”å›ç»“æ„: {channel_name: {tvg_id, tvg_name, logo, group, urls: [url1, url2, ...]}}
    """
    if not content:
        return {}
    
    # ä½¿ç”¨å­—å…¸åˆå¹¶ç›¸åŒé¢‘é“ï¼Œå€¼æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰URLçš„åˆ—è¡¨
    channel_dict = defaultdict(lambda: {
        'name': '',
        'tvg_id': '',
        'tvg_name': '',
        'logo': '',
        'group': TARGET_GROUP,
        'urls': [],  # å­˜å‚¨å¤šä¸ªæ’­æ”¾åœ°å€
        'source_groups': set()  # è®°å½•æ¥æºåˆ†ç»„
    })
    
    lines = content.split('\n')
    
    log(f"å¼€å§‹æå–å¹¶åˆå¹¶åˆ†ç»„: {SOURCE_GROUPS}")
    
    for source_group in SOURCE_GROUPS:
        in_section = False
        group_found = False
        group_count = 0
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # æŸ¥æ‰¾åˆ†ç»„å¼€å§‹
            if f"{source_group},#genre#" in line:
                log(f"âœ… æ‰¾åˆ°åˆ†ç»„: {source_group} (ç¬¬{i+1}è¡Œ)")
                in_section = True
                group_found = True
                continue
            
            # å¦‚æœå·²åœ¨åˆ†ç»„ä¸­ï¼Œé‡åˆ°ä¸‹ä¸€ä¸ªåˆ†ç»„åˆ™ç»“æŸ
            if in_section and '#genre#' in line and source_group not in line:
                break
            
            # æå–é¢‘é“
            if in_section and line and ',' in line:
                parts = line.split(',')
                if len(parts) >= 2:
                    channel_name = parts[0].strip()
                    url = ','.join(parts[1:]).strip()
                    
                    if url and ('://' in url or url.startswith('http')):
                        # å¦‚æœæ˜¯é¦–æ¬¡é‡åˆ°è¿™ä¸ªé¢‘é“ï¼Œç”Ÿæˆtvgä¿¡æ¯
                        if channel_name not in channel_dict or not channel_dict[channel_name]['tvg_id']:
                            tvg_id, tvg_name, logo_url = extract_tvg_info(channel_name)
                            channel_dict[channel_name].update({
                                'name': channel_name,
                                'tvg_id': tvg_id,
                                'tvg_name': tvg_name,
                                'logo': logo_url,
                                'group': TARGET_GROUP,
                            })
                        
                        # æ·»åŠ URLåˆ°åˆ—è¡¨
                        if url not in channel_dict[channel_name]['urls']:
                            channel_dict[channel_name]['urls'].append(url)
                            channel_dict[channel_name]['source_groups'].add(source_group)
                            group_count += 1
        
        if group_found:
            log(f"  ä»ã€Œ{source_group}ã€æå– {group_count} ä¸ªæ’­æ”¾æº")
        else:
            log(f"âš ï¸  æœªæ‰¾åˆ°åˆ†ç»„: {source_group}")
    
    # è½¬æ¢ä¸ºæ™®é€šå­—å…¸å¹¶ç»Ÿè®¡
    result = dict(channel_dict)
    total_channels = len(result)
    total_urls = sum(len(ch['urls']) for ch in result.values())
    
    log(f"âœ… åˆå¹¶åå¾—åˆ° {total_channels} ä¸ªå”¯ä¸€é¢‘é“ï¼Œå…± {total_urls} ä¸ªæ’­æ”¾æº")
    
    # æ˜¾ç¤ºåˆå¹¶ç¤ºä¾‹
    if result:
        log("é¢‘é“åˆå¹¶ç¤ºä¾‹:")
        for name, data in list(result.items())[:3]:
            log(f"  {name}: {len(data['urls'])} ä¸ªæ’­æ”¾æº (æ¥è‡ª: {', '.join(data['source_groups'])})")
    
    return result

def load_local_m3u():
    """åŠ è½½æœ¬åœ°BB.m3uæ–‡ä»¶"""
    try:
        if not os.path.exists(BB_FILE):
            log(f"âš ï¸  {BB_FILE} ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æ–‡ä»¶")
            default_content = """#EXTM3U
#EXTINF:-1 tvg-id="" tvg-name="æœ¬åœ°æµ‹è¯•1" tvg-logo="" group-title="æœ¬åœ°",æœ¬åœ°æµ‹è¯•1
http://example.com/local1
#EXTINF:-1 tvg-id="" tvg-name="æœ¬åœ°æµ‹è¯•2" tvg-logo="" group-title="æœ¬åœ°",æœ¬åœ°æµ‹è¯•2
http://example.com/local2"""
            with open(BB_FILE, 'w', encoding='utf-8') as f:
                f.write(default_content)
            return default_content
        
        with open(BB_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        log(f"âœ… åŠ è½½æœ¬åœ°æ–‡ä»¶æˆåŠŸï¼Œ{len(content.splitlines())} è¡Œ")
        return content
    except Exception as e:
        log(f"âŒ åŠ è½½æœ¬åœ°æ–‡ä»¶å¤±è´¥: {e}")
        return "#EXTM3U\n"

def generate_m3u_content(local_content, channel_dict):
    """ç”Ÿæˆæœ€ç»ˆçš„M3Uå†…å®¹ï¼ˆæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼‰"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    output_lines = [
        "#EXTM3U",
        f"# CC.m3u - è‡ªåŠ¨ç”Ÿæˆï¼ˆé¢‘é“æºåˆå¹¶ç‰ˆï¼‰",
        f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
        f"# æºåœ°å€: {SOURCE_URL}",
        f"# æå–åˆ†ç»„: {', '.join(SOURCE_GROUPS)} â†’ {TARGET_GROUP}",
        f"# å”¯ä¸€é¢‘é“æ•°: {len(channel_dict)}",
        f"# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ",
        ""
    ]
    
    # æ·»åŠ æœ¬åœ°å†…å®¹
    if local_content and local_content.strip():
        output_lines.append("#" + "=" * 60)
        output_lines.append("# æœ¬åœ°é¢‘é“")
        output_lines.append("#" + "=" * 60)
        output_lines.append("")
        
        local_lines = local_content.split('\n')
        for line in local_lines:
            if line.strip() == "#EXTM3U" and len(output_lines) > 8:
                continue
            output_lines.append(line)
        
        output_lines.append("")
    
    # æ·»åŠ æ¸¯æ¾³å°é¢‘é“ï¼ˆæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼‰
    if channel_dict:
        output_lines.append("#" + "=" * 60)
        output_lines.append(f"# {TARGET_GROUP} (åˆå¹¶è‡ª: {', '.join(SOURCE_GROUPS)})")
        output_lines.append("# è¯´æ˜ï¼šæ¯ä¸ªé¢‘é“å¯èƒ½åŒ…å«å¤šä¸ªæ’­æ”¾åœ°å€ï¼Œæ’­æ”¾å™¨ä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨æº")
        output_lines.append("#" + "=" * 60)
        output_lines.append("")
        
        for i, (channel_name, data) in enumerate(channel_dict.items(), 1):
            # EXTINF è¡Œ
            extinf = f'#EXTINF:-1 tvg-id="{data["tvg_id"]}" tvg-name="{data["tvg_name"]}" tvg-logo="{data["logo"]}" group-title="{TARGET_GROUP}",{channel_name}'
            output_lines.append(extinf)
            
            # å¤šä¸ªæ’­æ”¾åœ°å€ï¼ˆæ¯ä¸ªåœ°å€ä¸€è¡Œï¼‰
            for url in data['urls']:
                output_lines.append(url)
            
            # æ¯3ä¸ªé¢‘é“åŠ ä¸€ä¸ªç©ºè¡Œï¼ˆç¾è§‚ï¼‰
            if i % 3 == 0 and i < len(channel_dict):
                output_lines.append("")
        
        # ç§»é™¤æœ€åçš„ç©ºè¡Œï¼ˆå¦‚æœæœ‰ï¼‰
        while output_lines and output_lines[-1] == "":
            output_lines.pop()
    
    # ç»Ÿè®¡ä¿¡æ¯
    output_lines.append("")
    output_lines.append("#" + "=" * 60)
    output_lines.append("# ç»Ÿè®¡ä¿¡æ¯")
    local_channels = len([l for l in local_content.split('\n') if l.startswith('#EXTINF')])
    total_urls = sum(len(ch['urls']) for ch in channel_dict.values())
    output_lines.append(f"# æœ¬åœ°é¢‘é“æ•°: {local_channels}")
    output_lines.append(f"# æ¸¯æ¾³å°å”¯ä¸€é¢‘é“æ•°: {len(channel_dict)}")
    output_lines.append(f"# æ¸¯æ¾³å°æ’­æ”¾æºæ€»æ•°: {total_urls}")
    output_lines.append(f"# æ›´æ–°æ—¶é—´: {timestamp}")
    output_lines.append("# è¯´æ˜ï¼šç›¸åŒé¢‘é“çš„å¤šä¸ªæ’­æ”¾åœ°å€å·²åˆå¹¶ï¼Œæ’­æ”¾å™¨ä¼šå°è¯•æ‰€æœ‰åœ°å€ç›´åˆ°æˆåŠŸ")
    output_lines.append("#" + "=" * 60)
    
    return '\n'.join(output_lines)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    log("å¼€å§‹ç”Ÿæˆ CC.m3uï¼ˆé¢‘é“æºåˆå¹¶ç‰ˆï¼‰...")
    print("=" * 70)
    
    try:
        # 1. ä¸‹è½½æºæ•°æ®
        source_content = download_source()
        if not source_content:
            log("âŒ æ— æ³•è·å–æºæ•°æ®ï¼Œé€€å‡º")
            return
        
        # 2. æå–å¹¶åˆå¹¶é¢‘é“
        channel_dict = extract_and_merge_channels(source_content)
        
        if not channel_dict:
            log("âš ï¸  æœªæå–åˆ°ä»»ä½•é¢‘é“ï¼Œæ£€æŸ¥æºæ•°æ®æ ¼å¼")
            # æ˜¾ç¤ºå‰5ä¸ªåˆ†ç»„ä¾›è°ƒè¯•
            lines = source_content.split('\n')
            log("æºæ•°æ®ä¸­çš„åˆ†ç»„:")
            count = 0
            for line in lines:
                if '#genre#' in line and count < 5:
                    log(f"  - {line}")
                    count += 1
        
        # 3. åŠ è½½æœ¬åœ°æ–‡ä»¶
        local_content = load_local_m3u()
        
        # 4. ç”Ÿæˆå†…å®¹
        m3u_content = generate_m3u_content(local_content, channel_dict)
        
        # 5. ä¿å­˜æ–‡ä»¶
        with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='\n') as f:
            f.write(m3u_content)
        
        # 6. éªŒè¯ç»“æœ
        if os.path.exists(OUTPUT_FILE):
            file_size = os.path.getsize(OUTPUT_FILE)
            line_count = m3u_content.count('\n') + 1
            
            print("\n" + "=" * 70)
            log("âœ… CC.m3u ç”ŸæˆæˆåŠŸ!")
            log(f"   æ–‡ä»¶ä½ç½®: {os.path.abspath(OUTPUT_FILE)}")
            log(f"   æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            log(f"   æ€»è¡Œæ•°: {line_count}")
            log(f"   å”¯ä¸€é¢‘é“æ•°: {len(channel_dict)}")
            
            # æ˜¾ç¤ºåˆå¹¶ç¤ºä¾‹
            print("\nğŸ“‹ é¢‘é“åˆå¹¶ç¤ºä¾‹:")
            print("-" * 70)
            for name, data in list(channel_dict.items())[:2]:
                print(f'{data["tvg_name"]} ({len(data["urls"])}ä¸ªæ’­æ”¾æº):')
                for url in data['urls'][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªURL
                    print(f"  {url[:80]}..." if len(url) > 80 else f"  {url}")
                if len(data['urls']) > 2:
                    print(f"  ... è¿˜æœ‰{len(data['urls'])-2}ä¸ªæ’­æ”¾æº")
                print()
            print("-" * 70)
            
            # æ˜¾ç¤ºå®é™…æ–‡ä»¶å†…å®¹ç¤ºä¾‹
            print("\nğŸ“„ ç”Ÿæˆæ–‡ä»¶æ ¼å¼ç¤ºä¾‹:")
            print("-" * 50)
            lines = m3u_content.split('\n')
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤šæºé¢‘é“çš„éƒ¨åˆ†
            for i, line in enumerate(lines):
                if line.startswith('#EXTINF') and i+1 < len(lines) and lines[i+1].startswith('http'):
                    if i+2 < len(lines) and lines[i+2].startswith('http'):
                        # è¿™æ˜¯ä¸€ä¸ªå¤šæºé¢‘é“
                        print(lines[i])
                        print(lines[i+1])
                        print(lines[i+2])
                        if i+3 < len(lines) and lines[i+3].startswith('http'):
                            print(lines[i+3])
                        print("...")
                        break
            print("-" * 50)
            
        else:
            log("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
    
    except Exception as e:
        log(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("=" * 70)
    log("æ‰§è¡Œå®Œæˆ")
    print("=" * 70)

if __name__ == "__main__":
    main()
