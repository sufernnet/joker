#!/usr/bin/env python3
"""
ä» Cloudflare ä»£ç†é¡µé¢æå–å¹¶åˆå¹¶ M3U
ä»£ç†åœ°å€: https://smt-proxy.sufern001.workers.dev/
JULIåˆ†ç»„å·²æ”¹ä¸ºHKåˆ†ç»„
"""

import requests
import re
import os
from datetime import datetime

# é…ç½®
PROXY_URL = "https://smt-proxy.sufern001.workers.dev/"
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def download_bb_m3u():
    """ä¸‹è½½BB.m3u"""
    try:
        log("ä¸‹è½½ BB.m3u...")
        response = requests.get(BB_URL, timeout=10)
        response.raise_for_status()
        log(f"âœ… BB.m3u ä¸‹è½½æˆåŠŸ ({len(response.text)} å­—ç¬¦)")
        return response.text
    except Exception as e:
        log(f"âŒ BB.m3u ä¸‹è½½å¤±è´¥: {e}")
        return ""

def extract_m3u_from_proxy():
    """ä»ä»£ç†é¡µé¢æå–M3Uå†…å®¹"""
    log("ä»ä»£ç†é¡µé¢æå–å†…å®¹...")
    
    try:
        # è·å–ä»£ç†é¡µé¢
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(PROXY_URL, headers=headers, timeout=15)
        response.raise_for_status()
        
        html_content = response.text
        log(f"ä»£ç†é¡µé¢è·å–æˆåŠŸ ({len(html_content)} å­—ç¬¦)")
        
        # æ–¹æ³•1ï¼šç›´æ¥æŸ¥æ‰¾M3Ué“¾æ¥
        m3u_links = re.findall(r'https?://[^\s"\']+\.m3u(?:\?[^\s"\']*)?', html_content, re.IGNORECASE)
        
        if m3u_links:
            log(f"æ‰¾åˆ° {len(m3u_links)} ä¸ªM3Ué“¾æ¥")
            # å°è¯•ä¸‹è½½ç¬¬ä¸€ä¸ªM3Ué“¾æ¥
            try:
                m3u_response = requests.get(m3u_links[0], timeout=10)
                if m3u_response.status_code == 200:
                    log(f"âœ… æˆåŠŸä¸‹è½½M3Uæ–‡ä»¶ ({len(m3u_response.text)} å­—ç¬¦)")
                    return m3u_response.text
            except Exception as e:
                log(f"ä¸‹è½½M3Ué“¾æ¥å¤±è´¥: {e}")
        
        # æ–¹æ³•2ï¼šæŸ¥æ‰¾å¯èƒ½åŒ…å«M3Uå†…å®¹çš„åŒºåŸŸ
        log("å°è¯•ç›´æ¥æå–M3Uå†…å®¹...")
        
        patterns = [
            r'(#EXTM3U.*?)(?:</pre>|</code>|</textarea>|$)',
            r'<pre[^>]*>(.*?#EXTM3U.*?)</pre>',
            r'<code[^>]*>(.*?#EXTM3U.*?)</code>',
            r'<textarea[^>]*>(.*?#EXTM3U.*?)</textarea>',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, html_content, re.DOTALL | re.IGNORECASE)
            if matches:
                log(f"æ‰¾åˆ°æ¨¡å¼åŒ¹é…: {len(matches)} å¤„")
                for match in matches:
                    content = match.strip()
                    if content.startswith('#EXTM3U'):
                        log(f"âœ… æ‰¾åˆ°æœ‰æ•ˆçš„M3Uå†…å®¹ ({len(content)} å­—ç¬¦)")
                        return content
        
        # æ–¹æ³•3ï¼šå¦‚æœé¡µé¢æ˜¯çº¯æ–‡æœ¬æ ¼å¼çš„M3U
        if html_content.startswith('#EXTM3U'):
            log(f"âœ… é¡µé¢æœ¬èº«å°±æ˜¯M3Uæ–‡ä»¶ ({len(html_content)} å­—ç¬¦)")
            return html_content
        
        # æ–¹æ³•4ï¼šæå–æ‰€æœ‰å¯èƒ½åŒ…å«é¢‘é“ä¿¡æ¯çš„è¡Œ
        log("å°è¯•æå–é¢‘é“ä¿¡æ¯è¡Œ...")
        lines = html_content.split('\n')
        m3u_content = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('#EXTINF:') or ('://' in line and not line.startswith('<')):
                m3u_content.append(line)
        
        if m3u_content:
            log(f"âœ… æå–åˆ° {len(m3u_content)} è¡Œé¢‘é“ä¿¡æ¯")
            return '#EXTM3U\n' + '\n'.join(m3u_content)
        
        log("âŒ æ— æ³•ä»é¡µé¢æå–M3Uå†…å®¹")
        # ä¿å­˜HTMLä¾›è°ƒè¯•
        with open("proxy_debug.html", "w", encoding="utf-8") as f:
            f.write(html_content[:2000])
        
        return ""
        
    except Exception as e:
        log(f"âŒ ä»ä»£ç†æå–å¤±è´¥: {e}")
        return ""

def extract_hk_channels(m3u_content):
    """ä»M3Uå†…å®¹ä¸­æå–JULIé¢‘é“å¹¶æ”¹ä¸ºHKåˆ†ç»„"""
    if not m3u_content:
        return []
    
    log("æå–JULIé¢‘é“å¹¶æ”¹ä¸ºHKåˆ†ç»„...")
    lines = m3u_content.split('\n')
    channels = []
    seen_channels = set()
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # å¯»æ‰¾åŒ…å«JULIçš„è¡Œï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        if 'JULI' in line.upper():
            # å‘å‰æ‰¾EXTINFè¡Œ
            extinf_line = None
            for j in range(max(0, i-3), i+1):
                if lines[j].strip().startswith('#EXTINF:'):
                    extinf_line = lines[j].strip()
                    break
            
            # å‘åæ‰¾URLè¡Œ
            url_line = None
            if extinf_line:
                for k in range(i+1, min(len(lines), i+4)):
                    test_line = lines[k].strip()
                    if test_line and not test_line.startswith('#') and '://' in test_line:
                        url_line = test_line
                        break
            
            # å¦‚æœæ‰¾åˆ°äº†EXTINFå’ŒURL
            if extinf_line and url_line:
                # ä¿®æ”¹é¢‘é“åç§°ï¼šæŠŠJULIæ”¹æˆHK
                new_extinf = extinf_line
                if 'JULI' in new_extinf.upper():
                    # ä½¿ç”¨æ­£åˆ™æ›¿æ¢æ‰€æœ‰JULIä¸ºHK
                    new_extinf = re.sub(r'JULI', 'HK', new_extinf, flags=re.IGNORECASE)
                
                # åˆ›å»ºé¢‘é“å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºå»é‡ï¼‰
                channel_id = f"{new_extinf}|{url_line}"
                
                if channel_id not in seen_channels:
                    seen_channels.add(channel_id)
                    channels.append((new_extinf, url_line))
        
        i += 1
    
    log(f"âœ… æå–åˆ° {len(channels)} ä¸ªHKé¢‘é“ï¼ˆåŸJULIé¢‘é“ï¼‰")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªé¢‘é“
    if channels:
        log("éƒ¨åˆ†HKé¢‘é“:")
        for idx, (extinf, url) in enumerate(channels[:3]):
            if ',' in extinf:
                name = extinf.split(',', 1)[1]
                log(f"  {idx+1}. {name[:60]}{'...' if len(name) > 60 else ''}")
    
    return channels

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹åˆå¹¶M3Uæ–‡ä»¶...")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_bb_m3u()
    if not bb_content:
        log("âŒ æ— æ³•ç»§ç»­ï¼ŒBB.m3uä¸‹è½½å¤±è´¥")
        return
    
    # 2. ä»ä»£ç†è·å–å†…å®¹
    proxy_content = extract_m3u_from_proxy()
    if not proxy_content:
        log("âš ï¸  æ— æ³•ä»ä»£ç†è·å–å†…å®¹ï¼Œåªä½¿ç”¨BB.m3u")
        hk_channels = []
    else:
        # 3. æå–HKé¢‘é“ï¼ˆåŸJULIé¢‘é“ï¼‰
        hk_channels = extract_hk_channels(proxy_content)
    
    # 4. åˆå¹¶å†…å®¹
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    output = f"""#EXTM3U
# è‡ªåŠ¨åˆå¹¶ M3U æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {timestamp}
# ä»£ç†æº: {PROXY_URL}
# JULIåˆ†ç»„å·²æ”¹ä¸ºHKåˆ†ç»„
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡å¼€å¤´çš„#EXTM3Uï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    for line in bb_lines:
        if line.strip() and not line.startswith('#EXTM3U'):
            output += line + '\n'
            if line.startswith('#EXTINF:'):
                bb_count += 1
    
    # æ·»åŠ HKé¢‘é“ï¼ˆåŸJULIé¢‘é“ï¼‰
    if hk_channels:
        output += f"\n# HK é¢‘é“ (åŸJULIé¢‘é“ï¼Œä»ä»£ç†æå–)\n"
        for extinf, url in hk_channels:
            output += extinf + '\n'
            output += url + '\n'
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    output += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# HK é¢‘é“æ•°: {len(hk_channels)} (åŸJULIé¢‘é“)
# æ€»é¢‘é“æ•°: {bb_count + len(hk_channels)}
# æ›´æ–°æ—¶é—´: {timestamp}
"""
    
    # 5. ä¿å­˜æ–‡ä»¶
    output_file = "CC.m3u"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(output)
    
    log(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
    log(f"ğŸ“ æ–‡ä»¶: {output_file}")
    log(f"ğŸ“ å¤§å°: {len(output)} å­—ç¬¦")
    log(f"ğŸ“º BBé¢‘é“: {bb_count}")
    log(f"ğŸ“º HKé¢‘é“: {len(hk_channels)} (åŸJULI)")
    log(f"ğŸ“º æ€»è®¡: {bb_count + len(hk_channels)}")

if __name__ == "__main__":
    main()
