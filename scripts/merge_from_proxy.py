#!/usr/bin/env python3
"""
M3Uæ–‡ä»¶åˆå¹¶è„šæœ¬ - ä»æ–°åœ°å€æŠ“å–å…¨ç½‘é€šæ¸¯æ¾³å°ç›´æ’­æº
1. ä¸‹è½½BB.m3uï¼ˆåŒ…å«EPGä¿¡æ¯ï¼‰
2. ä»æ–°åœ°å€æŠ“å–"å…¨ç½‘é€šæ¸¯æ¾³å°"ç›´æ’­æº
3. ä¸BBåˆå¹¶ç”ŸæˆCC.m3u
åŒ—äº¬æ—¶é—´æ¯å¤©6:00ã€18:00è‡ªåŠ¨è¿è¡Œ
"""

import requests
import re
import os
import time
from datetime import datetime

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
NEW_SOURCE_URL = "https://gh-proxy.org/https://raw.githubusercontent.com/Jsnzkpg/Jsnzkpg/Jsnzkpg/Jsnzkpg1"
OUTPUT_FILE = "CC.m3u"

# å¤‡é€‰EPGæºï¼ˆå¦‚æœä¸»è¦EPGå¤±æ•ˆï¼‰
BACKUP_EPG_URLS = [
    "https://epg.112114.xyz/pp.xml",  # BBçš„EPG
    "https://epg.946985.filegear-sg.me/t.xml.gz",
    "http://epg.51zmt.top:8000/e.xml"
]

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def test_epg_url(epg_url):
    """æµ‹è¯•EPG URLæ˜¯å¦å¯è®¿é—®"""
    try:
        log(f"æµ‹è¯•EPG: {epg_url}")
        headers = {
            'User-Agent': 'Mozilla/5.0',
            'Accept': '*/*'
        }
        
        # åªä¸‹è½½å‰1KBæ£€æŸ¥
        response = requests.get(epg_url, headers=headers, timeout=10, stream=True)
        
        if response.status_code == 200:
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '').lower()
            
            # è¯»å–å‰1KBæ£€æŸ¥
            chunk = response.raw.read(1024)
            text = chunk.decode('utf-8', errors='ignore')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯XMLæ ¼å¼
            if '<?xml' in text or '<tv' in text or '<programme' in text:
                log(f"âœ… EPGå¯ç”¨: {epg_url}")
                return True
            else:
                log(f"âš ï¸  EPGä¸æ˜¯XMLæ ¼å¼: {epg_url}")
                return False
        else:
            log(f"âŒ EPGä¸å¯è®¿é—®: {epg_url} (çŠ¶æ€ç : {response.status_code})")
            return False
            
    except Exception as e:
        log(f"âŒ EPGæµ‹è¯•å¤±è´¥ {epg_url}: {e}")
        return False

def get_best_epg_url(epg_urls):
    """è·å–æœ€ä½³çš„EPG URL"""
    log("å¯»æ‰¾æœ€ä½³EPGæº...")
    
    # æµ‹è¯•æ‰€æœ‰EPG
    working_epgs = []
    for epg_url in epg_urls:
        if test_epg_url(epg_url):
            working_epgs.append(epg_url)
    
    if working_epgs:
        # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        best_epg = working_epgs[0]
        log(f"âœ… é€‰æ‹©EPG: {best_epg}")
        log(f"   å…¶ä»–å¯ç”¨EPG: {len(working_epgs)-1}ä¸ª")
        return best_epg
    else:
        log("âš ï¸  æ²¡æœ‰å¯ç”¨çš„EPGæº")
        return None

def download_bb_m3u():
    """ä¸‹è½½BB.m3uå¹¶æå–EPG"""
    try:
        log("ä¸‹è½½BB.m3u...")
        response = requests.get(BB_URL, timeout=10)
        response.raise_for_status()
        
        bb_content = response.text
        log(f"âœ… BB.m3uä¸‹è½½æˆåŠŸ ({len(bb_content)} å­—ç¬¦)")
        
        return bb_content
        
    except Exception as e:
        log(f"âŒ BB.m3uä¸‹è½½å¤±è´¥: {e}")
        return None

def get_quanwangtong_gangaotai():
    """ä»æ–°åœ°å€æŠ“å–"å…¨ç½‘é€šæ¸¯æ¾³å°"ç›´æ’­æº"""
    try:
        log("ä»æ–°åœ°å€æŠ“å–å…¨ç½‘é€šæ¸¯æ¾³å°ç›´æ’­æº...")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://github.com/'
        }
        
        response = requests.get(NEW_SOURCE_URL, headers=headers, timeout=15)
        
        if response.status_code == 200:
            content = response.text
            
            if content and content.strip():
                log(f"âœ… è·å–åˆ°å†…å®¹ ({len(content)} å­—ç¬¦)")
                
                # æŸ¥æ‰¾"å…¨ç½‘é€šæ¸¯æ¾³å°"åˆ†ç»„
                if "å…¨ç½‘é€šæ¸¯æ¾³å°" in content:
                    log("âœ… æ‰¾åˆ°'å…¨ç½‘é€šæ¸¯æ¾³å°'åˆ†ç»„")
                    
                    # æå–è¯¥åˆ†ç»„çš„å†…å®¹
                    lines = content.split('\n')
                    in_target_group = False
                    extracted_lines = []
                    
                    for line in lines:
                        line = line.rstrip()
                        
                        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡åˆ†ç»„
                        if 'group-title="å…¨ç½‘é€šæ¸¯æ¾³å°"' in line or 'group-title=".*å…¨ç½‘é€šæ¸¯æ¾³å°.*"' in line:
                            in_target_group = True
                        
                        # å¦‚æœåœ¨ç›®æ ‡åˆ†ç»„ä¸­ï¼Œæ”¶é›†å†…å®¹ç›´åˆ°é‡åˆ°å…¶ä»–åˆ†ç»„
                        if in_target_group:
                            # æ£€æŸ¥æ˜¯å¦é‡åˆ°å…¶ä»–åˆ†ç»„ï¼ˆä½†ä¸æ˜¯åŒä¸€åˆ†ç»„ï¼‰
                            if line.startswith('#EXTINF:') and 'group-title=' in line:
                                # å¦‚æœé‡åˆ°æ–°çš„åˆ†ç»„ä½†ä¸æ˜¯å…¨ç½‘é€šæ¸¯æ¾³å°ï¼Œåˆ™åœæ­¢
                                if 'å…¨ç½‘é€šæ¸¯æ¾³å°' not in line:
                                    break
                            
                            extracted_lines.append(line)
                    
                    # ç¡®ä¿åŒ…å«M3Uå¤´
                    if extracted_lines and not extracted_lines[0].startswith('#EXTM3U'):
                        extracted_lines.insert(0, '#EXTM3U')
                    
                    extracted_content = '\n'.join(extracted_lines)
                    log(f"âœ… æå–åˆ°å…¨ç½‘é€šæ¸¯æ¾³å°å†…å®¹ ({len(extracted_content)} å­—ç¬¦)")
                    return extracted_content
                else:
                    log("âš ï¸  æœªæ‰¾åˆ°'å…¨ç½‘é€šæ¸¯æ¾³å°'åˆ†ç»„")
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›å…¨éƒ¨å†…å®¹
                    return content
            else:
                log("âš ï¸  å†…å®¹ä¸ºç©º")
        else:
            log(f"âŒ æ–°åœ°å€è¿”å›é”™è¯¯: {response.status_code}")
            
    except Exception as e:
        log(f"âŒ ä»æ–°åœ°å€æŠ“å–å¤±è´¥: {e}")
    
    return None

def extract_epg_urls(content):
    """ä»å†…å®¹ä¸­æå–EPG URL"""
    epg_urls = []
    
    if not content:
        return epg_urls
    
    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„EPG URLæ¨¡å¼
    patterns = [
        r'url-tvg="([^"]+)"',
        r'x-tvg-url="([^"]+)"',
        r'epg-url="([^"]+)"',
        r'#EXTM3U.*?http[^"\s]+',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        for match in matches:
            if 'http' in match and match not in epg_urls:
                epg_urls.append(match)
                log(f"æ‰¾åˆ°EPG: {match}")
    
    return epg_urls

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹åˆå¹¶M3Uæ–‡ä»¶...")
    
    # æ˜¾ç¤ºå½“å‰æ—¶é—´ï¼ˆç”¨äºè°ƒè¯•å®šæ—¶ä»»åŠ¡ï¼‰
    current_time = datetime.now()
    log(f"å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    log(f"ä¸‹æ¬¡è¿è¡Œ: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 18:00")
    log(f"æ–°æºåœ°å€: {NEW_SOURCE_URL}")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_bb_m3u()
    if not bb_content:
        log("âŒ æ— æ³•ç»§ç»­ï¼ŒBB.m3uä¸‹è½½å¤±è´¥")
        return
    
    # 2. ä»æ–°åœ°å€æŠ“å–"å…¨ç½‘é€šæ¸¯æ¾³å°"ç›´æ’­æº
    new_source_content = get_quanwangtong_gangaotai()
    
    # 3. æ”¶é›†æ‰€æœ‰EPGæº
    epg_urls = []
    
    # ä»BB.m3uæå–EPG
    bb_epg_match = re.search(r'url-tvg="([^"]+)"', bb_content)
    if bb_epg_match:
        epg_urls.append(bb_epg_match.group(1))
        log(f"âœ… æ‰¾åˆ°BB EPG: {bb_epg_match.group(1)}")
    
    # ä»æ–°æºå†…å®¹æå–EPG
    if new_source_content:
        new_epgs = extract_epg_urls(new_source_content)
        for epg in new_epgs:
            if epg not in epg_urls:
                epg_urls.append(epg)
    
    # æ·»åŠ å¤‡é€‰EPG
    for backup_epg in BACKUP_EPG_URLS:
        if backup_epg not in epg_urls:
            epg_urls.append(backup_epg)
    
    log(f"æ‰¾åˆ° {len(epg_urls)} ä¸ªEPGæº")
    
    # 4. è·å–æœ€ä½³EPG
    best_epg = get_best_epg_url(epg_urls)
    
    # 5. è§£ææ–°æºå†…å®¹ï¼ˆå…¨ç½‘é€šæ¸¯æ¾³å°ï¼‰
    new_channels_count = 0
    new_channels_content = ""
    
    if new_source_content:
        lines = new_source_content.split('\n')
        in_m3u = False
        collecting = False
        
        for line in lines:
            line = line.rstrip()
            if not line:
                continue
            
            if line.startswith('#EXTM3U'):
                in_m3u = True
                # è·³è¿‡M3Uå¤´ï¼Œæˆ‘ä»¬ä¼šåœ¨åé¢æ·»åŠ è‡ªå·±çš„
                continue
            
            if in_m3u:
                # æ£€æŸ¥æ˜¯å¦æ˜¯"å…¨ç½‘é€šæ¸¯æ¾³å°"åˆ†ç»„
                if line.startswith('#EXTINF:'):
                    if 'å…¨ç½‘é€šæ¸¯æ¾³å°' in line:
                        collecting = True
                    else:
                        collecting = False
                
                if collecting:
                    new_channels_content += line + '\n'
                    if line.startswith('#EXTINF:'):
                        new_channels_count += 1
    
    # 6. æ„å»ºM3Uå†…å®¹
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # M3Uå¤´éƒ¨ï¼ˆä½¿ç”¨æœ€ä½³EPGï¼‰
    if best_epg:
        m3u_header = f'#EXTM3U url-tvg="{best_epg}"\n'
        log(f"âœ… ä½¿ç”¨EPG: {best_epg}")
    else:
        m3u_header = '#EXTM3U\n'
        log("âš ï¸  æœªæ‰¾åˆ°å¯ç”¨EPG")
    
    output = m3u_header + f"""# è‡ªåŠ¨åˆå¹¶ M3U æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
# BBæº: {BB_URL}
# æ–°æºåœ°å€: {NEW_SOURCE_URL}
# æŠ“å–åˆ†ç»„: å…¨ç½‘é€šæ¸¯æ¾³å°
# EPGæº: {best_epg if best_epg else 'æ— å¯ç”¨EPG'}
# æµ‹è¯•çš„EPGæº: {len(epg_urls)} ä¸ª
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    skip_first = True
    
    for line in bb_lines:
        line = line.rstrip()
        if not line:
            continue
        
        if skip_first and line.startswith('#EXTM3U'):
            skip_first = False
            continue
        
        output += line + '\n'
        if line.startswith('#EXTINF:'):
            bb_count += 1
    
    # æ·»åŠ å…¨ç½‘é€šæ¸¯æ¾³å°é¢‘é“
    if new_channels_content:
        output += f"\n# å…¨ç½‘é€šæ¸¯æ¾³å°é¢‘é“\n"
        output += f"# æ¥è‡ª: {NEW_SOURCE_URL}\n"
        output += new_channels_content
    
    # æ·»åŠ EPGä¿¡æ¯è¯´æ˜
    if epg_urls:
        output += f"""
# EPGä¿¡æ¯
# ä½¿ç”¨EPG: {best_epg if best_epg else 'æ— '}
# æµ‹è¯•çš„EPGæº ({len(epg_urls)}ä¸ª):"""
        for i, epg in enumerate(epg_urls, 1):
            status = "âœ…" if epg == best_epg else "  "
            output += f"\n#   {status} {epg}"
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    output += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# å…¨ç½‘é€šæ¸¯æ¾³å° é¢‘é“æ•°: {new_channels_count}
# æ€»é¢‘é“æ•°: {bb_count + new_channels_count}
# EPGçŠ¶æ€: {'âœ… æ­£å¸¸' if best_epg else 'âŒ æ— å¯ç”¨EPG'}
# æ›´æ–°æ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# æ›´æ–°é¢‘ç‡: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
"""
    
    # 7. ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(output)
    
    log(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
    log(f"ğŸ“ æ–‡ä»¶: {OUTPUT_FILE}")
    log(f"ğŸ“ å¤§å°: {len(output)} å­—ç¬¦")
    log(f"ğŸ“¡ EPG: {best_epg if best_epg else 'æ— å¯ç”¨EPG'}")
    log(f"ğŸ“º BBé¢‘é“: {bb_count}")
    log(f"ğŸ“º å…¨ç½‘é€šæ¸¯æ¾³å°é¢‘é“: {new_channels_count}")
    log(f"ğŸ“º æ€»è®¡: {bb_count + new_channels_count}")
    log(f"ğŸ•’ ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 18:00")

if __name__ == "__main__":
    main()
