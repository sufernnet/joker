#!/usr/bin/env python3
"""
M3Uæ–‡ä»¶åˆå¹¶è„šæœ¬ - ä»æ–°åœ°å€æŠ“å–ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°ç›´æ’­æº
1. ä¸‹è½½BB.m3uï¼ˆåŒ…å«EPGä¿¡æ¯ï¼‰
2. ä»æ–°åœ°å€æŠ“å–"ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°"ç›´æ’­æº
3. ä¸BBåˆå¹¶ç”ŸæˆCC.m3u
åŒ—äº¬æ—¶é—´æ¯å¤©6:00ã€18:00è‡ªåŠ¨è¿è¡Œ
"""

import requests
import re
import os
import time
from datetime import datetime

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
NEW_SOURCE_URL = "https://gh-proxy.org/https://raw.githubusercontent.com/Jsnzkpg/Jsnzkpg/Jsnzkpg/Jsnzkpg1"
TARGET_GROUPS = ["ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°", "å…¨ç½‘é€šæ¸¯æ¾³å°", "æ¸¯æ¾³å°", "Hongkong & Taiwan", "HK & TW"]
OUTPUT_FILE = "CC.m3u"

# å¤‡é€‰EPGæºï¼ˆå¦‚æœä¸»è¦EPGå¤±æ•ˆï¼‰
BACKUP_EPG_URLS = [
    "https://epg.112114.xyz/pp.xml",  # BBçš„EPG
    "https://epg.946985.filegear-sg.me/t.xml.gz",
    "http://epg.51zmt.top:8000/e.xml"
]

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def test_epg_url(epg_url):
    """æµ‹è¯•EPG URLæ˜¯å¦å¯è®¿é—®"""
    try:
        log(f"æµ‹è¯•EPG: {epg_url}")
        headers = {
            'User-Agent': 'Mozilla/5.0',
            'Accept': '*/*'
        }
        
        # åªä¸‹è½½å‰1KBæ£€æŸ¥
        response = requests.get(epg_url, headers=headers, timeout=10, stream=True)
        
        if response.status_code == 200:
            # è¯»å–å‰1KBæ£€æŸ¥
            chunk = response.raw.read(1024)
            text = chunk.decode('utf-8', errors='ignore')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯XMLæ ¼å¼
            if '<?xml' in text or '<tv' in text or '<programme' in text:
                log(f"âœ… EPGå¯ç”¨: {epg_url}")
                return True
            else:
                log(f"âš ï¸  EPGä¸æ˜¯XMLæ ¼å¼: {epg_url}")
                return False
        else:
            log(f"âŒ EPGä¸å¯è®¿é—®: {epg_url} (çŠ¶æ€ç : {response.status_code})")
            return False
            
    except Exception as e:
        log(f"âŒ EPGæµ‹è¯•å¤±è´¥ {epg_url}: {e}")
        return False

def get_best_epg_url(epg_urls):
    """è·å–æœ€ä½³çš„EPG URL"""
    log("å¯»æ‰¾æœ€ä½³EPGæº...")
    
    # æµ‹è¯•æ‰€æœ‰EPG
    working_epgs = []
    for epg_url in epg_urls:
        if test_epg_url(epg_url):
            working_epgs.append(epg_url)
    
    if working_epgs:
        # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        best_epg = working_epgs[0]
        log(f"âœ… é€‰æ‹©EPG: {best_epg}")
        log(f"   å…¶ä»–å¯ç”¨EPG: {len(working_epgs)-1}ä¸ª")
        return best_epg
    else:
        log("âš ï¸  æ²¡æœ‰å¯ç”¨çš„EPGæº")
        return None

def download_bb_m3u():
    """ä¸‹è½½BB.m3uå¹¶æå–EPG"""
    try:
        log("ä¸‹è½½BB.m3u...")
        response = requests.get(BB_URL, timeout=10)
        response.raise_for_status()
        
        bb_content = response.text
        log(f"âœ… BB.m3uä¸‹è½½æˆåŠŸ ({len(bb_content)} å­—ç¬¦)")
        
        return bb_content
        
    except Exception as e:
        log(f"âŒ BB.m3uä¸‹è½½å¤±è´¥: {e}")
        return None

def get_new_source_content():
    """ä»æ–°åœ°å€è·å–å†…å®¹å¹¶åˆ†æ"""
    try:
        log(f"ä»æ–°åœ°å€è·å–å†…å®¹: {NEW_SOURCE_URL}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://github.com/'
        }
        
        response = requests.get(NEW_SOURCE_URL, headers=headers, timeout=15)
        
        if response.status_code == 200:
            content = response.text
            
            if content and content.strip():
                log(f"âœ… è·å–åˆ°å†…å®¹ ({len(content)} å­—ç¬¦)")
                
                # åˆ†æå†…å®¹ç»“æ„
                analyze_content_structure(content)
                
                # å°è¯•æå–ç›®æ ‡åˆ†ç»„
                extracted_channels = extract_target_groups_channels(content)
                
                if extracted_channels:
                    # æ„å»ºM3Uå†…å®¹
                    m3u_content = "#EXTM3U\n" + "\n".join(extracted_channels)
                    log(f"âœ… æˆåŠŸæå–åˆ° {len(extracted_channels)//2} ä¸ªæ¸¯æ¾³å°ç›¸å…³é¢‘é“")
                    return m3u_content
                else:
                    log("âš ï¸  æœªèƒ½æå–åˆ°æ¸¯æ¾³å°ç›¸å…³é¢‘é“")
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›®æ ‡åˆ†ç»„ï¼Œä½†å†…å®¹çœ‹èµ·æ¥æ˜¯M3Uæ ¼å¼ï¼Œå°è¯•è¿”å›éƒ¨åˆ†å†…å®¹
                    if content.startswith('#EXTM3U'):
                        lines = content.split('\n')
                        # å°è¯•è¿”å›å‰100ä¸ªé¢‘é“ç”¨äºæµ‹è¯•
                        test_channels = []
                        count = 0
                        current_extinf = None
                        
                        for line in lines:
                            line = line.rstrip()
                            if not line:
                                continue
                                
                            if line.startswith('#EXTM3U'):
                                continue
                                
                            if line.startswith('#EXTINF:'):
                                current_extinf = line
                            elif current_extinf and '://' in line and not line.startswith('#'):
                                test_channels.append(current_extinf)
                                test_channels.append(line)
                                current_extinf = None
                                count += 1
                                
                                if count >= 50:  # åªå–50ä¸ªç”¨äºæµ‹è¯•
                                    break
                        
                        if test_channels:
                            m3u_content = "#EXTM3U\n" + "\n".join(test_channels)
                            log(f"âœ… è¿”å›å‰ {len(test_channels)//2} ä¸ªé¢‘é“ç”¨äºæµ‹è¯•")
                            return m3u_content
                    
                    return content[:5000]  # è¿”å›å‰5000å­—ç¬¦ç”¨äºè°ƒè¯•
            else:
                log("âš ï¸  å†…å®¹ä¸ºç©º")
        else:
            log(f"âŒ æ–°åœ°å€è¿”å›é”™è¯¯: {response.status_code}")
            
    except Exception as e:
        log(f"âŒ ä»æ–°åœ°å€æŠ“å–å¤±è´¥: {e}")
    
    return None

def analyze_content_structure(content):
    """åˆ†æM3Uå†…å®¹ç»“æ„"""
    log("åˆ†æå†…å®¹ç»“æ„...")
    
    if not content:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯M3Uæ ¼å¼
    if content.startswith('#EXTM3U'):
        log("âœ… å†…å®¹ä¸ºM3Uæ ¼å¼")
    else:
        log("âš ï¸  å†…å®¹ä¸æ˜¯æ ‡å‡†M3Uæ ¼å¼")
    
    # æŸ¥æ‰¾æ‰€æœ‰åˆ†ç»„
    groups = re.findall(r'group-title="([^"]+)"', content)
    if groups:
        unique_groups = list(set(groups))
        log(f"å‘ç° {len(unique_groups)} ä¸ªå”¯ä¸€åˆ†ç»„")
        
        # æ˜¾ç¤ºæ‰€æœ‰åˆ†ç»„
        log("æ‰€æœ‰åˆ†ç»„åˆ—è¡¨:")
        for i, group in enumerate(sorted(unique_groups), 1):
            count = groups.count(group)
            log(f"  {i:2d}. {group} ({count}ä¸ªé¢‘é“)")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡åˆ†ç»„
            for target in TARGET_GROUPS:
                if target in group:
                    log(f"     âš ï¸  åŒ¹é…åˆ°ç›®æ ‡åˆ†ç»„å…³é”®è¯: {target}")
    
    # ç»Ÿè®¡é¢‘é“æ€»æ•°
    extinf_count = content.count('#EXTINF:')
    log(f"æ€»é¢‘é“æ•°: {extinf_count}")
    
    # æŸ¥æ‰¾EPGä¿¡æ¯
    epg_patterns = [
        (r'url-tvg="([^"]+)"', 'url-tvg'),
        (r'x-tvg-url="([^"]+)"', 'x-tvg-url'),
    ]
    
    for pattern, name in epg_patterns:
        matches = re.findall(pattern, content)
        if matches:
            log(f"æ‰¾åˆ° {len(matches)} ä¸ª{name} EPG")
            for match in matches:
                log(f"  - {match}")

def extract_target_groups_channels(content):
    """æå–æ‰€æœ‰ç›®æ ‡åˆ†ç»„çš„é¢‘é“"""
    channels = []
    
    if not content:
        return channels
    
    lines = content.split('\n')
    current_extinf = None
    
    for line in lines:
        line = line.rstrip()
        if not line:
            continue
            
        if line.startswith('#EXTINF:'):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡åˆ†ç»„å…³é”®è¯
            is_target = False
            for target in TARGET_GROUPS:
                if target in line:
                    is_target = True
                    break
            
            if is_target:
                current_extinf = line
            else:
                current_extinf = None
                
        elif current_extinf and '://' in line and not line.startswith('#'):
            # è¿™æ˜¯ä¸€ä¸ªé¢‘é“URLï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            channels.append(current_extinf)
            channels.append(line)
            current_extinf = None
    
    return channels

def extract_epg_urls(content):
    """ä»å†…å®¹ä¸­æå–EPG URL"""
    epg_urls = []
    
    if not content:
        return epg_urls
    
    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„EPG URLæ¨¡å¼
    patterns = [
        r'url-tvg="([^"]+)"',
        r'x-tvg-url="([^"]+)"',
        r'tvg-url="([^"]+)"',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        for match in matches:
            if 'http' in match and match not in epg_urls:
                epg_urls.append(match)
    
    return epg_urls

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹åˆå¹¶M3Uæ–‡ä»¶...")
    
    # æ˜¾ç¤ºå½“å‰æ—¶é—´ï¼ˆç”¨äºè°ƒè¯•å®šæ—¶ä»»åŠ¡ï¼‰
    current_time = datetime.now()
    log(f"å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    log(f"ä¸‹æ¬¡è¿è¡Œ: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 18:00")
    log(f"æ–°æºåœ°å€: {NEW_SOURCE_URL}")
    log(f"ç›®æ ‡åˆ†ç»„å…³é”®è¯: {', '.join(TARGET_GROUPS)}")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_bb_m3u()
    if not bb_content:
        log("âŒ æ— æ³•ç»§ç»­ï¼ŒBB.m3uä¸‹è½½å¤±è´¥")
        return
    
    # 2. ä»æ–°åœ°å€æŠ“å–å†…å®¹
    new_source_content = get_new_source_content()
    
    # 3. æ”¶é›†æ‰€æœ‰EPGæº
    epg_urls = []
    
    # ä»BB.m3uæå–EPG
    bb_epg_match = re.search(r'url-tvg="([^"]+)"', bb_content)
    if bb_epg_match:
        epg_urls.append(bb_epg_match.group(1))
        log(f"âœ… æ‰¾åˆ°BB EPG: {bb_epg_match.group(1)}")
    
    # ä»æ–°æºå†…å®¹æå–EPG
    if new_source_content:
        new_epgs = extract_epg_urls(new_source_content)
        for epg in new_epgs:
            if epg not in epg_urls:
                epg_urls.append(epg)
    
    # æ·»åŠ å¤‡é€‰EPG
    for backup_epg in BACKUP_EPG_URLS:
        if backup_epg not in epg_urls:
            epg_urls.append(backup_epg)
    
    log(f"æ‰¾åˆ° {len(epg_urls)} ä¸ªEPGæº")
    
    # 4. è·å–æœ€ä½³EPG
    best_epg = get_best_epg_url(epg_urls)
    
    # 5. è§£ææ–°æºå†…å®¹
    new_channels_count = 0
    new_channels_content = ""
    
    if new_source_content:
        # è§£æé¢‘é“
        lines = new_source_content.split('\n')
        current_extinf = None
        
        for line in lines:
            line = line.rstrip()
            if not line:
                continue
            
            if line.startswith('#EXTM3U'):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢‘é“ä¿¡æ¯
            if line.startswith('#EXTINF:'):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡åˆ†ç»„å…³é”®è¯
                is_target = False
                for target in TARGET_GROUPS:
                    if target in line:
                        is_target = True
                        break
                
                if is_target:
                    current_extinf = line
                    new_channels_content += line + '\n'
                    new_channels_count += 1
                else:
                    current_extinf = None
                    
            elif current_extinf and '://' in line and not line.startswith('#'):
                new_channels_content += line + '\n'
                current_extinf = None
    
    # 6. æ„å»ºM3Uå†…å®¹
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # M3Uå¤´éƒ¨ï¼ˆä½¿ç”¨æœ€ä½³EPGï¼‰
    if best_epg:
        m3u_header = f'#EXTM3U url-tvg="{best_epg}"\n'
        log(f"âœ… ä½¿ç”¨EPG: {best_epg}")
    else:
        m3u_header = '#EXTM3U\n'
        log("âš ï¸  æœªæ‰¾åˆ°å¯ç”¨EPG")
    
    output = m3u_header + f"""# è‡ªåŠ¨åˆå¹¶ M3U æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
# BBæº: {BB_URL}
# æ–°æºåœ°å€: {NEW_SOURCE_URL}
# ç›®æ ‡åˆ†ç»„å…³é”®è¯: {', '.join(TARGET_GROUPS)}
# EPGæº: {best_epg if best_epg else 'æ— å¯ç”¨EPG'}
# æµ‹è¯•çš„EPGæº: {len(epg_urls)} ä¸ª
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    skip_first = True
    
    for line in bb_lines:
        line = line.rstrip()
        if not line:
            continue
        
        if skip_first and line.startswith('#EXTM3U'):
            skip_first = False
            continue
        
        output += line + '\n'
        if line.startswith('#EXTINF:'):
            bb_count += 1
    
    # æ·»åŠ æ¸¯æ¾³å°ç›¸å…³é¢‘é“
    if new_channels_content:
        output += f"\n# æ¸¯æ¾³å°ç›¸å…³é¢‘é“ (åŒ…å«å…³é”®è¯: {', '.join(TARGET_GROUPS)})\n"
        output += f"# æ¥è‡ª: {NEW_SOURCE_URL}\n"
        output += new_channels_content
    else:
        log("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ¸¯æ¾³å°ç›¸å…³é¢‘é“")
    
    # æ·»åŠ EPGä¿¡æ¯è¯´æ˜
    if epg_urls:
        output += f"""
# EPGä¿¡æ¯
# ä½¿ç”¨EPG: {best_epg if best_epg else 'æ— '}
# æµ‹è¯•çš„EPGæº ({len(epg_urls)}ä¸ª):"""
        for i, epg in enumerate(epg_urls, 1):
            status = "âœ…" if epg == best_epg else "  "
            output += f"\n#   {status} {epg}"
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    output += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# æ¸¯æ¾³å°ç›¸å…³é¢‘é“æ•°: {new_channels_count}
# æ€»é¢‘é“æ•°: {bb_count + new_channels_count}
# EPGçŠ¶æ€: {'âœ… æ­£å¸¸' if best_epg else 'âŒ æ— å¯ç”¨EPG'}
# æ›´æ–°æ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# æ›´æ–°é¢‘ç‡: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
"""
    
    # 7. ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(output)
    
    log(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
    log(f"ğŸ“ æ–‡ä»¶: {OUTPUT_FILE}")
    log(f"ğŸ“ å¤§å°: {len(output)} å­—ç¬¦")
    log(f"ğŸ“¡ EPG: {best_epg if best_epg else 'æ— å¯ç”¨EPG'}")
    log(f"ğŸ“º BBé¢‘é“: {bb_count}")
    log(f"ğŸ“º æ¸¯æ¾³å°ç›¸å…³é¢‘é“: {new_channels_count}")
    log(f"ğŸ“º æ€»è®¡: {bb_count + new_channels_count}")
    log(f"ğŸ•’ ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 18:00")
    
    # å¦‚æœæ²¡æœ‰ä»»ä½•æ¸¯æ¾³å°é¢‘é“ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
    if new_channels_count == 0 and new_source_content:
        log("\nâš ï¸  è°ƒè¯•ä¿¡æ¯ï¼š")
        log(f"æ–°æºå†…å®¹é•¿åº¦: {len(new_source_content)}")
        log(f"å‰500å­—ç¬¦: {new_source_content[:500]}")
        
        # æ£€æŸ¥å‰å‡ è¡Œ
        lines = new_source_content.split('\n')
        log(f"å‰10è¡Œ:")
        for i, line in enumerate(lines[:10], 1):
            log(f"  {i}: {line}")

if __name__ == "__main__":
    main()
