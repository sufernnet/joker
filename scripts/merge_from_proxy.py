#!/usr/bin/env python3
"""
M3Uæ–‡ä»¶åˆå¹¶è„šæœ¬
1. å…ˆæ›´æ–°è®¢é˜…ç¡®ä¿è·å–æœ‰æ•ˆç›´æ’­
2. ä»æ›´æ–°çš„è®¢é˜…ä¸­æå–JULIé¢‘é“å¹¶æ”¹ä¸ºHKåˆ†ç»„
3. åˆå¹¶BB.m3uå’Œæå–çš„HKé¢‘é“
4. ç”Ÿæˆæ–°çš„CC.m3u
"""

import requests
import re
import os
import time
from datetime import datetime

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
JULI_SUB_URL = "https://smart.946985.filegear-sg.me/sub.php?user=tg_Thinkoo_bot"
OUTPUT_FILE = "CC.m3u"

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def download_with_retry(url, description, max_retries=3):
    """ä¸‹è½½æ–‡ä»¶ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'https://smart.946985.filegear-sg.me/',
        'Connection': 'keep-alive'
    }
    
    for attempt in range(max_retries):
        try:
            log(f"ä¸‹è½½{description} (å°è¯• {attempt + 1}/{max_retries})...")
            response = requests.get(url, headers=headers, timeout=30)
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                content = response.text.strip()
                if content:
                    log(f"âœ… {description} ä¸‹è½½æˆåŠŸ ({len(content)} å­—ç¬¦)")
                    return content
                else:
                    log(f"âš ï¸  {description} å†…å®¹ä¸ºç©º")
            else:
                log(f"âŒ {description} HTTPé”™è¯¯: {response.status_code}")
                
        except requests.exceptions.Timeout:
            log(f"âŒ {description} è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            log(f"âŒ {description} è¿æ¥é”™è¯¯")
        except Exception as e:
            log(f"âŒ {description} é”™è¯¯: {e}")
        
        if attempt < max_retries - 1:
            wait_time = (attempt + 1) * 5  # é€’å¢ç­‰å¾…æ—¶é—´
            log(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)
    
    return None

def update_and_get_juli_subscription():
    """æ›´æ–°å¹¶è·å–JULIè®¢é˜…å†…å®¹"""
    log("æ›´æ–°JULIè®¢é˜…...")
    
    # å…ˆè®¿é—®ä¸€æ¬¡æ¿€æ´»è®¢é˜…ï¼ˆå¦‚æœéœ€è¦ï¼‰
    activation_url = f"{JULI_SUB_URL}&t={int(time.time())}"
    log(f"è®¿é—®è®¢é˜…URL: {JULI_SUB_URL}")
    
    # è·å–è®¢é˜…å†…å®¹
    content = download_with_retry(activation_url, "JULIè®¢é˜…")
    
    if not content:
        log("âŒ æ— æ³•è·å–JULIè®¢é˜…")
        return None
    
    # æ£€æŸ¥è®¢é˜…æ˜¯å¦æœ‰æ•ˆ
    if not content.startswith('#EXTM3U'):
        log("âš ï¸  è®¢é˜…å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„M3Uæ ¼å¼")
        
        # å°è¯•ä»å†…å®¹ä¸­æå–M3U
        m3u_pattern = r'#EXTM3U.*'
        match = re.search(m3u_pattern, content, re.DOTALL)
        if match:
            content = match.group(0)
            log(f"âœ… ä»å†…å®¹ä¸­æå–åˆ°M3U ({len(content)} å­—ç¬¦)")
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰é¢‘é“ä¿¡æ¯
            lines = content.split('\n')
            m3u_lines = []
            for line in lines:
                if line.strip().startswith('#EXTINF:') or ('://' in line and not line.startswith('<')):
                    m3u_lines.append(line.strip())
            
            if m3u_lines:
                content = '#EXTM3U\n' + '\n'.join(m3u_lines)
                log(f"âœ… ä»é¡µé¢æå–åˆ°é¢‘é“ä¿¡æ¯ ({len(m3u_lines)} ä¸ª)")
            else:
                log("âŒ è®¢é˜…å†…å®¹ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“ä¿¡æ¯")
                return None
    
    # éªŒè¯è®¢é˜…ä¸­çš„é¢‘é“æ˜¯å¦æœ‰æ•ˆ
    log("éªŒè¯è®¢é˜…é¢‘é“æœ‰æ•ˆæ€§...")
    channels = extract_channels_from_m3u(content)
    if not channels:
        log("âŒ è®¢é˜…ä¸­æ²¡æœ‰æ‰¾åˆ°é¢‘é“")
        return None
    
    log(f"âœ… è®¢é˜…éªŒè¯é€šè¿‡ï¼Œæ‰¾åˆ° {len(channels)} ä¸ªé¢‘é“")
    
    # å¯é€‰ï¼šå¿«é€Ÿæµ‹è¯•å‡ ä¸ªé¢‘é“ï¼ˆä¸å®é™…æ’­æ”¾ï¼Œåªæ£€æŸ¥URLæ ¼å¼ï¼‰
    test_channels = channels[:3]
    for i, (extinf, url) in enumerate(test_channels):
        if ',' in extinf:
            name = extinf.split(',', 1)[1][:30]
            log(f"  é¢‘é“{i+1}: {name}...")
    
    return content

def extract_channels_from_m3u(m3u_content):
    """ä»M3Uå†…å®¹ä¸­æå–æ‰€æœ‰é¢‘é“"""
    if not m3u_content:
        return []
    
    lines = m3u_content.split('\n')
    channels = []
    current_extinf = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        if line.startswith('#EXTINF:'):
            current_extinf = line
        elif current_extinf and '://' in line and not line.startswith('#'):
            channels.append((current_extinf, line))
            current_extinf = None
    
    return channels

def extract_hk_channels_from_subscription(sub_content):
    """ä»è®¢é˜…å†…å®¹ä¸­æå–JULIé¢‘é“å¹¶æ”¹ä¸ºHKåˆ†ç»„"""
    log("ä»è®¢é˜…ä¸­æå–JULIé¢‘é“å¹¶æ”¹ä¸ºHKåˆ†ç»„...")
    
    channels = extract_channels_from_m3u(sub_content)
    if not channels:
        return []
    
    hk_channels = []
    seen = set()
    
    for extinf, url in channels:
        # æ£€æŸ¥æ˜¯å¦æ˜¯JULIé¢‘é“
        if 'JULI' in extinf.upper():
            # é‡å‘½åä¸ºHKåˆ†ç»„
            new_extinf = re.sub(r'JULI', 'HK', extinf, flags=re.IGNORECASE)
            
            # ä¹Ÿå¯ä»¥æ·»åŠ åˆ†ç»„æ ‡ç­¾
            if 'group-title=' in new_extinf:
                new_extinf = re.sub(r'group-title="[^"]*"', 'group-title="HK"', new_extinf)
            else:
                # å¦‚æœæ²¡æœ‰group-titleï¼Œæ·»åŠ ä¸€ä¸ª
                if ',' in new_extinf:
                    parts = new_extinf.split(',', 1)
                    new_extinf = f'{parts[0]} group-title="HK",{parts[1]}'
            
            # å»é‡
            channel_key = f"{new_extinf}|{url}"
            if channel_key not in seen:
                seen.add(channel_key)
                hk_channels.append((new_extinf, url))
    
    log(f"âœ… æå–åˆ° {len(hk_channels)} ä¸ªHKé¢‘é“ï¼ˆåŸJULIé¢‘é“ï¼‰")
    
    # æ˜¾ç¤ºéƒ¨åˆ†é¢‘é“
    if hk_channels:
        log("éƒ¨åˆ†HKé¢‘é“:")
        for i, (extinf, url) in enumerate(hk_channels[:3]):
            if ',' in extinf:
                name = extinf.split(',', 1)[1]
                log(f"  {i+1}. {name[:50]}{'...' if len(name) > 50 else ''}")
    
    return hk_channels

def get_epg_url(content):
    """ä»å†…å®¹ä¸­æå–EPG URL"""
    if not content:
        return None
    
    # æŸ¥æ‰¾url-tvg
    match = re.search(r'url-tvg="([^"]+)"', content)
    if match:
        return match.group(1)
    
    # æŸ¥æ‰¾x-tvg-url
    match = re.search(r'x-tvg-url="([^"]+)"', content)
    if match:
        return match.group(1)
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹æ›´æ–°å’Œåˆå¹¶M3Uæ–‡ä»¶...")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_with_retry(BB_URL, "BB.m3u")
    if not bb_content:
        log("âŒ BB.m3uä¸‹è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # æå–BBçš„EPG
    bb_epg = get_epg_url(bb_content)
    if bb_epg:
        log(f"âœ… BB EPG: {bb_epg}")
    
    # 2. æ›´æ–°å¹¶è·å–JULIè®¢é˜…
    juli_content = update_and_get_juli_subscription()
    
    # æå–JULIçš„EPG
    juli_epg = get_epg_url(juli_content) if juli_content else None
    if juli_epg:
        log(f"âœ… JULI EPG: {juli_epg}")
    
    # 3. ä»è®¢é˜…ä¸­æå–HKé¢‘é“
    hk_channels = []
    if juli_content:
        hk_channels = extract_hk_channels_from_subscription(juli_content)
    else:
        log("âš ï¸  æ— æ³•è·å–JULIè®¢é˜…ï¼Œåªåˆå¹¶BB.m3u")
    
    # 4. é€‰æ‹©EPGï¼ˆä¼˜å…ˆä½¿ç”¨BBçš„ï¼‰
    epg_url = bb_epg or juli_epg
    if epg_url:
        log(f"âœ… ä½¿ç”¨EPG: {epg_url}")
    
    # 5. æ„å»ºåˆå¹¶åçš„M3U
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # M3Uå¤´éƒ¨
    if epg_url:
        output = f'#EXTM3U url-tvg="{epg_url}"\n'
    else:
        output = '#EXTM3U\n'
    
    output += f"""# è‡ªåŠ¨åˆå¹¶ M3U æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {timestamp}
# BBæº: {BB_URL}
# JULIæº: {JULI_SUB_URL}
# JULIåˆ†ç»„å·²æ”¹ä¸ºHKåˆ†ç»„
# EPGæº: {epg_url if epg_url else 'æ— '}
# è®¢é˜…æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡å¼€å¤´çš„#EXTM3Uè¡Œï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    skip_header = True
    
    for line in bb_lines:
        line = line.rstrip()
        if not line:
            continue
        
        if skip_header and line.startswith('#EXTM3U'):
            skip_header = False
            continue
        
        output += line + '\n'
        if line.startswith('#EXTINF:'):
            bb_count += 1
    
    # æ·»åŠ HKé¢‘é“
    if hk_channels:
        output += f"\n# HKé¢‘é“ (åŸJULIé¢‘é“ï¼Œè®¢é˜…å·²æ›´æ–°éªŒè¯)\n"
        for extinf, url in hk_channels:
            output += extinf + '\n'
            output += url + '\n'
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    output += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# HK é¢‘é“æ•°: {len(hk_channels)} (å·²æ›´æ–°éªŒè¯)
# æ€»é¢‘é“æ•°: {bb_count + len(hk_channels)}
# æ›´æ–°æ—¶é—´: {timestamp}
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
# è®¢é˜…çŠ¶æ€: {"å·²æ›´æ–°" if juli_content else "æ›´æ–°å¤±è´¥"}
"""
    
    # 6. ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(output)
    
    log(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
    log(f"ğŸ“ æ–‡ä»¶: {OUTPUT_FILE}")
    log(f"ğŸ“ å¤§å°: {len(output)} å­—ç¬¦")
    log(f"ğŸ“¡ EPG: {epg_url if epg_url else 'æ— '}")
    log(f"ğŸ“º BBé¢‘é“: {bb_count}")
    log(f"ğŸ“º HKé¢‘é“: {len(hk_channels)}")
    log(f"ğŸ“º æ€»è®¡: {bb_count + len(hk_channels)}")
    log(f"ğŸ”„ è®¢é˜…çŠ¶æ€: {'âœ… å·²æ›´æ–°' if juli_content else 'âŒ æ›´æ–°å¤±è´¥'}")
    
    # 7. ä¿å­˜æ›´æ–°è®°å½•
    with open("update_log.txt", "a", encoding="utf-8") as f:
        f.write(f"{timestamp} | BB:{bb_count} | HK:{len(hk_channels)} | EPG:{epg_url or 'none'} | STATUS:{'OK' if juli_content else 'FAILED'}\n")

if __name__ == "__main__":
    main()
