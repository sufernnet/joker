#!/usr/bin/env python3
"""
M3Uæ–‡ä»¶åˆå¹¶è„šæœ¬ - åŒæ—¶ç”ŸæˆEPG XML
1. ä¸‹è½½BB.m3u
2. ä»Cloudflareä»£ç†è·å–å†…å®¹
3. æå–HKå’ŒTWé¢‘é“
4. åŒæ—¶ç”ŸæˆCC.m3uå’ŒCC.xmlï¼ˆEPGæ–‡ä»¶ï¼‰
5. ç¡®ä¿EPGä¸é¢‘é“ç²¾ç¡®åŒ¹é…
"""

import requests
import re
import os
import time
import json
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from xml.dom import minidom

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
CLOUDFLARE_PROXY = "https://smt-proxy.sufern001.workers.dev/"
M3U_FILE = "CC.m3u"
EPG_FILE = "CC.xml"

# é¢‘é“è¿‡æ»¤å’Œæ’åºé…ç½®
BLACKLIST_TW = [
    "Bloomberg TV", "Bloomberg", "SBNå…¨çƒè´¢ç»å°", "SBNè´¢ç»",
    "FRANCE24è‹±æ–‡å°", "FRANCE24", "åŠå²›å›½é™…æ–°é—»å°", "åŠå²›å›½é™…",
    "NHK world-japan", "NHK world", "NHK", "CNBC Asia", "CNBC"
]

HK_PRIORITY_ORDER = [
    "å‡¤å‡°ä¸­æ–‡", "å‡¤å‡°èµ„è®¯", "å‡¤å‡°é¦™æ¸¯",
    "NOWæ–°é—»å°", "NOWæ˜Ÿå½±", "NOWçˆ†è°·"
]

# é¢‘é“èŠ‚ç›®å•æ¨¡æ¿ï¼ˆå¦‚æœæ²¡æœ‰çœŸå®EPGï¼Œä½¿ç”¨è¿™ä¸ªï¼‰
CHANNEL_SCHEDULES = {
    # å‡¤å‡°ç³»åˆ—
    "å‡¤å‡°ä¸­æ–‡": [
        ("06:00", "09:00", "å‡¤å‡°æ—©ç­è½¦"),
        ("09:00", "12:00", "æ—¶äº‹ç›´é€šè½¦"),
        ("12:00", "14:00", "å‡¤å‡°åˆé—´ç‰¹å¿«"),
        ("14:00", "17:00", "ç¯çƒæ–°é—»è¿½å‡»"),
        ("17:00", "19:00", "æ—¶äº‹è¾©è®ºä¼š"),
        ("19:00", "21:00", "å‡¤å‡°ç„¦ç‚¹æ–°é—»"),
        ("21:00", "23:00", "é‡‘çŸ³è´¢ç»"),
        ("23:00", "01:00", "å¤œç­æ–°é—»")
    ],
    "å‡¤å‡°èµ„è®¯": [
        ("06:00", "08:00", "æ–°é—»æ—©ç­è½¦"),
        ("08:00", "10:00", "ç¯çƒç›´æ’­"),
        ("10:00", "12:00", "è´¢ç»æœ€å‰çº¿"),
        ("12:00", "14:00", "åˆé—´æ–°é—»"),
        ("14:00", "16:00", "æ·±åº¦æŠ¥é“"),
        ("16:00", "18:00", "æ—¶äº‹è§‚å¯Ÿ"),
        ("18:00", "20:00", "æ–°é—»æ™šé«˜å³°"),
        ("20:00", "22:00", "ä»Šæ—¥å…³æ³¨"),
        ("22:00", "00:00", "å¤œé—´æ–°é—»")
    ],
    "å‡¤å‡°é¦™æ¸¯": [
        ("06:00", "09:00", "é¦™æ¸¯æ—©æ™¨"),
        ("09:00", "12:00", "è´¢ç»é€è§†"),
        ("12:00", "14:00", "åˆé—´æŠ¥é“"),
        ("14:00", "17:00", "å¨±ä¹å‰çº¿"),
        ("17:00", "19:00", "æ–°é—»æœ€å‰çº¿"),
        ("19:00", "21:00", "æ—¶äº‹è¿½å‡»"),
        ("21:00", "23:00", "å¤œé—´è´¢ç»"),
        ("23:00", "01:00", "æ·±å¤œæ–°é—»")
    ],
    # NOWç³»åˆ—
    "NOWæ–°é—»å°": [
        ("00:00", "06:00", "é€šå®µæ–°é—»"),
        ("06:00", "09:00", "æ—©æ™¨æ–°é—»"),
        ("09:00", "12:00", "è´¢ç»æ—©æŠ¥"),
        ("12:00", "14:00", "åˆé—´å¿«è®¯"),
        ("14:00", "17:00", "æ—¶äº‹èšç„¦"),
        ("17:00", "19:00", "æ–°é—»æœ€å‰çº¿"),
        ("19:00", "21:00", "æ™šé—´æŠ¥é“"),
        ("21:00", "23:00", "åç‚¹æ–°é—»"),
        ("23:00", "00:00", "å¤œé—´æ–°é—»")
    ],
    "NOWæ˜Ÿå½±": [
        ("06:00", "09:00", "ç»å…¸ç”µå½±"),
        ("09:00", "12:00", "åŠ¨ä½œå‰§åœº"),
        ("12:00", "15:00", "çˆ±æƒ…å‰§åœº"),
        ("15:00", "18:00", "å–œå‰§ä¸“åœº"),
        ("18:00", "21:00", "é»„é‡‘å‰§åœº"),
        ("21:00", "00:00", "æ·±å¤œå½±é™¢"),
        ("00:00", "03:00", "ç»å…¸å›é¡¾"),
        ("03:00", "06:00", "ç”µå½±é©¬æ‹‰æ¾")
    ],
    "NOWçˆ†è°·": [
        ("06:00", "09:00", "å¡é€šä¸–ç•Œ"),
        ("09:00", "12:00", "å„¿ç«¥å‰§åœº"),
        ("12:00", "15:00", "ç»¼è‰ºå¤©åœ°"),
        ("15:00", "18:00", "å¨±ä¹ç›´æ’­"),
        ("18:00", "21:00", "çˆ†è°·å‰§åœº"),
        ("21:00", "00:00", "å¨±ä¹æœ€å‰çº¿"),
        ("00:00", "03:00", "æ·±å¤œå¨±ä¹"),
        ("03:00", "06:00", "å›æ”¾ç²¾é€‰")
    ],
    # é»˜è®¤æ¨¡æ¿
    "DEFAULT": [
        ("06:00", "09:00", "æ—©æ™¨èŠ‚ç›®"),
        ("09:00", "12:00", "ä¸Šåˆå‰§åœº"),
        ("12:00", "14:00", "åˆé—´æ–°é—»"),
        ("14:00", "17:00", "ä¸‹åˆå‰§åœº"),
        ("17:00", "19:00", "å‚æ™šæ–°é—»"),
        ("19:00", "21:00", "é»„é‡‘å‰§åœº"),
        ("21:00", "23:00", "æ™šé—´æ–°é—»"),
        ("23:00", "01:00", "å¤œé—´èŠ‚ç›®"),
        ("01:00", "06:00", "é€šå®µå‰§åœº")
    ]
}

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def generate_channel_id(channel_name):
    """ä¸ºé¢‘é“ç”Ÿæˆå”¯ä¸€çš„ID"""
    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    clean_name = re.sub(r'[^\w\u4e00-\u9fff]', '', channel_name)
    
    # å¸¸è§é¢‘é“æ˜ å°„
    channel_map = {
        "å‡¤å‡°ä¸­æ–‡": "fenghuang_zhongwen",
        "å‡¤å‡°èµ„è®¯": "fenghuang_zixun",
        "å‡¤å‡°é¦™æ¸¯": "fenghuang_xianggang",
        "NOWæ–°é—»å°": "now_news",
        "NOWæ˜Ÿå½±": "now_movie",
        "NOWçˆ†è°·": "now_ent",
        "TVBæ–°é—»": "tvb_news",
        "TVBè´¢ç»": "tvb_finance",
        "æœ‰çº¿æ–°é—»": "cable_news",
        "æ°‘è§†": "ftv",
        "ä¸­è§†": "ctv",
        "åè§†": "cts",
        "å°è§†": "ttv",
        "ä¸‰ç«‹": "set",
        "ä¸œæ£®": "ebc",
        "TVBS": "tvbs",
        "ä¸­å¤©": "ctitv",
        "å¯°å®‡": "universal",
        "éå‡¡": "ustv"
    }
    
    # æ£€æŸ¥æ˜ å°„
    for key, value in channel_map.items():
        if key in channel_name:
            return value
    
    # ç”Ÿæˆç®€å†™ID
    if len(clean_name) >= 4:
        # å–å‰4ä¸ªå­—ç¬¦çš„æ‹¼éŸ³é¦–å­—æ¯æˆ–ç›´æ¥ä½¿ç”¨
        return clean_name[:8].lower()
    else:
        # ä½¿ç”¨å“ˆå¸Œ
        import hashlib
        return "ch_" + hashlib.md5(channel_name.encode()).hexdigest()[:6]

def download_bb_m3u():
    """ä¸‹è½½BB.m3u"""
    try:
        log("ä¸‹è½½BB.m3u...")
        response = requests.get(BB_URL, timeout=10)
        response.raise_for_status()
        log(f"âœ… BB.m3uä¸‹è½½æˆåŠŸ ({len(response.text)} å­—ç¬¦)")
        return response.text
    except Exception as e:
        log(f"âŒ BB.m3uä¸‹è½½å¤±è´¥: {e}")
        return None

def get_proxy_content():
    """ä»Cloudflareä»£ç†è·å–å†…å®¹"""
    try:
        log("ä»Cloudflareä»£ç†è·å–å†…å®¹...")
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(CLOUDFLARE_PROXY, headers=headers, timeout=15)
        
        if response.status_code == 200:
            content = response.text
            
            # æå–M3Uå†…å®¹
            if '<html' in content.lower():
                m3u_match = re.search(r'(#EXTM3U.*?)(?:</pre>|</code>|$)', content, re.DOTALL)
                if m3u_match:
                    content = m3u_match.group(1).strip()
                    log("âœ… ä»HTMLæå–åˆ°M3Uå†…å®¹")
            
            if content and content.strip():
                log(f"âœ… è·å–åˆ°å†…å®¹ ({len(content)} å­—ç¬¦)")
                return content
    except Exception as e:
        log(f"âŒ ä»£ç†è®¿é—®å¤±è´¥: {e}")
    
    return None

def parse_m3u_channels(content):
    """è§£æM3Uå†…å®¹ä¸ºé¢‘é“åˆ—è¡¨"""
    if not content:
        return []
    
    channels = []
    lines = content.split('\n')
    current_extinf = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        if line.startswith('#EXTINF:'):
            current_extinf = line
        elif current_extinf and '://' in line and not line.startswith('#'):
            # æå–é¢‘é“å
            channel_name = current_extinf.split(',', 1)[1] if ',' in current_extinf else current_extinf
            
            channels.append({
                'extinf': current_extinf,
                'url': line,
                'name': channel_name,
                'original_name': channel_name
            })
            current_extinf = None
    
    return channels

def filter_and_rename_channels(channels):
    """è¿‡æ»¤å’Œé‡å‘½åé¢‘é“"""
    hk_channels = []
    tw_channels = []
    
    for channel in channels:
        channel_name = channel['name']
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯JULIé¢‘é“ï¼ˆHKï¼‰
        if 'JULI' in channel_name.upper():
            # é‡å‘½åä¸ºHK
            new_name = re.sub(r'JULI', 'HK', channel_name, flags=re.IGNORECASE)
            new_extinf = channel['extinf'].replace(channel_name, new_name)
            
            # ç¡®ä¿group-titleä¸ºHK
            if 'group-title=' in new_extinf:
                new_extinf = re.sub(r'group-title="[^"]*"', 'group-title="HK"', new_extinf)
            else:
                new_extinf = new_extinf.replace('#EXTINF:', '#EXTINF: group-title="HK",', 1)
            
            channel['name'] = new_name
            channel['extinf'] = new_extinf
            channel['group'] = 'HK'
            hk_channels.append(channel)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯4gtvé¢‘é“ï¼ˆTWï¼‰
        elif '4gtv' in channel_name.lower():
            # æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­
            skip = False
            for black_word in BLACKLIST_TW:
                if black_word.lower() in channel_name.lower():
                    skip = True
                    break
            
            if not skip:
                # é‡å‘½åä¸ºTW
                new_name = re.sub(r'4gtv', 'TW', channel_name, flags=re.IGNORECASE)
                new_extinf = channel['extinf'].replace(channel_name, new_name)
                
                # ç¡®ä¿group-titleä¸ºTW
                if 'group-title=' in new_extinf:
                    new_extinf = re.sub(r'group-title="[^"]*"', 'group-title="TW"', new_extinf)
                else:
                    new_extinf = new_extinf.replace('#EXTINF:', '#EXTINF: group-title="TW",', 1)
                
                channel['name'] = new_name
                channel['extinf'] = new_extinf
                channel['group'] = 'TW'
                tw_channels.append(channel)
    
    # HKé¢‘é“æ’åº
    def hk_sort_key(channel):
        name = channel['name']
        for i, priority in enumerate(HK_PRIORITY_ORDER):
            if priority in name:
                return i
        return len(HK_PRIORITY_ORDER)
    
    hk_channels.sort(key=hk_sort_key)
    
    # TWé¢‘é“é™åˆ¶30ä¸ª
    tw_channels = tw_channels[:30]
    
    return hk_channels, tw_channels

def generate_epg_xml(channels):
    """ç”ŸæˆEPG XMLæ–‡ä»¶"""
    log("ç”ŸæˆEPG XMLæ–‡ä»¶...")
    
    # åˆ›å»ºXMLæ ¹å…ƒç´ 
    tv = ET.Element('tv')
    tv.set('generator-info-name', 'CC EPG Generator')
    tv.set('generator-info-url', 'https://github.com/sufernnet/joker')
    
    # è·å–å½“å‰æ—¥æœŸ
    today = datetime.now()
    tomorrow = today + timedelta(days=1)
    
    for channel in channels:
        channel_name = channel['name']
        channel_id = generate_channel_id(channel_name)
        
        # æ·»åŠ é¢‘é“å…ƒç´ 
        channel_elem = ET.SubElement(tv, 'channel')
        channel_elem.set('id', channel_id)
        
        # æ·»åŠ æ˜¾ç¤ºåç§°
        display_name = ET.SubElement(channel_elem, 'display-name')
        display_name.set('lang', 'zh')
        display_name.text = channel_name
        
        # æ·»åŠ èŠ‚ç›®å•
        schedule = CHANNEL_SCHEDULES.get(channel_name, CHANNEL_SCHEDULES['DEFAULT'])
        
        # ä»Šå¤©å’Œæ˜å¤©çš„èŠ‚ç›®
        for day_offset in [0, 1]:
            day = today + timedelta(days=day_offset)
            date_str = day.strftime('%Y%m%d')
            
            for start_time, end_time, program_title in schedule:
                # åˆ›å»ºèŠ‚ç›®å…ƒç´ 
                programme = ET.SubElement(tv, 'programme')
                
                # æ—¶é—´æ ¼å¼ï¼šYYYYMMDDHHMMSS +0800
                start_dt = datetime.strptime(f"{date_str} {start_time}", "%Y%m%d %H:%M")
                end_dt = datetime.strptime(f"{date_str} {end_time}", "%Y%m%d %H:%M")
                
                # å¤„ç†è·¨å¤©
                if end_time < start_time:
                    end_dt += timedelta(days=1)
                
                programme.set('start', start_dt.strftime('%Y%m%d%H%M%S +0800'))
                programme.set('stop', end_dt.strftime('%Y%m%d%H%M%S +0800'))
                programme.set('channel', channel_id)
                
                # èŠ‚ç›®æ ‡é¢˜
                title = ET.SubElement(programme, 'title')
                title.set('lang', 'zh')
                title.text = program_title
                
                # èŠ‚ç›®æè¿°
                desc = ET.SubElement(programme, 'desc')
                desc.set('lang', 'zh')
                desc.text = f"{channel_name} - {program_title} ({start_time}-{end_time})"
                
                # èŠ‚ç›®åˆ†ç±»
                category = ET.SubElement(programme, 'category')
                category.set('lang', 'zh')
                if "æ–°é—»" in program_title or "è´¢ç»" in program_title:
                    category.text = "æ–°é—»"
                elif "ç”µå½±" in program_title or "å‰§åœº" in program_title:
                    category.text = "ç”µå½±"
                elif "å¨±ä¹" in program_title or "ç»¼è‰º" in program_title:
                    category.text = "å¨±ä¹"
                else:
                    category.text = "ç»¼åˆ"
    
    # ç¾åŒ–XMLè¾“å‡º
    xml_str = ET.tostring(tv, encoding='utf-8')
    dom = minidom.parseString(xml_str)
    pretty_xml = dom.toprettyxml(indent='  ', encoding='utf-8')
    
    log(f"âœ… ç”ŸæˆEPG XMLï¼ŒåŒ…å« {len(channels)} ä¸ªé¢‘é“")
    return pretty_xml.decode('utf-8')

def enhance_m3u_with_epg(channels, epg_url):
    """å¢å¼ºM3Uæ–‡ä»¶ï¼Œæ·»åŠ EPGä¿¡æ¯"""
    enhanced_channels = []
    
    for channel in channels:
        extinf = channel['extinf']
        channel_name = channel['name']
        channel_id = generate_channel_id(channel_name)
        
        # æ·»åŠ tvg-idå’Œtvg-name
        if 'tvg-id=' not in extinf:
            if 'tvg-name=' not in extinf:
                # åœ¨group-titleå‰æ’å…¥tvgä¿¡æ¯
                if 'group-title=' in extinf:
                    new_extinf = extinf.replace('group-title=', f'tvg-id="{channel_id}" tvg-name="{channel_name}" group-title=')
                else:
                    # å¦‚æœæ²¡æœ‰group-titleï¼Œåœ¨é€—å·å‰æ·»åŠ 
                    if ',' in extinf:
                        parts = extinf.split(',', 1)
                        new_extinf = f'{parts[0]} tvg-id="{channel_id}" tvg-name="{channel_name}",{parts[1]}'
                    else:
                        new_extinf = f'{extinf} tvg-id="{channel_id}" tvg-name="{channel_name}"'
            else:
                # å·²æœ‰tvg-nameï¼Œåªæ·»åŠ tvg-id
                new_extinf = extinf.replace('tvg-name=', f'tvg-id="{channel_id}" tvg-name=')
        else:
            new_extinf = extinf
        
        channel['extinf'] = new_extinf
        channel['tvg_id'] = channel_id
        enhanced_channels.append(channel)
    
    return enhanced_channels

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹ç”ŸæˆM3Uå’ŒEPGæ–‡ä»¶...")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_bb_m3u()
    if not bb_content:
        log("âŒ æ— æ³•ç»§ç»­ï¼ŒBB.m3uä¸‹è½½å¤±è´¥")
        return
    
    # 2. ä»ä»£ç†è·å–å†…å®¹
    proxy_content = get_proxy_content()
    
    # 3. è§£æé¢‘é“
    all_channels = []
    
    # è§£æBBé¢‘é“
    bb_channels = parse_m3u_channels(bb_content)
    log(f"è§£æåˆ° {len(bb_channels)} ä¸ªBBé¢‘é“")
    
    # è§£æä»£ç†é¢‘é“
    if proxy_content:
        proxy_channels = parse_m3u_channels(proxy_content)
        log(f"è§£æåˆ° {len(proxy_channels)} ä¸ªä»£ç†é¢‘é“")
        
        # è¿‡æ»¤å’Œé‡å‘½åHK/TWé¢‘é“
        hk_channels, tw_channels = filter_and_rename_channels(proxy_channels)
        log(f"è¿‡æ»¤åå¾—åˆ° {len(hk_channels)} ä¸ªHKé¢‘é“ï¼Œ{len(tw_channels)} ä¸ªTWé¢‘é“")
        
        all_channels.extend(hk_channels)
        all_channels.extend(tw_channels)
    else:
        log("âš ï¸  æ— æ³•è·å–ä»£ç†å†…å®¹ï¼Œåªä½¿ç”¨BBé¢‘é“")
    
    # æ·»åŠ BBé¢‘é“ï¼ˆæ’é™¤é‡å¤ï¼‰
    bb_names = {ch['name'] for ch in all_channels}
    for channel in bb_channels:
        if channel['name'] not in bb_names:
            channel['group'] = 'BB'
            all_channels.append(channel)
    
    log(f"æ€»å…± {len(all_channels)} ä¸ªé¢‘é“")
    
    # 4. ç”ŸæˆEPG XML
    epg_xml = generate_epg_xml(all_channels)
    
    # 5. å¢å¼ºM3Ué¢‘é“ï¼ˆæ·»åŠ EPGä¿¡æ¯ï¼‰
    enhanced_channels = enhance_m3u_with_epg(all_channels, "CC.xml")
    
    # 6. ç”ŸæˆM3Uæ–‡ä»¶
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # EPGæ–‡ä»¶URLï¼ˆGitHub Rawï¼‰
    epg_file_url = f"https://raw.githubusercontent.com/sufernnet/joker/main/{EPG_FILE}"
    
    m3u_content = f"""#EXTM3U x-tvg-url="{epg_file_url}" url-tvg="{epg_file_url}"
#EXTVLCOPT:program=999999
# è‡ªåŠ¨ç”Ÿæˆ M3U+EPG æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 18:00
# åŒ…å«é¢‘é“: {len(enhanced_channels)} ä¸ª
# EPGæ–‡ä»¶: {EPG_FILE} (æœ¬åœ°ç”Ÿæˆï¼Œç¡®ä¿åŒ¹é…)
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æŒ‰åˆ†ç»„æ·»åŠ é¢‘é“
    groups = {}
    for channel in enhanced_channels:
        group = channel.get('group', 'Other')
        if group not in groups:
            groups[group] = []
        groups[group].append(channel)
    
    # æŒ‰é¡ºåºè¾“å‡ºï¼šBB -> HK -> TW -> Other
    for group in ['BB', 'HK', 'TW', 'Other']:
        if group in groups and groups[group]:
            m3u_content += f"\n# {group}é¢‘é“\n"
            for channel in groups[group]:
                m3u_content += channel['extinf'] + '\n'
                m3u_content += channel['url'] + '\n'
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    m3u_content += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BBé¢‘é“: {len(groups.get('BB', []))}
# HKé¢‘é“: {len(groups.get('HK', []))} (æŒ‰æŒ‡å®šé¡ºåºæ’åˆ—)
# TWé¢‘é“: {len(groups.get('TW', []))} (å‰30ä¸ªï¼Œå·²è¿‡æ»¤)
# æ€»é¢‘é“: {len(enhanced_channels)}
# EPGçŠ¶æ€: âœ… å·²ç”Ÿæˆæœ¬åœ°EPGæ–‡ä»¶ ({EPG_FILE})
# æ›´æ–°æ—¶é—´: {timestamp}
# æ›´æ–°é¢‘ç‡: æ¯å¤© 06:00 å’Œ 18:00 (åŒ—äº¬æ—¶é—´)
"""
    
    # 7. ä¿å­˜æ–‡ä»¶
    with open(M3U_FILE, "w", encoding="utf-8") as f:
        f.write(m3u_content)
    
    with open(EPG_FILE, "w", encoding="utf-8") as f:
        f.write(epg_xml)
    
    log(f"\nğŸ‰ ç”Ÿæˆå®Œæˆ!")
    log(f"ğŸ“ M3Uæ–‡ä»¶: {M3U_FILE} ({len(m3u_content)} å­—ç¬¦)")
    log(f"ğŸ“ EPGæ–‡ä»¶: {EPG_FILE} ({len(epg_xml)} å­—ç¬¦)")
    log(f"ğŸ“º é¢‘é“æ€»æ•°: {len(enhanced_channels)}")
    log(f"ğŸ“¡ EPGè¦†ç›–: 100% (æœ¬åœ°ç”Ÿæˆï¼Œç¡®ä¿åŒ¹é…)")
    log(f"ğŸ•’ ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 18:00")
    
    # æ˜¾ç¤ºEPGæ–‡ä»¶URL
    log(f"ğŸ”— EPGæ–‡ä»¶URL: {epg_file_url}")

if __name__ == "__main__":
    main()
