#!/usr/bin/env python3
"""
DD.m3uåˆå¹¶è„šæœ¬ - é’ˆå¯¹ç›®æ ‡æºä¼˜åŒ–ç‰ˆ
1. ä»æŒ‡å®šURLæå–â€œæ¸¯æ¾³å°ç›´æ’­â€åˆ†ç»„å†…çš„æ‰€æœ‰é¢‘é“
2. è‡ªåŠ¨ç»†åˆ†ä¸ºâ€œé¦™æ¸¯â€ã€â€œå°æ¹¾â€ä¸¤ä¸ªåˆ†ç»„
3. ä¸BB.m3uåˆå¹¶
4. è¾“å‡ºDD.m3u
åŒ—äº¬æ—¶é—´æ¯å¤©6:00ã€17:00è‡ªåŠ¨è¿è¡Œ
"""

import requests
import re
import os
from datetime import datetime

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
GAT_URL = "https://gh-proxy.org/https://raw.githubusercontent.com/Jsnzkpg/Jsnzkpg/Jsnzkpg/Jsnzkpg1"
OUTPUT_FILE = "DD.m3u"

# åˆ†ç»„å…³é”®è¯
TARGET_GROUP = "æ¸¯æ¾³å°ç›´æ’­"  # è¦æå–çš„ç›®æ ‡åˆ†ç»„
HK_GROUP_NAME = "é¦™æ¸¯"
TW_GROUP_NAME = "å°æ¹¾"

# é¦™æ¸¯é¢‘é“å…³é”®è¯ (ç”¨äºä»â€œæ¸¯æ¾³å°ç›´æ’­â€ä¸­äºŒæ¬¡ç»†åˆ†)
HK_KEYWORDS = ["é¦™æ¸¯", "æ¸¯", "TVB", "æ— çº¿", "æ˜ç ", "ç¿¡ç¿ ", "æœ¬æ¸¯å°", "å‡¤å‡°å«è§†", "NOW", "VIU", "RTHK", "æœ‰çº¿"]
# å°æ¹¾é¢‘é“å…³é”®è¯
TW_KEYWORDS = ["å°æ¹¾", "å°", "å°è§†", "ä¸­è§†", "åè§†", "æ°‘è§†", "ä¸‰ç«‹", "ä¸œæ£®", "TVBS", "ä¸­å¤©", "å¯°å®‡", "éå‡¡", "çº¬æ¥"]

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def download_content(url, description):
    """ä¸‹è½½å†…å®¹"""
    try:
        log(f"ä¸‹è½½ {description}...")
        headers = {'User-Agent': 'Mozilla/5.0', 'Accept': '*/*'}
        response = requests.get(url, headers=headers, timeout=25)
        response.raise_for_status()
        log(f"âœ… {description} ä¸‹è½½æˆåŠŸ ({len(response.text)} å­—ç¬¦)")
        return response.text
    except Exception as e:
        log(f"âŒ {description} ä¸‹è½½å¤±è´¥: {e}")
        return None

def extract_target_group_channels(content):
    """
    æ ¸å¿ƒåŠŸèƒ½ï¼šä»å†…å®¹ä¸­ç²¾ç¡®æå–â€œæ¸¯æ¾³å°ç›´æ’­â€åˆ†ç»„ä¸‹çš„æ‰€æœ‰é¢‘é“
    æ ¼å¼ç¤ºä¾‹ï¼šé¢‘é“åç§°,http://url
    """
    if not content:
        log("å†…å®¹ä¸ºç©ºï¼Œæ— æ³•æå–")
        return []
    
    log(f"å¼€å§‹æå–åˆ†ç»„ï¼š{TARGET_GROUP}")
    
    # æŸ¥æ‰¾ç›®æ ‡åˆ†ç»„å¼€å§‹ä½ç½®
    target_section_pattern = f"{TARGET_GROUP},#genre#"
    lines = content.split('\n')
    target_channels = []
    in_target_section = False
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        
        # æ‰¾åˆ°ç›®æ ‡åˆ†ç»„æ ‡é¢˜è¡Œ
        if target_section_pattern in line:
            in_target_section = True
            log(f"âœ… åœ¨ç¬¬{i+1}è¡Œæ‰¾åˆ°ç›®æ ‡åˆ†ç»„: {TARGET_GROUP}")
            continue
        
        # å¦‚æœå·²ç»åœ¨ç›®æ ‡åˆ†ç»„å†…
        if in_target_section:
            # é‡åˆ°ä¸‹ä¸€ä¸ªåˆ†ç»„æ ‡é¢˜è¡Œï¼ˆåŒ…å«â€œ,#genre#â€ï¼‰åˆ™åœæ­¢
            if ",#genre#" in line:
                log(f"åˆ°è¾¾ä¸‹ä¸€ä¸ªåˆ†ç»„ï¼Œåœæ­¢æå–")
                break
            
            # è§£æé¢‘é“è¡Œï¼ˆæ ¼å¼ï¼šé¢‘é“å,URLï¼‰
            if ',' in line and '://' in line:
                parts = line.split(',', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªé€—å·
                if len(parts) == 2:
                    channel_name, channel_url = parts
                    target_channels.append((channel_name.strip(), channel_url.strip()))
    
    log(f"ä»ã€{TARGET_GROUP}ã€åˆ†ç»„ä¸­æå–åˆ° {len(target_channels)} ä¸ªé¢‘é“")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªæå–åˆ°çš„é¢‘é“
    if target_channels:
        log("æå–åˆ°çš„é¢‘é“ç¤ºä¾‹ï¼š")
        for idx, (name, url) in enumerate(target_channels[:8]):
            log(f"  {idx+1:2d}. {name[:40]:<40} | URLé•¿åº¦:{len(url)}")
    else:
        log("âš ï¸  æœªåœ¨ç›®æ ‡åˆ†ç»„ä¸­æ‰¾åˆ°ä»»ä½•é¢‘é“")
        # è°ƒè¯•ï¼šæ˜¾ç¤ºç›®æ ‡åˆ†ç»„é™„è¿‘çš„å†…å®¹
        log("åˆ†ç»„é™„è¿‘å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰ï¼š")
        for i, line in enumerate(lines):
            if TARGET_GROUP in line:
                start = max(0, i-3)
                end = min(len(lines), i+10)
                for j in range(start, end):
                    log(f"  è¡Œ{j+1}: {lines[j][:80]}")
                break
    
    return target_channels

def classify_channels_by_region(channels):
    """å°†é¢‘é“ç»†åˆ†ä¸ºé¦™æ¸¯å’Œå°æ¹¾"""
    hk_channels = []
    tw_channels = []
    unclassified_channels = []  # æ— æ³•åˆ†ç±»çš„é¢‘é“
    
    log("å¼€å§‹ç»†åˆ†é¦™æ¸¯/å°æ¹¾é¢‘é“...")
    
    for channel_name, channel_url in channels:
        name_lower = channel_name.lower()
        classified = False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¦™æ¸¯é¢‘é“
        for keyword in HK_KEYWORDS:
            if keyword.lower() in name_lower:
                # ç¡®ä¿é¢‘é“åç§°æ ¼å¼æ­£ç¡®
                extinf_line = f'#EXTINF:-1,{channel_name}'
                if not any(group_tag in extinf_line for group_tag in ['group-title="', 'tvg-id="']):
                    extinf_line = f'#EXTINF:-1 group-title="{HK_GROUP_NAME}",{channel_name}'
                else:
                    # æ›¿æ¢ç°æœ‰åˆ†ç»„
                    extinf_line = re.sub(r'group-title="[^"]*"', f'group-title="{HK_GROUP_NAME}"', extinf_line)
                
                hk_channels.append((extinf_line, channel_url, channel_name))
                classified = True
                break
        
        # å¦‚æœä¸æ˜¯é¦™æ¸¯ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºå°æ¹¾
        if not classified:
            for keyword in TW_KEYWORDS:
                if keyword.lower() in name_lower:
                    extinf_line = f'#EXTINF:-1,{channel_name}'
                    if not any(group_tag in extinf_line for group_tag in ['group-title="', 'tvg-id="']):
                        extinf_line = f'#EXTINF:-1 group-title="{TW_GROUP_NAME}",{channel_name}'
                    else:
                        extinf_line = re.sub(r'group-title="[^"]*"', f'group-title="{TW_GROUP_NAME}"', extinf_line)
                    
                    tw_channels.append((extinf_line, channel_url, channel_name))
                    classified = True
                    break
        
        # å¦‚æœæ— æ³•åˆ†ç±»ï¼Œä¿ç•™åŸæ ·ï¼ˆä»å±äºâ€œæ¸¯æ¾³å°ç›´æ’­â€åˆ†ç»„ï¼‰
        if not classified:
            extinf_line = f'#EXTINF:-1,{channel_name}'
            unclassified_channels.append((extinf_line, channel_url, channel_name))
    
    # è¾“å‡ºåˆ†ç±»ç»Ÿè®¡
    log(f"âœ… é¢‘é“ç»†åˆ†å®Œæˆï¼š")
    log(f"   â”œâ”€ é¦™æ¸¯é¢‘é“: {len(hk_channels)} ä¸ª")
    log(f"   â”œâ”€ å°æ¹¾é¢‘é“: {len(tw_channels)} ä¸ª")
    log(f"   â””â”€ æœªç»†åˆ†é¢‘é“: {len(unclassified_channels)} ä¸ª (ä¿ç•™åœ¨ã€{TARGET_GROUP}ã€)")
    
    # æ˜¾ç¤ºåˆ†ç±»ç¤ºä¾‹
    if hk_channels:
        log("é¦™æ¸¯é¢‘é“ç¤ºä¾‹ï¼š")
        for _, _, name in hk_channels[:4]:
            log(f"    â€¢ {name}")
    
    if tw_channels:
        log("å°æ¹¾é¢‘é“ç¤ºä¾‹ï¼š")
        for _, _, name in tw_channels[:4]:
            log(f"    â€¢ {name}")
    
    return hk_channels, tw_channels, unclassified_channels

def get_bb_epg(bb_content):
    """ä»BB.m3uæå–EPGä¿¡æ¯"""
    if not bb_content:
        return None
    
    epg_match = re.search(r'url-tvg="([^"]+)"', bb_content)
    if epg_match:
        return epg_match.group(1)
    
    epg_match = re.search(r'x-tvg-url="([^"]+)"', bb_content)
    if epg_match:
        return epg_match.group(1)
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹ç”Ÿæˆ DD.m3u (é’ˆå¯¹ç›®æ ‡æºä¼˜åŒ–ç‰ˆ)...")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_content(BB_URL, "BB.m3u")
    if not bb_content:
        log("âŒ BB.m3uä¸‹è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # 2. ä¸‹è½½æ¸¯æ¾³å°æº
    gat_content = download_content(GAT_URL, "æ¸¯æ¾³å°ç›´æ’­æº")
    if not gat_content:
        log("âš ï¸  æ¸¯æ¾³å°æºä¸‹è½½å¤±è´¥ï¼Œåªåˆå¹¶BB.m3u")
        gat_content = ""
    
    # 3. æå–EPG
    epg_url = get_bb_epg(bb_content)
    log(f"EPGæº: {epg_url if epg_url else 'æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å¤´éƒ¨'}")
    
    # 4. å¤„ç†ç›®æ ‡åˆ†ç»„é¢‘é“
    hk_channels, tw_channels, other_gat_channels = [], [], []
    
    if gat_content:
        # 4.1 æå–ç›®æ ‡åˆ†ç»„çš„æ‰€æœ‰é¢‘é“
        target_group_channels = extract_target_group_channels(gat_content)
        
        if target_group_channels:
            # 4.2 å°†ç›®æ ‡åˆ†ç»„é¢‘é“ç»†åˆ†ä¸ºé¦™æ¸¯å’Œå°æ¹¾
            hk_channels, tw_channels, other_gat_channels = classify_channels_by_region(target_group_channels)
        else:
            log("âš ï¸  æœªæ‰¾åˆ°ç›®æ ‡åˆ†ç»„é¢‘é“ï¼Œè·³è¿‡æ¸¯æ¾³å°å†…å®¹")
    else:
        log("âš ï¸  æ— æ¸¯æ¾³å°å†…å®¹ï¼Œä»…ä½¿ç”¨BB.m3u")
    
    # 5. æ„å»ºDD.m3u
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # M3Uå¤´éƒ¨
    if epg_url:
        m3u_header = f'#EXTM3U url-tvg="{epg_url}"\n'
    else:
        m3u_header = '#EXTM3U\n'
    
    output = m3u_header + f"""# DD.m3u - æ¸¯æ¾³å°ä¸“ç‰ˆ (ä¼˜åŒ–ç‰ˆ)
# ç”Ÿæˆæ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 17:00 (åŒ—äº¬æ—¶é—´)
# BBæº: {BB_URL}
# æ¸¯æ¾³å°æº: {GAT_URL}
# å¤„ç†é€»è¾‘: æå–ã€{TARGET_GROUP}ã€åˆ†ç»„ â†’ ç»†åˆ†ä¸ºã€Œé¦™æ¸¯ã€ã€Œå°æ¹¾ã€
# EPGæº: {epg_url if epg_url else 'æ²¿ç”¨BBçš„EPG'}
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # 5.1 æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    skip_first = True
    
    for line in bb_lines:
        line = line.rstrip()
        if not line:
            continue
        
        if skip_first and line.startswith('#EXTM3U'):
            skip_first = False
            continue
        
        output += line + '\n'
        if line.startswith('#EXTINF:'):
            bb_count += 1
    
    # 5.2 æ·»åŠ é¦™æ¸¯é¢‘é“
    if hk_channels:
        output += f"\n# {HK_GROUP_NAME}é¢‘é“ (å…± {len(hk_channels)} ä¸ªï¼Œä»ã€{TARGET_GROUP}ã€ç»†åˆ†)\n"
        # æŒ‰é¢‘é“åæ’åº
        hk_channels.sort(key=lambda x: x[2])
        for extinf, url, _ in hk_channels:
            output += extinf + '\n'
            output += url + '\n'
    else:
        output += f"\n# {HK_GROUP_NAME}é¢‘é“ (0ä¸ª - æœªä»æºä¸­è¯†åˆ«åˆ°é¦™æ¸¯é¢‘é“)\n"
    
    # 5.3 æ·»åŠ å°æ¹¾é¢‘é“
    if tw_channels:
        output += f"\n# {TW_GROUP_NAME}é¢‘é“ (å…± {len(tw_channels)} ä¸ªï¼Œä»ã€{TARGET_GROUP}ã€ç»†åˆ†)\n"
        tw_channels.sort(key=lambda x: x[2])
        for extinf, url, _ in tw_channels:
            output += extinf + '\n'
            output += url + '\n'
    else:
        output += f"\n# {TW_GROUP_NAME}é¢‘é“ (0ä¸ª - æœªä»æºä¸­è¯†åˆ«åˆ°å°æ¹¾é¢‘é“)\n"
    
    # 5.4 æ·»åŠ æœªç»†åˆ†çš„æ¸¯æ¾³å°é¢‘é“ï¼ˆå¦‚æœ‰ï¼‰
    if other_gat_channels:
        output += f"\n# å…¶ä»–{TARGET_GROUP}é¢‘é“ (å…± {len(other_gat_channels)} ä¸ªï¼Œæœªç»†åˆ†)\n"
        for extinf, url, _ in other_gat_channels:
            output += extinf + '\n'
            output += url + '\n'
    
    # 5.5 æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    total_channels = bb_count + len(hk_channels) + len(tw_channels) + len(other_gat_channels)
output += f"""

# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# é¦™æ¸¯é¢‘é“æ•°: {len(hk_channels)} (ä»ã€{TARGET_GROUP}ã€ç»†åˆ†)
# å°æ¹¾é¢‘é“æ•°: {len(tw_channels)} (ä»ã€{TARGET_GROUP}ã€ç»†åˆ†)
# å…¶ä»–{target_group}é¢‘é“æ•°: {len(other_gat_channels)}
# æ€»é¢‘é“æ•°: {total_channels}
# æ›´æ–°æ—¶é—´: {timestamp}
# æ›´æ–°é¢‘ç‡: æ¯å¤© 06:00 å’Œ 17:00 (åŒ—äº¬æ—¶é—´)
# å¤‡æ³¨: æœ¬æ–‡ä»¶ä¸“ä¸ºã€{GAT_URL}ã€æºä¼˜åŒ–ï¼Œç¡®ä¿æ­£ç¡®æå–å¹¶ç»†åˆ†æ¸¯æ¾³å°é¢‘é“
"""
    
    # 6. ä¿å­˜æ–‡ä»¶
    try:
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            f.write(output)
        
        log(f"\nğŸ‰ DD.m3u ç”ŸæˆæˆåŠŸï¼")
        log(f"ğŸ“ æ–‡ä»¶: {OUTPUT_FILE}")
        log(f"ğŸ“ å¤§å°: {len(output):,} å­—ç¬¦")
        log(f"ğŸ“º é¢‘é“ç»Ÿè®¡: BB({bb_count}) + é¦™æ¸¯({len(hk_channels)}) + å°æ¹¾({len(tw_channels)}) = {total_channels}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤´éƒ¨
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            log("æ–‡ä»¶å¤´éƒ¨é¢„è§ˆ:")
            for i, line in enumerate(f.readlines()[:15]):
                if line.strip():
                    log(f"  {i+1:2d}: {line.rstrip()}")
                    
    except Exception as e:
        log(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
