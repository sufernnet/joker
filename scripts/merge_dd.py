#!/usr/bin/env python3
"""
DD.m3uåˆå¹¶è„šæœ¬
1. ä»æŒ‡å®šURLæå–æ¸¯æ¾³å°ç›´æ’­
2. è‡ªåŠ¨æŒ‰é¦™æ¸¯ã€å°æ¹¾åˆ†ç»„
3. ä¸BB.m3uåˆå¹¶
4. è¾“å‡ºDD.m3u
åŒ—äº¬æ—¶é—´æ¯å¤©6:00ã€17:00è‡ªåŠ¨è¿è¡Œ
"""

import requests
import re
import os
import time
from datetime import datetime

# é…ç½®
BB_URL = "https://raw.githubusercontent.com/sufernnet/joker/main/BB.m3u"
GAT_URL = "https://gh-proxy.org/https://raw.githubusercontent.com/Jsnzkpg/Jsnzkpg/Jsnzkpg/Jsnzkpg1"
OUTPUT_FILE = "DD.m3u"

# é¦™æ¸¯é¢‘é“å…³é”®è¯
HK_KEYWORDS = [
    "é¦™æ¸¯", "æ¸¯å°", "TVB", "æ— çº¿", "æœ‰çº¿", "å‡¤å‡°", "NOW", "VIU", "RTHK",
    "æ˜ç ", "ç¿¡ç¿ ", "æœ¬æ¸¯", "å›½é™…", "è´¢ç»", "æ–°é—»", "å«è§†", "äºšæ´²",
    "ä¸­æ–‡", "èµ„è®¯", "ç”µå½±", "å¨±ä¹", "ä½“è‚²", "å„¿ç«¥", "ç²¤è¯­"
]

# å°æ¹¾é¢‘é“å…³é”®è¯
TW_KEYWORDS = [
    "å°æ¹¾", "å°è§†", "ä¸­è§†", "åè§†", "æ°‘è§†", "ä¸‰ç«‹", "ä¸œæ£®", "TVBS",
    "ä¸­å¤©", "å¯°å®‡", "éå‡¡", "å«è§†", "ç”µå½±", "æˆå‰§", "æ–°é—»", "è´¢ç»",
    "å¨±ä¹", "ç»¼åˆ", "ä½“è‚²", "å®¢å®¶", "åŸæ°‘", "å…¬è§†", "çº¬æ¥", "é¾™ç¥¥"
]

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def download_content(url, description):
    """ä¸‹è½½å†…å®¹"""
    try:
        log(f"ä¸‹è½½{description}...")
        headers = {
            'User-Agent': 'Mozilla/5.0',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }
        
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        content = response.text
        log(f"âœ… {description}ä¸‹è½½æˆåŠŸ ({len(content)} å­—ç¬¦)")
        return content
        
    except Exception as e:
        log(f"âŒ {description}ä¸‹è½½å¤±è´¥: {e}")
        return None

def extract_gat_channels(content):
    """ä»å†…å®¹ä¸­æå–æ¸¯æ¾³å°é¢‘é“"""
    if not content:
        return [], []
    
    log("æå–æ¸¯æ¾³å°é¢‘é“...")
    
    # è§£æM3Uå†…å®¹
    lines = content.split('\n')
    channels = []
    current_extinf = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        if line.startswith('#EXTINF:'):
            current_extinf = line
        elif current_extinf and '://' in line and not line.startswith('#'):
            channels.append((current_extinf, line))
            current_extinf = None
    
    log(f"æ‰¾åˆ° {len(channels)} ä¸ªé¢‘é“")
    
    # åˆ†ç±»é¢‘é“
    hk_channels = []
    tw_channels = []
    other_channels = []
    
    for extinf, url in channels:
        channel_name = extinf.split(',', 1)[1] if ',' in extinf else extinf
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ¸¯æ¾³å°é¢‘é“
        is_gat = False
        
        # æ£€æŸ¥é¦™æ¸¯å…³é”®è¯
        for keyword in HK_KEYWORDS:
            if keyword in channel_name:
                # å¢å¼ºEXTINFï¼Œæ·»åŠ group-title
                if 'group-title=' not in extinf:
                    new_extinf = extinf.replace('#EXTINF:', '#EXTINF: group-title="é¦™æ¸¯",', 1)
                else:
                    new_extinf = re.sub(r'group-title="[^"]*"', 'group-title="é¦™æ¸¯"', extinf)
                
                hk_channels.append((new_extinf, url, channel_name))
                is_gat = True
                break
        
        # æ£€æŸ¥å°æ¹¾å…³é”®è¯ï¼ˆå¦‚æœè¿˜ä¸æ˜¯æ¸¯æ¾³å°é¢‘é“ï¼‰
        if not is_gat:
            for keyword in TW_KEYWORDS:
                if keyword in channel_name:
                    if 'group-title=' not in extinf:
                        new_extinf = extinf.replace('#EXTINF:', '#EXTINF: group-title="å°æ¹¾",', 1)
                    else:
                        new_extinf = re.sub(r'group-title="[^"]*"', 'group-title="å°æ¹¾"', extinf)
                    
                    tw_channels.append((new_extinf, url, channel_name))
                    is_gat = True
                    break
        
        # å¦‚æœä¸æ˜¯æ¸¯æ¾³å°é¢‘é“ï¼Œæ£€æŸ¥å…¶ä»–ç‰¹å¾
        if not is_gat:
            # æ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
            url_lower = url.lower()
            if 'hongkong' in url_lower or 'hk' in url_lower or 'tw' in url_lower or 'taiwan' in url_lower:
                # æ ¹æ®URLåˆ¤æ–­
                if 'hk' in url_lower or 'hongkong' in url_lower:
                    new_extinf = extinf.replace('#EXTINF:', '#EXTINF: group-title="é¦™æ¸¯",', 1)
                    hk_channels.append((new_extinf, url, channel_name))
                elif 'tw' in url_lower or 'taiwan' in url_lower:
                    new_extinf = extinf.replace('#EXTINF:', '#EXTINF: group-title="å°æ¹¾",', 1)
                    tw_channels.append((new_extinf, url, channel_name))
                else:
                    other_channels.append((extinf, url, channel_name))
            else:
                other_channels.append((extinf, url, channel_name))
    
    log(f"âœ… åˆ†ç±»å®Œæˆ:")
    log(f"   é¦™æ¸¯é¢‘é“: {len(hk_channels)} ä¸ª")
    log(f"   å°æ¹¾é¢‘é“: {len(tw_channels)} ä¸ª")
    log(f"   å…¶ä»–é¢‘é“: {len(other_channels)} ä¸ª")
    
    # æ˜¾ç¤ºéƒ¨åˆ†é¢‘é“
    if hk_channels:
        log("é¦™æ¸¯é¢‘é“ç¤ºä¾‹:")
        for i, (extinf, url, name) in enumerate(hk_channels[:5]):
            log(f"   {i+1}. {name[:40]}...")
    
    if tw_channels:
        log("å°æ¹¾é¢‘é“ç¤ºä¾‹:")
        for i, (extinf, url, name) in enumerate(tw_channels[:5]):
            log(f"   {i+1}. {name[:40]}...")
    
    return hk_channels, tw_channels

def get_bb_epg(bb_content):
    """ä»BB.m3uæå–EPGä¿¡æ¯"""
    if not bb_content:
        return None
    
    # æŸ¥æ‰¾EPG URL
    epg_match = re.search(r'url-tvg="([^"]+)"', bb_content)
    if epg_match:
        return epg_match.group(1)
    
    # å°è¯•å…¶ä»–æ ¼å¼
    epg_match = re.search(r'x-tvg-url="([^"]+)"', bb_content)
    if epg_match:
        return epg_match.group(1)
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    log("å¼€å§‹ç”ŸæˆDD.m3uæ–‡ä»¶...")
    
    # æ˜¾ç¤ºæ—¶é—´ä¿¡æ¯
    current_time = datetime.now()
    log(f"å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    log(f"ä¸‹æ¬¡è¿è¡Œ: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 17:00")
    log(f"æ¸¯æ¾³å°æº: {GAT_URL}")
    
    # 1. ä¸‹è½½BB.m3u
    bb_content = download_content(BB_URL, "BB.m3u")
    if not bb_content:
        log("âŒ BB.m3uä¸‹è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # æå–BBçš„EPG
    epg_url = get_bb_epg(bb_content)
    if epg_url:
        log(f"âœ… ä½¿ç”¨EPG: {epg_url}")
    else:
        log("âš ï¸  æœªæ‰¾åˆ°EPGä¿¡æ¯")
    
    # 2. ä¸‹è½½æ¸¯æ¾³å°ç›´æ’­æº
    gat_content = download_content(GAT_URL, "æ¸¯æ¾³å°ç›´æ’­æº")
    
    # 3. æå–å¹¶åˆ†ç±»æ¸¯æ¾³å°é¢‘é“
    hk_channels, tw_channels = [], []
    if gat_content:
        hk_channels, tw_channels = extract_gat_channels(gat_content)
    else:
        log("âš ï¸  æ— æ³•è·å–æ¸¯æ¾³å°å†…å®¹ï¼Œåªåˆå¹¶BB.m3u")
    
    # 4. æ„å»ºDD.m3uå†…å®¹
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # M3Uå¤´éƒ¨ï¼ˆä½¿ç”¨BBçš„EPGï¼‰
    if epg_url:
        m3u_header = f'#EXTM3U url-tvg="{epg_url}"\n'
    else:
        m3u_header = '#EXTM3U\n'
    
    output = m3u_header + f"""# DD.m3u - æ¸¯æ¾³å°ä¸“ç‰ˆ
# ç”Ÿæˆæ—¶é—´: {timestamp} (åŒ—äº¬æ—¶é—´)
# ä¸‹æ¬¡æ›´æ–°: æ¯å¤© 06:00 å’Œ 17:00 (åŒ—äº¬æ—¶é—´)
# BBæº: {BB_URL}
# æ¸¯æ¾³å°æº: {GAT_URL}
# EPGæº: {epg_url if epg_url else 'æ²¿ç”¨BBçš„EPG'}
# è‡ªåŠ¨åˆ†ç±»: é¦™æ¸¯é¢‘é“ã€å°æ¹¾é¢‘é“
# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ

"""
    
    # æ·»åŠ BBå†…å®¹ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
    bb_lines = bb_content.split('\n')
    bb_count = 0
    skip_first = True
    
    for line in bb_lines:
        line = line.rstrip()
        if not line:
            continue
        
        if skip_first and line.startswith('#EXTM3U'):
            skip_first = False
            continue
        
        output += line + '\n'
        if line.startswith('#EXTINF:'):
            bb_count += 1
    
    # æ·»åŠ é¦™æ¸¯é¢‘é“
    if hk_channels:
        output += f"\n# é¦™æ¸¯é¢‘é“ ({len(hk_channels)}ä¸ª)\n"
        
        # æŒ‰é¢‘é“åæ’åº
        hk_channels.sort(key=lambda x: x[2])
        
        for extinf, url, name in hk_channels:
            output += extinf + '\n'
            output += url + '\n'
    
    # æ·»åŠ å°æ¹¾é¢‘é“
    if tw_channels:
        output += f"\n# å°æ¹¾é¢‘é“ ({len(tw_channels)}ä¸ª)\n"
        
        # æŒ‰é¢‘é“åæ’åº
        tw_channels.sort(key=lambda x: x[2])
        
        for extinf, url, name in tw_channels:
            output += extinf + '\n'
            output += url + '\n'
    
    # æ·»åŠ ç»Ÿè®¡å’Œè¯´æ˜
    output += f"""
# ç»Ÿè®¡ä¿¡æ¯
# BB é¢‘é“æ•°: {bb_count}
# é¦™æ¸¯é¢‘é“æ•°: {len(hk_channels)} (è‡ªåŠ¨åˆ†ç±»)
# å°æ¹¾é¢‘é“æ•°: {len(tw_channels)} (è‡ªåŠ¨åˆ†ç±»)
# æ€»é¢‘é“æ•°: {bb_count + len(hk_channels) + len(tw_channels)}
# æ›´æ–°æ—¶é—´: {timestamp}
# æ›´æ–°é¢‘ç‡: æ¯å¤© 06:00 å’Œ 17:00 (åŒ—äº¬æ—¶é—´)
# åˆ†ç±»è§„åˆ™:
#   é¦™æ¸¯: {', '.join(HK_KEYWORDS[:10])}...
#   å°æ¹¾: {', '.join(TW_KEYWORDS[:10])}...
# EPGè¯´æ˜: æ²¿ç”¨BB.m3uçš„EPGæºï¼Œç¡®ä¿èŠ‚ç›®å•æ˜¾ç¤º
"""
    
    # 5. ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(output)
    
    log(f"\nğŸ‰ DD.m3uç”Ÿæˆå®Œæˆ!")
    log(f"ğŸ“ æ–‡ä»¶: {OUTPUT_FILE}")
    log(f"ğŸ“ å¤§å°: {len(output)} å­—ç¬¦")
    log(f"ğŸ“¡ EPG: {epg_url if epg_url else 'æ²¿ç”¨BB'}")
    log(f"ğŸ“º BBé¢‘é“: {bb_count}")
    log(f"ğŸ¯ é¦™æ¸¯é¢‘é“: {len(hk_channels)} (è‡ªåŠ¨åˆ†ç±»)")
    log(f"ğŸ¯ å°æ¹¾é¢‘é“: {len(tw_channels)} (è‡ªåŠ¨åˆ†ç±»)")
    log(f"ğŸ“º æ€»è®¡: {bb_count + len(hk_channels) + len(tw_channels)}")
    log(f"ğŸ•’ ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°: åŒ—äº¬æ—¶é—´ 06:00 å’Œ 17:00")

if __name__ == "__main__":
    main()
