#!/usr/bin/env python3
"""
CC.m3u åˆå¹¶è„šæœ¬ - æ ‡å‡†M3Uæ ¼å¼ï¼ˆæ”¯æŒEPGã€é¢‘é“æ’åºã€é¢‘é“è¿‡æ»¤ï¼‰
ä» https://stymei.sufern001.workers.dev/ æå–ï¼š
1. ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°
2. ğŸ”®æ¸¯æ¾³å°ç›´æ’­
å°†ç›¸åŒé¢‘é“åˆå¹¶ï¼Œæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼Œå¹¶æŒ‰æŒ‡å®šè§„åˆ™æ’åºã€è¿‡æ»¤
"""

import requests
from datetime import datetime
import os
import re
import hashlib
from collections import defaultdict

# ================== é…ç½®åŒºåŸŸ ==================
SOURCE_URL = "https://stymei.sufern001.workers.dev/"
BB_FILE = "BB.m3u"
OUTPUT_FILE = "CC.m3u"
EPG_URL = "http://epg.51zmt.top:8000/e.xml"  # EPGèŠ‚ç›®å•åœ°å€

# è¦æå–çš„æºåˆ†ç»„ï¼ˆå¯æ‰©å±•å¤šä¸ªï¼‰
SOURCE_GROUPS = [
    "ğŸ”¥å…¨ç½‘é€šæ¸¯æ¾³å°",
    "ğŸ”®æ¸¯æ¾³å°ç›´æ’­"
]
TARGET_GROUP = "å…¨ç½‘é€šæ¸¯æ¾³å°"  # åˆå¹¶åçš„ç»Ÿä¸€åˆ†ç»„å

# å°æ ‡æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
LOGO_SOURCES = [
    "https://raw.githubusercontent.com/iptv-org/iptv/master/logos/",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/",
    "https://raw.githubusercontent.com/lqist/IPTVlogos/main/",
]

# é¢‘é“æ’åºä¼˜å…ˆçº§ï¼ˆä¾æ¬¡ä¸º:å‡¤å‡°â†’NOWâ†’TVBâ†’HOYâ†’VIUTVâ†’å…¶ä»–ï¼‰
CHANNEL_PRIORITY = {
    # æœ€é«˜ä¼˜å…ˆçº§ï¼šå‡¤å‡°ç³»åˆ—
    "å‡¤å‡°ä¸­æ–‡": 1,
    "å‡¤å‡°èµ„è®¯": 2,
    "å‡¤å‡°é¦™æ¸¯": 3,
    "å‡¤å‡°ç”µå½±": 4,
    "å‡¤å‡°å«è§†": 5,
    # ç¬¬äºŒä¼˜å…ˆçº§ï¼šNOWç³»åˆ—
    "NOW": 10,
    "NOWæ–°é—»": 11,
    "NOWè´¢ç»": 12,
    "NOWä½“è‚²": 13,
    # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šTVBç³»åˆ—
    "TVB": 20,
    "ç¿¡ç¿ å°": 21,
    "æ˜ç å°": 22,
    "J2": 23,
    "æ— çº¿æ–°é—»": 24,
    "æ— çº¿è´¢ç»": 25,
    # ç¬¬å››ä¼˜å…ˆçº§ï¼šHOYç³»åˆ—
    "HOY": 30,
    "HOY TV": 31,
    "HOYèµ„è®¯å°": 32,
    "é¦™æ¸¯å¼€ç”µè§†": 33,  # HOY TVå‰èº«
    # ç¬¬äº”ä¼˜å…ˆçº§ï¼šVIUTVç³»åˆ—
    "VIUTV": 40,
    "VIUTVä¸­æ–‡å°": 41,
    "VIUTVç»¼è‰ºå°": 42,
    # å…¶ä»–é¢‘é“é»˜è®¤ä¼˜å…ˆçº§ï¼š100
}

# éœ€è¦å‰”é™¤çš„é¢‘é“å…³é”®è¯ï¼ˆå®Œå…¨åŒ¹é…æˆ–éƒ¨åˆ†åŒ¹é…ï¼‰
BLACKLIST_KEYWORDS = [
    "SPOTV",
    "GOODTV",
    "GOOD2",
    "ç•ªè–¯111",
    "äººé—´å«è§†",
    "å”¯å¿ƒç”µè§†",
    "ä¸­æ—ºç”µè§†",
    "ç”Ÿå‘½ç”µå½±",
    "å”äººå«è§†",
    "é¦™æ¸¯å«è§†",
    "å”NTD",
    "NTDTV",  # å¯èƒ½çš„ç›¸å…³é¢‘é“
    "æ–°å”äºº",  # å¯èƒ½çš„ç›¸å…³é¢‘é“
]

# ================== å·¥å…·å‡½æ•° ==================
def log(msg):
    """æ—¥å¿—è¾“å‡º"""
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def is_channel_blacklisted(channel_name):
    """æ£€æŸ¥é¢‘é“æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    for keyword in BLACKLIST_KEYWORDS:
        if keyword in channel_name:
            return True
    return False

def get_channel_priority(channel_name):
    """è·å–é¢‘é“æ’åºä¼˜å…ˆçº§"""
    # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
    for key, priority in CHANNEL_PRIORITY.items():
        if key == channel_name:
            return priority
    
    # æ£€æŸ¥éƒ¨åˆ†åŒ¹é…
    for key, priority in CHANNEL_PRIORITY.items():
        if key in channel_name:
            return priority
    
    # ç‰¹æ®Šè§„åˆ™ï¼šåŒ…å«"å‡¤å‡°"ä½†ä¸æ˜¯å·²å®šä¹‰çš„
    if "å‡¤å‡°" in channel_name and channel_name not in CHANNEL_PRIORITY:
        return 6  # å…¶ä»–å‡¤å‡°é¢‘é“æ”¾åœ¨å·²å®šä¹‰å‡¤å‡°é¢‘é“ä¹‹å
    
    # é»˜è®¤ä¼˜å…ˆçº§
    return 100

def sort_channels(channel_dict):
    """æŒ‰æŒ‡å®šè§„åˆ™æ’åºé¢‘é“"""
    # è½¬æ¢ä¸ºåˆ—è¡¨ä¾¿äºæ’åº
    channels_list = [(name, data) for name, data in channel_dict.items()]
    
    # æ’åºè§„åˆ™ï¼š1.ä¼˜å…ˆçº§ 2.é¢‘é“åç§°
    def sort_key(item):
        channel_name = item[0]
        priority = get_channel_priority(channel_name)
        return (priority, channel_name)
    
    sorted_channels = sorted(channels_list, key=sort_key)
    
    # è½¬æ¢å›å­—å…¸
    sorted_dict = {name: data for name, data in sorted_channels}
    
    # è®°å½•æ’åºä¿¡æ¯
    log(f"é¢‘é“æ’åºå®Œæˆï¼Œä¼˜å…ˆçº§åˆ†å¸ƒ:")
    priority_groups = defaultdict(list)
    for name, _ in sorted_channels:
        priority = get_channel_priority(name)
        priority_groups[priority].append(name)
    
    for priority in sorted(priority_groups.keys()):
        if priority <= 40:  # åªæ˜¾ç¤ºä¸»è¦ä¼˜å…ˆçº§ç»„
            group_name = {
                1: "å‡¤å‡°ç³»åˆ—",
                10: "NOWç³»åˆ—",
                20: "TVBç³»åˆ—",
                30: "HOYç³»åˆ—",
                40: "VIUTVç³»åˆ—"
            }.get(priority, f"ä¼˜å…ˆçº§{priority}")
            log(f"  {group_name}: {len(priority_groups[priority])}ä¸ªé¢‘é“")
    
    return sorted_dict

def get_channel_logo(channel_name):
    """æ ¹æ®é¢‘é“ååŒ¹é…å°æ ‡"""
    # é¢‘é“åæ˜ å°„è¡¨ï¼ˆå¯è‡ªè¡Œæ‰©å±•ï¼‰
    logo_map = {
        # å‡¤å‡°ç³»åˆ—
        "å‡¤å‡°ä¸­æ–‡": "phoenix.chinese.png",
        "å‡¤å‡°èµ„è®¯": "phoenix.infonews.png",
        "å‡¤å‡°é¦™æ¸¯": "phoenix.hongkong.png",
        "å‡¤å‡°å«è§†": "phoenix.tv.png",
        "å‡¤å‡°ç”µå½±": "phoenix.movie.png",
        # TVBç³»åˆ—
        "ç¿¡ç¿ å°": "tvb.jade.png",
        "æ˜ç å°": "tvb.pearl.png",
        "J2": "tvb.j2.png",
        "TVB": "tvb.png",
        # HOYç³»åˆ—
        "HOY": "hoy.png",
        "HOY TV": "hoy.tv.png",
        "é¦™æ¸¯å¼€ç”µè§†": "hoy.tv.png",
        # VIUTVç³»åˆ—
        "VIUTV": "viutv.png",
        # NOWç³»åˆ—
        "NOW": "now.png",
        "NOWæ–°é—»": "now.news.png",
        # å…¶ä»–å¸¸è§é¢‘é“
        "ä¸­å¤©": "cti.png",
        "ä¸œæ£®": "ettv.png",
        "ä¸‰ç«‹": "set.png",
        "æ°‘è§†": "ftv.png",
    }
    
    # 1. ç²¾ç¡®åŒ¹é…
    for key, filename in logo_map.items():
        if key in channel_name:
            for source in LOGO_SOURCES:
                logo_url = f"{source}{filename}"
                return logo_url
    
    # 2. å…³é”®è¯åŒ¹é…
    keywords = {
        "æ–°é—»": "news.png",
        "ä½“è‚²": "sports.png",
        "ç”µå½±": "movie.png",
        "éŸ³ä¹": "music.png",
        "è´¢ç»": "finance.png",
    }
    
    for keyword, filename in keywords.items():
        if keyword in channel_name:
            for source in LOGO_SOURCES:
                logo_url = f"{source}{filename}"
                return logo_url
    
    # 3. è¿”å›é»˜è®¤å°æ ‡
    return "https://raw.githubusercontent.com/iptv-org/iptv/master/logos/default.png"

def extract_tvg_info(channel_name):
    """ç”Ÿæˆé¢‘é“çš„tvgä¿¡æ¯"""
    # æ¸…ç†åç§°ç”Ÿæˆtvg-id
    clean_name = re.sub(r'[^\w\u4e00-\u9fff]', '', channel_name)
    
    # ä½¿ç”¨MD5ç”Ÿæˆä¸€è‡´çš„tvg-idï¼Œç¡®ä¿ç›¸åŒé¢‘é“åæœ‰ç›¸åŒID
    tvg_id = f"channel_{hashlib.md5(channel_name.encode()).hexdigest()[:8]}"
    tvg_name = channel_name
    logo_url = get_channel_logo(channel_name)
    
    return tvg_id, tvg_name, logo_url

def download_source():
    """ä¸‹è½½æºæ•°æ®"""
    try:
        log(f"æ­£åœ¨ä¸‹è½½æºæ•°æ®: {SOURCE_URL}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/plain'
        }
        response = requests.get(SOURCE_URL, headers=headers, timeout=30)
        response.raise_for_status()
        content = response.text
        log(f"âœ… ä¸‹è½½æˆåŠŸï¼Œ{len(content)} å­—ç¬¦")
        return content
    except Exception as e:
        log(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None

def extract_and_merge_channels(content):
    """
    ä»å†…å®¹ä¸­æå–æŒ‡å®šåˆ†ç»„çš„æ‰€æœ‰é¢‘é“ï¼Œå¹¶åˆå¹¶ç›¸åŒé¢‘é“çš„å¤šä¸ªæº
    è¿”å›ç»“æ„: {channel_name: {tvg_id, tvg_name, logo, group, urls: [url1, url2, ...]}}
    """
    if not content:
        return {}
    
    # ä½¿ç”¨å­—å…¸åˆå¹¶ç›¸åŒé¢‘é“ï¼Œå€¼æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰URLçš„åˆ—è¡¨
    channel_dict = defaultdict(lambda: {
        'name': '',
        'tvg_id': '',
        'tvg_name': '',
        'logo': '',
        'group': TARGET_GROUP,
        'urls': [],  # å­˜å‚¨å¤šä¸ªæ’­æ”¾åœ°å€
        'source_groups': set()  # è®°å½•æ¥æºåˆ†ç»„
    })
    
    lines = content.split('\n')
    
    log(f"å¼€å§‹æå–å¹¶åˆå¹¶åˆ†ç»„: {SOURCE_GROUPS}")
    log(f"é»‘åå•è¿‡æ»¤: {BLACKLIST_KEYWORDS}")
    
    for source_group in SOURCE_GROUPS:
        in_section = False
        group_found = False
        group_count = 0
        blacklist_count = 0
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # æŸ¥æ‰¾åˆ†ç»„å¼€å§‹
            if f"{source_group},#genre#" in line:
                log(f"âœ… æ‰¾åˆ°åˆ†ç»„: {source_group} (ç¬¬{i+1}è¡Œ)")
                in_section = True
                group_found = True
                continue
            
            # å¦‚æœå·²åœ¨åˆ†ç»„ä¸­ï¼Œé‡åˆ°ä¸‹ä¸€ä¸ªåˆ†ç»„åˆ™ç»“æŸ
            if in_section and '#genre#' in line and source_group not in line:
                break
            
            # æå–é¢‘é“
            if in_section and line and ',' in line:
                parts = line.split(',')
                if len(parts) >= 2:
                    channel_name = parts[0].strip()
                    url = ','.join(parts[1:]).strip()
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­
                    if is_channel_blacklisted(channel_name):
                        blacklist_count += 1
                        log(f"  è¿‡æ»¤é»‘åå•é¢‘é“: {channel_name}")
                        continue
                    
                    if url and ('://' in url or url.startswith('http')):
                        # å¦‚æœæ˜¯é¦–æ¬¡é‡åˆ°è¿™ä¸ªé¢‘é“ï¼Œç”Ÿæˆtvgä¿¡æ¯
                        if channel_name not in channel_dict or not channel_dict[channel_name]['tvg_id']:
                            tvg_id, tvg_name, logo_url = extract_tvg_info(channel_name)
                            channel_dict[channel_name].update({
                                'name': channel_name,
                                'tvg_id': tvg_id,
                                'tvg_name': tvg_name,
                                'logo': logo_url,
                                'group': TARGET_GROUP,
                            })
                        
                        # æ·»åŠ URLåˆ°åˆ—è¡¨
                        if url not in channel_dict[channel_name]['urls']:
                            channel_dict[channel_name]['urls'].append(url)
                            channel_dict[channel_name]['source_groups'].add(source_group)
                            group_count += 1
        
        if group_found:
            log(f"  ä»ã€Œ{source_group}ã€æå– {group_count} ä¸ªæ’­æ”¾æºï¼Œè¿‡æ»¤ {blacklist_count} ä¸ªé»‘åå•é¢‘é“")
        else:
            log(f"âš ï¸  æœªæ‰¾åˆ°åˆ†ç»„: {source_group}")
    
    # è½¬æ¢ä¸ºæ™®é€šå­—å…¸
    result = dict(channel_dict)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_channels = len(result)
    total_urls = sum(len(ch['urls']) for ch in result.values())
    
    log(f"âœ… åˆå¹¶åå¾—åˆ° {total_channels} ä¸ªå”¯ä¸€é¢‘é“ï¼Œå…± {total_urls} ä¸ªæ’­æ”¾æº")
    
    # æ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡
    if blacklist_count > 0:
        log(f"âœ… å…±è¿‡æ»¤ {blacklist_count} ä¸ªé»‘åå•é¢‘é“")
    
    # æ˜¾ç¤ºåˆå¹¶ç¤ºä¾‹
    if result:
        log("é¢‘é“åˆå¹¶ç¤ºä¾‹:")
        for name, data in list(result.items())[:3]:
            log(f"  {name}: {len(data['urls'])} ä¸ªæ’­æ”¾æº (æ¥è‡ª: {', '.join(data['source_groups'])})")
    
    return result

def load_local_m3u():
    """åŠ è½½æœ¬åœ°BB.m3uæ–‡ä»¶"""
    try:
        if not os.path.exists(BB_FILE):
            log(f"âš ï¸  {BB_FILE} ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æ–‡ä»¶")
            default_content = f"""#EXTM3U
#EXTINF:-1 tvg-id="" tvg-name="æœ¬åœ°æµ‹è¯•1" tvg-logo="" group-title="æœ¬åœ°",æœ¬åœ°æµ‹è¯•1
http://example.com/local1
#EXTINF:-1 tvg-id="" tvg-name="æœ¬åœ°æµ‹è¯•2" tvg-logo="" group-title="æœ¬åœ°",æœ¬åœ°æµ‹è¯•2
http://example.com/local2"""
            with open(BB_FILE, 'w', encoding='utf-8') as f:
                f.write(default_content)
            return default_content
        
        with open(BB_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        log(f"âœ… åŠ è½½æœ¬åœ°æ–‡ä»¶æˆåŠŸï¼Œ{len(content.splitlines())} è¡Œ")
        return content
    except Exception as e:
        log(f"âŒ åŠ è½½æœ¬åœ°æ–‡ä»¶å¤±è´¥: {e}")
        return "#EXTM3U\n"

def generate_m3u_content(local_content, channel_dict):
    """ç”Ÿæˆæœ€ç»ˆçš„M3Uå†…å®¹ï¼ˆæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼‰"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    output_lines = [
        f'#EXTM3U url-tvg="{EPG_URL}"',
        f"# CC.m3u - è‡ªåŠ¨ç”Ÿæˆï¼ˆEPG+æ’åº+è¿‡æ»¤ç‰ˆï¼‰",
        f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
        f"# æºåœ°å€: {SOURCE_URL}",
        f"# EPGåœ°å€: {EPG_URL}",
        f"# æå–åˆ†ç»„: {', '.join(SOURCE_GROUPS)} â†’ {TARGET_GROUP}",
        f"# æ’åºè§„åˆ™: å‡¤å‡°â†’NOWâ†’TVBâ†’HOYâ†’VIUTVâ†’å…¶ä»–",
        f"# è¿‡æ»¤é¢‘é“: {', '.join(BLACKLIST_KEYWORDS)}",
        f"# å”¯ä¸€é¢‘é“æ•°: {len(channel_dict)}",
        f"# GitHub Actions è‡ªåŠ¨ç”Ÿæˆ",
        ""
    ]
    
    # æ·»åŠ æœ¬åœ°å†…å®¹
    if local_content and local_content.strip():
        output_lines.append("#" + "=" * 60)
        output_lines.append("# æœ¬åœ°é¢‘é“")
        output_lines.append("#" + "=" * 60)
        output_lines.append("")
        
        local_lines = local_content.split('\n')
        for line in local_lines:
            if line.strip() == "#EXTM3U" and len(output_lines) > 8:
                continue
            output_lines.append(line)
        
        output_lines.append("")
    
    # æ·»åŠ æ¸¯æ¾³å°é¢‘é“ï¼ˆæ”¯æŒå¤šæ’­æ”¾åœ°å€ï¼‰
    if channel_dict:
        output_lines.append("#" + "=" * 60)
        output_lines.append(f"# {TARGET_GROUP} (åˆå¹¶è‡ª: {', '.join(SOURCE_GROUPS)})")
        output_lines.append("# è¯´æ˜ï¼šæ¯ä¸ªé¢‘é“å¯èƒ½åŒ…å«å¤šä¸ªæ’­æ”¾åœ°å€ï¼Œæ’­æ”¾å™¨ä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨æº")
        output_lines.append("# æ’åºï¼šå‡¤å‡°ç³»åˆ—â†’NOWç³»åˆ—â†’TVBç³»åˆ—â†’HOYç³»åˆ—â†’VIUTVç³»åˆ—â†’å…¶ä»–")
        output_lines.append("#" + "=" * 60)
        output_lines.append("")
        
        # æ·»åŠ åˆ†ç»„æ ‡é¢˜ä¾¿äºè¯†åˆ«
        current_priority = None
        for i, (channel_name, data) in enumerate(channel_dict.items(), 1):
            priority = get_channel_priority(channel_name)
            
            # æ·»åŠ åˆ†ç»„åˆ†éš”
            if current_priority != priority:
                current_priority = priority
                group_name = {
                    1: "å‡¤å‡°ç³»åˆ—",
                    2: "å‡¤å‡°ç³»åˆ—",
                    3: "å‡¤å‡°ç³»åˆ—",
                    4: "å‡¤å‡°ç³»åˆ—",
                    5: "å‡¤å‡°ç³»åˆ—",
                    6: "å‡¤å‡°ç³»åˆ—",
                    10: "NOWç³»åˆ—",
                    11: "NOWç³»åˆ—",
                    12: "NOWç³»åˆ—",
                    13: "NOWç³»åˆ—",
                    20: "TVBç³»åˆ—",
                    21: "TVBç³»åˆ—",
                    22: "TVBç³»åˆ—",
                    23: "TVBç³»åˆ—",
                    24: "TVBç³»åˆ—",
                    25: "TVBç³»åˆ—",
                    30: "HOYç³»åˆ—",
                    31: "HOYç³»åˆ—",
                    32: "HOYç³»åˆ—",
                    33: "HOYç³»åˆ—",
                    40: "VIUTVç³»åˆ—",
                    41: "VIUTVç³»åˆ—",
                    42: "VIUTVç³»åˆ—",
                }.get(priority, "å…¶ä»–é¢‘é“")
                
                if i > 1:  # ä¸æ˜¯ç¬¬ä¸€ä¸ªé¢‘é“æ‰æ·»åŠ ç©ºè¡Œ
                    output_lines.append("")
                output_lines.append(f"# --- {group_name} ---")
            
            # EXTINF è¡Œ
            extinf = f'#EXTINF:-1 tvg-id="{data["tvg_id"]}" tvg-name="{data["tvg_name"]}" tvg-logo="{data["logo"]}" group-title="{TARGET_GROUP}",{channel_name}'
            output_lines.append(extinf)
            
            # å¤šä¸ªæ’­æ”¾åœ°å€ï¼ˆæ¯ä¸ªåœ°å€ä¸€è¡Œï¼‰
            for url in data['urls']:
                output_lines.append(url)
        
        # ç§»é™¤æœ€åçš„ç©ºè¡Œï¼ˆå¦‚æœæœ‰ï¼‰
        while output_lines and output_lines[-1] == "":
            output_lines.pop()
    
    # ç»Ÿè®¡ä¿¡æ¯
    output_lines.append("")
    output_lines.append("#" + "=" * 60)
    output_lines.append("# ç»Ÿè®¡ä¿¡æ¯")
    local_channels = len([l for l in local_content.split('\n') if l.startswith('#EXTINF')])
    total_urls = sum(len(ch['urls']) for ch in channel_dict.values())
    
    # ç»Ÿè®¡å„ç³»åˆ—æ•°é‡
    series_count = defaultdict(int)
    for channel_name in channel_dict.keys():
        priority = get_channel_priority(channel_name)
        series = {
            1: "å‡¤å‡°", 2: "å‡¤å‡°", 3: "å‡¤å‡°", 4: "å‡¤å‡°", 5: "å‡¤å‡°", 6: "å‡¤å‡°",
            10: "NOW", 11: "NOW", 12: "NOW", 13: "NOW",
            20: "TVB", 21: "TVB", 22: "TVB", 23: "TVB", 24: "TVB", 25: "TVB",
            30: "HOY", 31: "HOY", 32: "HOY", 33: "HOY",
            40: "VIUTV", 41: "VIUTV", 42: "VIUTV",
        }.get(priority, "å…¶ä»–")
        series_count[series] += 1
    
    output_lines.append(f"# æœ¬åœ°é¢‘é“æ•°: {local_channels}")
    output_lines.append(f"# æ¸¯æ¾³å°å”¯ä¸€é¢‘é“æ•°: {len(channel_dict)}")
    output_lines.append(f"# æ¸¯æ¾³å°æ’­æ”¾æºæ€»æ•°: {total_urls}")
    
    if series_count:
        output_lines.append("# é¢‘é“ç³»åˆ—åˆ†å¸ƒ:")
        for series in ["å‡¤å‡°", "NOW", "TVB", "HOY", "VIUTV", "å…¶ä»–"]:
            if series_count.get(series, 0) > 0:
                output_lines.append(f"#   {series}: {series_count[series]}ä¸ªé¢‘é“")
    
    output_lines.append(f"# æ›´æ–°æ—¶é—´: {timestamp}")
    output_lines.append("# EPGèŠ‚ç›®å•: å·²é›†æˆï¼Œæ’­æ”¾å™¨ä¼šè‡ªåŠ¨åŠ è½½")
    output_lines.append("#" + "=" * 60)
    
    return '\n'.join(output_lines)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    log("å¼€å§‹ç”Ÿæˆ CC.m3uï¼ˆEPG+æ’åº+è¿‡æ»¤ç‰ˆï¼‰...")
    print("=" * 70)
    
    try:
        # 1. ä¸‹è½½æºæ•°æ®
        source_content = download_source()
        if not source_content:
            log("âŒ æ— æ³•è·å–æºæ•°æ®ï¼Œé€€å‡º")
            return
        
        # 2. æå–å¹¶åˆå¹¶é¢‘é“
        channel_dict = extract_and_merge_channels(source_content)
        
        if not channel_dict:
            log("âš ï¸  æœªæå–åˆ°ä»»ä½•é¢‘é“ï¼Œæ£€æŸ¥æºæ•°æ®æ ¼å¼")
            # æ˜¾ç¤ºå‰5ä¸ªåˆ†ç»„ä¾›è°ƒè¯•
            lines = source_content.split('\n')
            log("æºæ•°æ®ä¸­çš„åˆ†ç»„:")
            count = 0
            for line in lines:
                if '#genre#' in line and count < 5:
                    log(f"  - {line}")
                    count += 1
        
        # 3. æŒ‰è§„åˆ™æ’åºé¢‘é“
        log("å¼€å§‹æŒ‰è§„åˆ™æ’åºé¢‘é“...")
        sorted_channel_dict = sort_channels(channel_dict)
        
        # 4. åŠ è½½æœ¬åœ°æ–‡ä»¶
        local_content = load_local_m3u()
        
        # 5. ç”Ÿæˆå†…å®¹
        m3u_content = generate_m3u_content(local_content, sorted_channel_dict)
        
        # 6. ä¿å­˜æ–‡ä»¶
        with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='\n') as f:
            f.write(m3u_content)
        
        # 7. éªŒè¯ç»“æœ
        if os.path.exists(OUTPUT_FILE):
            file_size = os.path.getsize(OUTPUT_FILE)
            line_count = m3u_content.count('\n') + 1
            
            print("\n" + "=" * 70)
            log("âœ… CC.m3u ç”ŸæˆæˆåŠŸ!")
            log(f"   æ–‡ä»¶ä½ç½®: {os.path.abspath(OUTPUT_FILE)}")
            log(f"   æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            log(f"   æ€»è¡Œæ•°: {line_count}")
            log(f"   å”¯ä¸€é¢‘é“æ•°: {len(sorted_channel_dict)}")
            log(f"   EPGåœ°å€: {EPG_URL}")
            
            # æ˜¾ç¤ºæ’åºç»“æœ
            print("\nğŸ“‹ é¢‘é“æ’åºç»“æœï¼ˆå‰10ä¸ªï¼‰:")
            print("-" * 70)
            for i, (name, data) in enumerate(list(sorted_channel_dict.items())[:10]):
                priority = get_channel_priority(name)
                series = {
                    1: "å‡¤å‡°", 2: "å‡¤å‡°", 3: "å‡¤å‡°", 4: "å‡¤å‡°", 5: "å‡¤å‡°", 6: "å‡¤å‡°": "å‡¤å‡°",
                    10: "NOW", 11: "NOW", 12: "NOW", 13: "NOW": "NOW",
                    20: "TVB", 21: "TVB", 22: "TVB", 23: "TVB", 24: "TVB", 25: "TVB": "TVB",
                    30: "HOY", 31: "HOY", 32: "HOY", 33: "HOY": "HOY",
                    40: "VIUTV", 41: "VIUTV", 42: "VIUTV": "VIUTV",
                }.get(priority, "å…¶ä»–")
                print(f"{i+1:2d}. [{series}] {name} ({len(data['urls'])}ä¸ªæº)")
            print("-" * 70)
            
            # æ˜¾ç¤ºè¿‡æ»¤ç»“æœ
            print("\nğŸš« å·²è¿‡æ»¤çš„é»‘åå•é¢‘é“:")
            lines = source_content.split('\n')
            filtered = []
            for line in lines:
                if ',' in line:
                    channel_name = line.split(',')[0].strip()
                    if is_channel_blacklisted(channel_name):
                        filtered.append(channel_name)
            
            if filtered:
                for i, name in enumerate(filtered[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                    print(f"  {i+1}. {name}")
                if len(filtered) > 10:
                    print(f"  ... è¿˜æœ‰{len(filtered)-10}ä¸ª")
            else:
                print("  æ— åŒ¹é…çš„é»‘åå•é¢‘é“")
            
            # æ˜¾ç¤ºæ–‡ä»¶å¤´
            print("\nğŸ“„ ç”Ÿæˆæ–‡ä»¶å¤´éƒ¨:")
            print("-" * 50)
            lines = m3u_content.split('\n')
            for line in lines[:15]:
                print(line)
            print("-" * 50)
            
        else:
            log("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
    
    except Exception as e:
        log(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("=" * 70)
    log("æ‰§è¡Œå®Œæˆ")
    print("=" * 70)

if __name__ == "__main__":
    main()
