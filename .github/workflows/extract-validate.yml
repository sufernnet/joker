name: Extract and Validate HK/TW Channels

on:
  schedule:
    - cron: '0 6 * * *'   # UTC 6:00
    - cron: '0 18 * * *'  # UTC 18:00
  workflow_dispatch:
    inputs:
      skip_validation:
        description: 'è·³è¿‡æ’­æ”¾éªŒè¯ï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰'
        required: false
        default: 'false'
        type: boolean

jobs:
  extract-and-validate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
      
      - name: Install Python dependencies
        run: pip install requests
      
      - name: Create extraction script
        run: |
          mkdir -p scripts
          # ç›´æŽ¥åœ¨scriptsç›®å½•åˆ›å»ºæ–‡ä»¶
          cat > scripts/tv_extractor_new.py << 'EOF'
#!/usr/bin/env python3
"""
ä»Žä¸¤ä¸ªTVæºä¸­æå–HKå’ŒTWé¢‘é“ï¼Œæ ¡éªŒæ’­æ”¾çŠ¶æ€åŽä¸ŽBB.m3uåˆå¹¶
"""

import requests
import re
import os
import sys
import time
import subprocess
from datetime import datetime
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
HK_SOURCE_URL = "https://hacks.sufern001.workers.dev/?type=hk"
TW_SOURCE_URL = "https://hacks.sufern001.workers.dev/?type=tw"
EPG_URL = "http://epg.51zmt.top:8000/e.xml"
BB_FILE = "BB.m3u"  # å‡è®¾BB.m3uåœ¨ä»“åº“æ ¹ç›®å½•
OUTPUT_FILE = "../EE.m3u"  # ä¸Šä¸€çº§ç›®å½•
FFMPEG_PATH = "ffmpeg"  # å‡è®¾ffmpegå·²å®‰è£…
TIMEOUT = 10  # æ’­æ”¾æ ¡éªŒè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_WORKERS = 5  # å¹¶å‘æ ¡éªŒæœ€å¤§çº¿ç¨‹æ•°

def fetch_m3u_content(url, source_name):
    """èŽ·å–M3Uæ–‡ä»¶å†…å®¹"""
    try:
        logger.info(f"æ­£åœ¨ä»Ž {source_name} ä¸‹è½½M3Uæ–‡ä»¶...")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        content = response.text
        
        if not content.strip().startswith("#EXTM3U"):
            logger.warning(f"{source_name} å†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„M3Uæ ¼å¼")
            
        logger.info(f"{source_name} ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(content)} å­—ç¬¦")
        return content
    except requests.RequestException as e:
        logger.error(f"ä¸‹è½½ {source_name} å¤±è´¥: {e}")
        return None

def read_bb_file():
    """è¯»å–BB.m3uæ–‡ä»¶å†…å®¹"""
    try:
        # BB.m3uåœ¨ä»“åº“æ ¹ç›®å½•
        bb_path = "../BB.m3u"
        if os.path.exists(bb_path):
            with open(bb_path, 'r', encoding='utf-8') as f:
                content = f.read()
            logger.info(f"è¯»å–BB.m3uæˆåŠŸï¼Œå¤§å°: {len(content)} å­—ç¬¦")
            return content
        else:
            logger.warning(f"BB.m3uæ–‡ä»¶ä¸å­˜åœ¨: {bb_path}")
            return None
    except Exception as e:
        logger.error(f"è¯»å–BB.m3uå¤±è´¥: {e}")
        return None

def parse_m3u_content(content, default_group):
    """è§£æžM3Uå†…å®¹ï¼Œè¿”å›žé¢‘é“åˆ—è¡¨"""
    if not content:
        return []
    
    channels = []
    lines = content.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        if not line:
            i += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é¢‘é“ä¿¡æ¯è¡Œ
        if line.startswith("#EXTINF"):
            # æå–é¢‘é“ä¿¡æ¯
            extinf_line = line
            
            # æŸ¥æ‰¾å¯¹åº”çš„URLè¡Œ
            j = i + 1
            url_line = ""
            while j < len(lines):
                temp_line = lines[j].strip()
                if not temp_line:
                    j += 1
                    continue
                if temp_line.startswith("#EXTINF"):
                    break
                if temp_line and not temp_line.startswith("#"):
                    url_line = temp_line
                    break
                j += 1
            
            if url_line:
                # æå–é¢‘é“åç§°
                channel_name = "æœªçŸ¥é¢‘é“"
                name_match = re.search(r',([^,]+)$', extinf_line)
                if name_match:
                    channel_name = name_match.group(1).strip()
                
                # æå–åŽŸå§‹åˆ†ç»„
                original_group = default_group
                group_match = re.search(r'group-title="([^"]+)"', extinf_line)
                if group_match:
                    original_group = group_match.group(1)
                
                # åˆ›å»ºæ–°çš„EXTINFè¡Œï¼Œç»Ÿä¸€åˆ†ç»„
                new_extinf = re.sub(r'group-title="[^"]+"', f'group-title="{default_group}"', extinf_line)
                if 'group-title=' not in new_extinf:
                    # å¦‚æžœåŽŸæ¥æ²¡æœ‰åˆ†ç»„ä¿¡æ¯ï¼Œæ·»åŠ åˆ†ç»„
                    new_extinf = new_extinf.replace('#EXTINF:', f'#EXTINF: group-title="{default_group}",', 1)
                
                channel_data = {
                    'original_extinf': extinf_line,
                    'extinf': new_extinf,
                    'url': url_line,
                    'name': channel_name,
                    'group': default_group,
                    'original_group': original_group,
                    'working': None  # æ˜¯å¦å¯æ’­æ”¾ï¼ŒNoneè¡¨ç¤ºæœªæ£€æŸ¥
                }
                channels.append(channel_data)
        
        i += 1
    
    return channels

def check_stream_playable(url, channel_name):
    """æ£€æŸ¥æµæ˜¯å¦å¯ä»¥æ’­æ”¾"""
    try:
        # ä½¿ç”¨ffprobeæ£€æŸ¥æµ
        command = [
            FFMPEG_PATH, '-hide_banner', '-loglevel', 'error',
            '-timeout', str(TIMEOUT * 1000000),  # å¾®ç§’
            '-i', url,
            '-t', '5',  # åªæ£€æŸ¥5ç§’
            '-f', 'null', '-'
        ]
        
        logger.debug(f"æ£€æŸ¥é¢‘é“: {channel_name} - {url}")
        
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=TIMEOUT + 2
        )
        
        # æ ¹æ®è¿”å›žç åˆ¤æ–­
        if result.returncode == 0:
            return True
        else:
            # æ£€æŸ¥é”™è¯¯ä¿¡æ¯ä¸­æ˜¯å¦åŒ…å«è¶…æ—¶æˆ–è¿žæŽ¥å¤±è´¥
            error_msg = result.stderr.decode('utf-8', errors='ignore').lower()
            if 'timeout' in error_msg or 'connection refused' in error_msg:
                return False
            # æœ‰äº›æµå¯èƒ½è¿”å›žéž0ä½†å®žé™…ä¸Šæ˜¯å¯æ’­æ”¾çš„
            return True
            
    except subprocess.TimeoutExpired:
        logger.warning(f"é¢‘é“æ£€æŸ¥è¶…æ—¶: {channel_name}")
        return False
    except Exception as e:
        logger.warning(f"æ£€æŸ¥é¢‘é“å¤±è´¥ {channel_name}: {e}")
        return False

def validate_channels(channels):
    """éªŒè¯é¢‘é“æ˜¯å¦å¯ä»¥æ’­æ”¾"""
    logger.info(f"å¼€å§‹éªŒè¯ {len(channels)} ä¸ªé¢‘é“çš„æ’­æ”¾çŠ¶æ€...")
    
    valid_channels = []
    invalid_channels = []
    
    # å¦‚æžœæ²¡æœ‰ffmpegï¼Œè·³è¿‡éªŒè¯
    try:
        subprocess.run([FFMPEG_PATH, '-version'], 
                      stdout=subprocess.PIPE, 
                      stderr=subprocess.PIPE,
                      timeout=5)
        has_ffmpeg = True
        logger.info("æ£€æµ‹åˆ°ffmpegï¼Œå°†è¿›è¡Œæ’­æ”¾éªŒè¯")
    except:
        has_ffmpeg = False
        logger.warning("æœªæ£€æµ‹åˆ°ffmpegï¼Œè·³è¿‡æ’­æ”¾éªŒè¯")
        return channels, []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘éªŒè¯
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_channel = {}
        for channel in channels:
            future = executor.submit(
                check_stream_playable, 
                channel['url'], 
                channel['name']
            )
            future_to_channel[future] = channel
        
        completed = 0
        for future in as_completed(future_to_channel):
            channel = future_to_channel[future]
            try:
                is_playable = future.result()
                channel['working'] = is_playable
                
                if is_playable:
                    valid_channels.append(channel)
                    logger.info(f"âœ… å¯æ’­æ”¾: {channel['name']}")
                else:
                    invalid_channels.append(channel)
                    logger.warning(f"âŒ ä¸å¯æ’­æ”¾: {channel['name']}")
                
                completed += 1
                if completed % 10 == 0:
                    logger.info(f"éªŒè¯è¿›åº¦: {completed}/{len(channels)}")
                    
            except Exception as e:
                logger.error(f"éªŒè¯é¢‘é“å¼‚å¸¸ {channel['name']}: {e}")
                invalid_channels.append(channel)
    
    logger.info(f"éªŒè¯å®Œæˆ: {len(valid_channels)} ä¸ªå¯æ’­æ”¾, {len(invalid_channels)} ä¸ªä¸å¯æ’­æ”¾")
    return valid_channels, invalid_channels

def build_m3u_content(hk_channels, tw_channels):
    """æž„å»ºM3Uæ–‡ä»¶å†…å®¹"""
    lines = []
    
    # æ·»åŠ æ–‡ä»¶å¤´
    lines.append(f'#EXTM3U url-tvg="{EPG_URL}"')
    
    # æ·»åŠ ç”Ÿæˆä¿¡æ¯
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    lines.append(f"# ç”Ÿæˆæ—¶é—´: {timestamp}")
    lines.append(f"# HKæºåœ°å€: {HK_SOURCE_URL}")
    lines.append(f"# TWæºåœ°å€: {TW_SOURCE_URL}")
    lines.append(f"# EPGæº: {EPG_URL}")
    lines.append("# åŒ…å«å†…å®¹: BB.m3u + HKé¢‘é“ + TWé¢‘é“")
    lines.append("# è‡ªåŠ¨æ›´æ–°é¢‘é“åˆ—è¡¨")
    lines.append("")
    
    # æ·»åŠ HKé¢‘é“
    if hk_channels:
        lines.append("#" + "="*60)
        lines.append("# HKé¢‘é“")
        lines.append("#" + "="*60)
        lines.append("")
        
        for channel in hk_channels:
            lines.append(channel['extinf'])
            lines.append(channel['url'])
        
        lines.append("")
    
    # æ·»åŠ TWé¢‘é“
    if tw_channels:
        lines.append("#" + "="*60)
        lines.append("# TWé¢‘é“")
        lines.append("#" + "="*60)
        lines.append("")
        
        for channel in tw_channels:
            lines.append(channel['extinf'])
            lines.append(channel['url'])
    
    return '\n'.join(lines)

def merge_with_bb(tv_content, bb_content):
    """å°†æå–çš„TVå†…å®¹ä¸ŽBB.m3uåˆå¹¶"""
    merged_lines = []
    
    # æ·»åŠ æ–‡ä»¶å¤´
    merged_lines.append(f'#EXTM3U url-tvg="{EPG_URL}"')
    
    # æ·»åŠ ç”Ÿæˆä¿¡æ¯
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    merged_lines.append(f"# ç”Ÿæˆæ—¶é—´: {timestamp}")
    merged_lines.append(f"# HKæºåœ°å€: {HK_SOURCE_URL}")
    merged_lines.append(f"# TWæºåœ°å€: {TW_SOURCE_URL}")
    merged_lines.append(f"# EPGæº: {EPG_URL}")
    merged_lines.append("# åŒ…å«å†…å®¹: BB.m3u + HKé¢‘é“ + TWé¢‘é“")
    merged_lines.append("# è‡ªåŠ¨æ›´æ–°é¢‘é“åˆ—è¡¨")
    merged_lines.append("")
    
    # å¦‚æžœæœ‰BBå†…å®¹ï¼Œå…ˆæ·»åŠ BBçš„å†…å®¹ï¼ˆè·³è¿‡å…¶æ–‡ä»¶å¤´ï¼‰
    if bb_content:
        bb_lines = bb_content.split('\n')
        bb_count = 0
        for line in bb_lines:
            line = line.strip()
            if line:
                if line.startswith("#EXTM3U"):
                    continue  # è·³è¿‡BBçš„æ–‡ä»¶å¤´
                if line.startswith("#EXTINF"):
                    bb_count += 1
                merged_lines.append(line)
        
        if bb_count > 0:
            logger.info(f"åˆå¹¶äº† {bb_count} ä¸ªBBé¢‘é“")
            merged_lines.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
            merged_lines.append("#" + "="*60)
            merged_lines.append("# ä»¥ä¸‹ä¸ºHKå’ŒTWé¢‘é“ï¼ˆå·²éªŒè¯å¯æ’­æ”¾ï¼‰")
            merged_lines.append("#" + "="*60)
            merged_lines.append("")
    
    # æ·»åŠ æå–çš„TVå†…å®¹ï¼ˆè·³è¿‡æ–‡ä»¶å¤´ï¼‰
    if tv_content:
        tv_lines = tv_content.split('\n')
        for line in tv_lines:
            line = line.strip()
            if line:
                merged_lines.append(line)
    
    return '\n'.join(merged_lines)

def save_m3u_file(content):
    """ä¿å­˜M3Uæ–‡ä»¶"""
    if not content:
        logger.error("æ²¡æœ‰å†…å®¹å¯ä¿å­˜")
        return False
    
    try:
        # èŽ·å–è„šæœ¬ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•ï¼ˆjokerç›®å½•ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(script_dir)
        output_path = os.path.join(parent_dir, "EE.m3u")
        
        logger.info(f"å°†ä¿å­˜åˆ°: {output_path}")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # éªŒè¯æ–‡ä»¶
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            extinf_count = content.count("#EXTINF")
            
            logger.info("âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
            logger.info(f"ðŸ“ æ–‡ä»¶è·¯å¾„: {output_path}")
            logger.info(f"ðŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            logger.info(f"ðŸ“ˆ é¢‘é“æ€»æ•°: {extinf_count}")
            
            # ç»Ÿè®¡å„åˆ†ç±»æ•°é‡
            hk_count = content.count('group-title="HK"')
            tw_count = content.count('group-title="TW"')
            
            logger.info("=== è¯¦ç»†åˆ†ç±»ç»Ÿè®¡ ===")
            logger.info(f"HKé¢‘é“: {hk_count} ä¸ª")
            logger.info(f"TWé¢‘é“: {tw_count} ä¸ª")
            
            return True
        else:
            logger.error("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=== M3Ué¢‘é“æå–å™¨å¼€å§‹è¿è¡Œ ===")
    logger.info("å°†æå–HKå’ŒTWé¢‘é“ï¼Œå¹¶éªŒè¯æ’­æ”¾çŠ¶æ€")
    
    # 1. èŽ·å–HKæºå†…å®¹
    logger.info("=== å¤„ç†HKæº ===")
    hk_content = fetch_m3u_content(HK_SOURCE_URL, "HKæº")
    if hk_content:
        hk_channels = parse_m3u_content(hk_content, "HK")
        logger.info(f"ä»ŽHKæºè§£æžå‡º {len(hk_channels)} ä¸ªé¢‘é“")
    else:
        hk_channels = []
        logger.warning("HKæºèŽ·å–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç©ºåˆ—è¡¨")
    
    # 2. èŽ·å–TWæºå†…å®¹
    logger.info("=== å¤„ç†TWæº ===")
    tw_content = fetch_m3u_content(TW_SOURCE_URL, "TWæº")
    if tw_content:
        tw_channels = parse_m3u_content(tw_content, "TW")
        logger.info(f"ä»ŽTWæºè§£æžå‡º {len(tw_channels)} ä¸ªé¢‘é“")
    else:
        tw_channels = []
        logger.warning("TWæºèŽ·å–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç©ºåˆ—è¡¨")
    
    # 3. éªŒè¯é¢‘é“æ’­æ”¾çŠ¶æ€
    logger.info("=== å¼€å§‹éªŒè¯é¢‘é“æ’­æ”¾çŠ¶æ€ ===")
    all_channels = hk_channels + tw_channels
    
    if all_channels:
        valid_channels, invalid_channels = validate_channels(all_channels)
        
        # é‡æ–°åˆ†ç»„
        hk_valid = [c for c in valid_channels if c['group'] == 'HK']
        tw_valid = [c for c in valid_channels if c['group'] == 'TW']
        
        logger.info(f"éªŒè¯ç»“æžœ: HKæœ‰æ•ˆ {len(hk_valid)} ä¸ª, TWæœ‰æ•ˆ {len(tw_valid)} ä¸ª")
        
        # è®°å½•æ— æ•ˆé¢‘é“
        if invalid_channels:
            logger.warning(f"ä»¥ä¸‹ {len(invalid_channels)} ä¸ªé¢‘é“ä¸å¯æ’­æ”¾:")
            for channel in invalid_channels[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.warning(f"  - {channel['name']} ({channel['group']})")
            if len(invalid_channels) > 10:
                logger.warning(f"  ... è¿˜æœ‰ {len(invalid_channels) - 10} ä¸ª")
    else:
        hk_valid = []
        tw_valid = []
        logger.warning("æ²¡æœ‰æå–åˆ°ä»»ä½•é¢‘é“")
    
    # 4. æž„å»ºTVå†…å®¹
    tv_content = build_m3u_content(hk_valid, tw_valid)
    
    # 5. è¯»å–BB.m3u
    bb_content = read_bb_file()
    
    # 6. åˆå¹¶å†…å®¹
    merged_content = merge_with_bb(tv_content, bb_content)
    
    # 7. ä¿å­˜æ–‡ä»¶
    if save_m3u_file(merged_content):
        logger.info("=== å¤„ç†å®Œæˆ ===")
        
        # æœ€ç»ˆç»Ÿè®¡
        final_hk_count = merged_content.count('group-title="HK"')
        final_tw_count = merged_content.count('group-title="TW"')
        final_total = merged_content.count("#EXTINF")
        
        logger.info(f"æœ€ç»ˆç»“æžœ: æ€»é¢‘é“æ•°={final_total}, HKé¢‘é“={final_hk_count}, TWé¢‘é“={final_tw_count}")
        
        return True
    else:
        logger.error("=== å¤„ç†å¤±è´¥ ===")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
EOF
          
          # è®¾ç½®æ‰§è¡Œæƒé™
          chmod +x scripts/tv_extractor_new.py
      
      - name: Run extraction with validation
        working-directory: ./scripts
        run: |
          echo "=== å¼€å§‹æå–å’ŒéªŒè¯é¢‘é“ ==="
          python tv_extractor_new.py
      
      - name: Verify EE.m3u file
        run: |
          echo "=== éªŒè¯EE.m3uæ–‡ä»¶ ==="
          if [ -f "EE.m3u" ]; then
            echo "âœ… EE.m3uæ–‡ä»¶å­˜åœ¨"
            
            # ç»Ÿè®¡ä¿¡æ¯ - ä¿®å¤shellç®—æœ¯è¿ç®—
            echo ""
            echo "=== é¢‘é“ç»Ÿè®¡ ==="
            total=$(grep -c "#EXTINF" EE.m3u 2>/dev/null || true)
            hk=$(grep -c 'group-title="HK"' EE.m3u 2>/dev/null || true)
            tw=$(grep -c 'group-title="TW"' EE.m3u 2>/dev/null || true)
            
            # è®¾ç½®é»˜è®¤å€¼ä¸º0
            total=${total:-0}
            hk=${hk:-0}
            tw=${tw:-0}
            
            # å®‰å…¨åœ°è¿›è¡Œç®—æœ¯è¿ç®—
            if [ "$total" -eq 0 ] 2>/dev/null; then
              bb_total=0
            else
              bb_total=$((total - hk - tw))
            fi
            
            echo "æ€»é¢‘é“æ•°: $total"
            echo "BBé¢‘é“æ•°: $bb_total"
            echo "HKé¢‘é“æ•°: $hk"
            echo "TWé¢‘é“æ•°: $tw"
            
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            echo ""
            echo "=== æ–‡ä»¶æ ¼å¼æ£€æŸ¥ ==="
            if head -1 EE.m3u | grep -q "#EXTM3U"; then
              echo "âœ… æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆä»¥#EXTM3Uå¼€å¤´ï¼‰"
            else
              echo "âŒ æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®"
            fi
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªé¢‘é“ç¤ºä¾‹
            echo ""
            echo "=== é¢‘é“ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰ ==="
            grep -A1 "#EXTINF" EE.m3u 2>/dev/null | head -10 || true
            
            # æ£€æŸ¥æ˜¯å¦æœ‰URL
            url_count=$(grep -c "^http" EE.m3u 2>/dev/null || true)
            url_count=${url_count:-0}
            echo ""
            echo "URLæ•°é‡: $url_count"
            
          else
            echo "âŒ EE.m3uæ–‡ä»¶ä¸å­˜åœ¨"
            exit 1
          fi
      
      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
      
      - name: Pull latest changes
        run: git pull origin main --rebase || true
      
      - name: Commit changes
        run: |
          git add EE.m3u
          if git diff --staged --quiet; then
            echo "æ²¡æœ‰æ›´æ”¹éœ€è¦æäº¤"
          else
            # èŽ·å–å½“å‰æ—¶é—´
            current_time=$(date +'%Y-%m-%d %H:%M:%S')
            
            # å®‰å…¨åœ°èŽ·å–ç»Ÿè®¡ä¿¡æ¯
            if [ -f "EE.m3u" ]; then
              total=$(grep -c "#EXTINF" EE.m3u 2>/dev/null || echo 0)
              hk=$(grep -c 'group-title="HK"' EE.m3u 2>/dev/null || echo 0)
              tw=$(grep -c 'group-title="TW"' EE.m3u 2>/dev/null || echo 0)
              
              # ç¡®ä¿æ˜¯æ•°å­—
              total=${total:-0}
              hk=${hk:-0}
              tw=${tw:-0}
              
              commit_msg="æ›´æ–°EE.m3u - ${total}é¢‘é“(HK:${hk}/TW:${tw}) ${current_time}"
            else
              commit_msg="æ›´æ–°EE.m3u ${current_time}"
            fi
            git commit -m "$commit_msg"
          fi
      
      - name: Push to repository
        run: git push origin main
      
      - name: Create summary report
        if: always()
        run: |
          echo "## é¢‘é“æå–æŠ¥å‘Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "EE.m3u" ]; then
            # å®‰å…¨åœ°èŽ·å–ç»Ÿè®¡ä¿¡æ¯
            total=$(grep -c "#EXTINF" EE.m3u 2>/dev/null || echo 0)
            hk=$(grep -c 'group-title="HK"' EE.m3u 2>/dev/null || echo 0)
            tw=$(grep -c 'group-title="TW"' EE.m3u 2>/dev/null || echo 0)
            
            # ç¡®ä¿æ˜¯æ•°å­—
            total=${total:-0}
            hk=${hk:-0}
            tw=${tw:-0}
            
            echo "âœ… **æå–å®Œæˆ**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| ç±»åˆ« | æ•°é‡ |" >> $GITHUB_STEP_SUMMARY
            echo "|------|------|" >> $GITHUB_STEP_SUMMARY
            echo "| æ€»é¢‘é“æ•° | $total |" >> $GITHUB_STEP_SUMMARY
            echo "| HKé¢‘é“ | $hk |" >> $GITHUB_STEP_SUMMARY
            echo "| TWé¢‘é“ | $tw |" >> $GITHUB_STEP_SUMMARY
            echo "| BBé¢‘é“ | $((total - hk - tw)) |" >> $GITHUB_STEP_SUMMARY
            
            # æ·»åŠ æ–‡ä»¶é¢„è§ˆé“¾æŽ¥
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“ **æ–‡ä»¶å·²æ›´æ–°**: [EE.m3u](EE.m3u)" >> $GITHUB_STEP_SUMMARY
            
          else
            echo "âŒ **æå–å¤±è´¥**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "EE.m3uæ–‡ä»¶æœªç”Ÿæˆï¼Œè¯·æ£€æŸ¥æ—¥å¿—" >> $GITHUB_STEP_SUMMARY
          fi
